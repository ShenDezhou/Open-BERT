{"cells":[{"cell_type":"markdown","metadata":{"id":"w8GkPIVd2uOY"},"source":["#BERT development praparation\n","BERT needs python3.6, tensorflow1.13.1, pytorch1.10.0, pytorch-transformers1.2.0 to run properly."]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":74188,"status":"ok","timestamp":1684741055037,"user":{"displayName":"Brian Shen","userId":"08246478872294528508"},"user_tz":-480},"id":"7v3GObGOKDMJ","outputId":"0103bb8b-8eb3-4aac-d25c-9e9027d67bda"},"outputs":[{"output_type":"stream","name":"stdout","text":["Python 3.10.11\n","Reading package lists... Done\n","Building dependency tree       \n","Reading state information... Done\n","The following additional packages will be installed:\n","  libpython3.6-minimal libpython3.6-stdlib python3.6-minimal\n","Suggested packages:\n","  python3.6-venv binfmt-support\n","The following NEW packages will be installed:\n","  libpython3.6-minimal libpython3.6-stdlib python3.6 python3.6-minimal\n","0 upgraded, 4 newly installed, 0 to remove and 24 not upgraded.\n","Need to get 4,294 kB of archives.\n","After this operation, 22.1 MB of additional disk space will be used.\n","Get:1 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu focal/main amd64 libpython3.6-minimal amd64 3.6.15-1+focal3 [569 kB]\n","Get:2 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu focal/main amd64 python3.6-minimal amd64 3.6.15-1+focal3 [1,718 kB]\n","Get:3 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu focal/main amd64 libpython3.6-stdlib amd64 3.6.15-1+focal3 [1,758 kB]\n","Get:4 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu focal/main amd64 python3.6 amd64 3.6.15-1+focal3 [248 kB]\n","Fetched 4,294 kB in 4s (963 kB/s)\n","debconf: unable to initialize frontend: Dialog\n","debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 4.)\n","debconf: falling back to frontend: Readline\n","debconf: unable to initialize frontend: Readline\n","debconf: (This frontend requires a controlling tty.)\n","debconf: falling back to frontend: Teletype\n","dpkg-preconfigure: unable to re-open stdin: \n","Selecting previously unselected package libpython3.6-minimal:amd64.\n","(Reading database ... 122531 files and directories currently installed.)\n","Preparing to unpack .../libpython3.6-minimal_3.6.15-1+focal3_amd64.deb ...\n","Unpacking libpython3.6-minimal:amd64 (3.6.15-1+focal3) ...\n","Selecting previously unselected package python3.6-minimal.\n","Preparing to unpack .../python3.6-minimal_3.6.15-1+focal3_amd64.deb ...\n","Unpacking python3.6-minimal (3.6.15-1+focal3) ...\n","Selecting previously unselected package libpython3.6-stdlib:amd64.\n","Preparing to unpack .../libpython3.6-stdlib_3.6.15-1+focal3_amd64.deb ...\n","Unpacking libpython3.6-stdlib:amd64 (3.6.15-1+focal3) ...\n","Selecting previously unselected package python3.6.\n","Preparing to unpack .../python3.6_3.6.15-1+focal3_amd64.deb ...\n","Unpacking python3.6 (3.6.15-1+focal3) ...\n","Setting up libpython3.6-minimal:amd64 (3.6.15-1+focal3) ...\n","Setting up python3.6-minimal (3.6.15-1+focal3) ...\n","Setting up libpython3.6-stdlib:amd64 (3.6.15-1+focal3) ...\n","Setting up python3.6 (3.6.15-1+focal3) ...\n","Processing triggers for man-db (2.9.1-1) ...\n","Processing triggers for mime-support (3.64ubuntu1) ...\n","update-alternatives: using /usr/bin/python3.6 to provide /usr/bin/python3 (python3) in auto mode\n","Reading package lists... Done\n","Building dependency tree       \n","Reading state information... Done\n","The following additional packages will be installed:\n","  python3.6-lib2to3\n","The following NEW packages will be installed:\n","  python3.6-distutils python3.6-lib2to3\n","0 upgraded, 2 newly installed, 0 to remove and 24 not upgraded.\n","Need to get 308 kB of archives.\n","After this operation, 1,232 kB of additional disk space will be used.\n","Get:1 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu focal/main amd64 python3.6-lib2to3 all 3.6.15-1+focal3 [122 kB]\n","Get:2 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu focal/main amd64 python3.6-distutils all 3.6.15-1+focal3 [187 kB]\n","Fetched 308 kB in 1s (224 kB/s)\n","debconf: unable to initialize frontend: Dialog\n","debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 2.)\n","debconf: falling back to frontend: Readline\n","debconf: unable to initialize frontend: Readline\n","debconf: (This frontend requires a controlling tty.)\n","debconf: falling back to frontend: Teletype\n","dpkg-preconfigure: unable to re-open stdin: \n","Selecting previously unselected package python3.6-lib2to3.\n","(Reading database ... 123142 files and directories currently installed.)\n","Preparing to unpack .../python3.6-lib2to3_3.6.15-1+focal3_all.deb ...\n","Unpacking python3.6-lib2to3 (3.6.15-1+focal3) ...\n","Selecting previously unselected package python3.6-distutils.\n","Preparing to unpack .../python3.6-distutils_3.6.15-1+focal3_all.deb ...\n","Unpacking python3.6-distutils (3.6.15-1+focal3) ...\n","Setting up python3.6-lib2to3 (3.6.15-1+focal3) ...\n","Setting up python3.6-distutils (3.6.15-1+focal3) ...\n","Reading package lists... Done\n","Building dependency tree       \n","Reading state information... Done\n","The following additional packages will be installed:\n","  python-pip-whl python3-setuptools python3-wheel\n","Suggested packages:\n","  python-setuptools-doc\n","The following NEW packages will be installed:\n","  python-pip-whl python3-pip python3-setuptools python3-wheel\n","0 upgraded, 4 newly installed, 0 to remove and 24 not upgraded.\n","Need to get 2,389 kB of archives.\n","After this operation, 4,933 kB of additional disk space will be used.\n","Get:1 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 python-pip-whl all 20.0.2-5ubuntu1.8 [1,805 kB]\n","Get:2 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 python3-setuptools all 45.2.0-1ubuntu0.1 [330 kB]\n","Get:3 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 python3-wheel all 0.34.2-1ubuntu0.1 [23.9 kB]\n","Get:4 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 python3-pip all 20.0.2-5ubuntu1.8 [231 kB]\n","Fetched 2,389 kB in 1s (1,622 kB/s)\n","debconf: unable to initialize frontend: Dialog\n","debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 4.)\n","debconf: falling back to frontend: Readline\n","debconf: unable to initialize frontend: Readline\n","debconf: (This frontend requires a controlling tty.)\n","debconf: falling back to frontend: Teletype\n","dpkg-preconfigure: unable to re-open stdin: \n","Selecting previously unselected package python-pip-whl.\n","(Reading database ... 123281 files and directories currently installed.)\n","Preparing to unpack .../python-pip-whl_20.0.2-5ubuntu1.8_all.deb ...\n","Unpacking python-pip-whl (20.0.2-5ubuntu1.8) ...\n","Selecting previously unselected package python3-setuptools.\n","Preparing to unpack .../python3-setuptools_45.2.0-1ubuntu0.1_all.deb ...\n","Unpacking python3-setuptools (45.2.0-1ubuntu0.1) ...\n","Selecting previously unselected package python3-wheel.\n","Preparing to unpack .../python3-wheel_0.34.2-1ubuntu0.1_all.deb ...\n","Unpacking python3-wheel (0.34.2-1ubuntu0.1) ...\n","Selecting previously unselected package python3-pip.\n","Preparing to unpack .../python3-pip_20.0.2-5ubuntu1.8_all.deb ...\n","Unpacking python3-pip (20.0.2-5ubuntu1.8) ...\n","Setting up python3-setuptools (45.2.0-1ubuntu0.1) ...\n","Setting up python3-wheel (0.34.2-1ubuntu0.1) ...\n","Setting up python-pip-whl (20.0.2-5ubuntu1.8) ...\n","Setting up python3-pip (20.0.2-5ubuntu1.8) ...\n","Processing triggers for man-db (2.9.1-1) ...\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting pip\n","  Downloading pip-21.3.1-py3-none-any.whl (1.7 MB)\n","\u001b[K     |████████████████████████████████| 1.7 MB 9.4 MB/s \n","\u001b[?25hInstalling collected packages: pip\n","  Attempting uninstall: pip\n","    Found existing installation: pip 20.0.2\n","    Not uninstalling pip at /usr/lib/python3/dist-packages, outside environment /usr\n","    Can't uninstall 'pip'. No files were found to uninstall.\n","Successfully installed pip-21.3.1\n","\u001b[33mWARNING: Skipping six as it is not installed.\u001b[0m\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting tensorflow==1.13.1\n","  Downloading tensorflow-1.13.1-cp36-cp36m-manylinux1_x86_64.whl (92.5 MB)\n","     |████████████████████████████████| 92.5 MB 86 kB/s              \n","\u001b[?25hCollecting keras-preprocessing>=1.0.5\n","  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n","     |████████████████████████████████| 42 kB 628 kB/s             \n","\u001b[?25hCollecting numpy>=1.13.3\n","  Downloading numpy-1.19.5-cp36-cp36m-manylinux2010_x86_64.whl (14.8 MB)\n","     |████████████████████████████████| 14.8 MB 33.4 MB/s            \n","\u001b[?25hCollecting keras-applications>=1.0.6\n","  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n","     |████████████████████████████████| 50 kB 5.6 MB/s             \n","\u001b[?25hCollecting absl-py>=0.1.6\n","  Downloading absl_py-1.4.0-py3-none-any.whl (126 kB)\n","     |████████████████████████████████| 126 kB 46.7 MB/s            \n","\u001b[?25hRequirement already satisfied: wheel>=0.26 in /usr/lib/python3/dist-packages (from tensorflow==1.13.1) (0.34.2)\n","Collecting astor>=0.6.0\n","  Downloading astor-0.8.1-py2.py3-none-any.whl (27 kB)\n","Collecting grpcio>=1.8.6\n","  Downloading grpcio-1.48.2-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n","     |████████████████████████████████| 4.6 MB 50.8 MB/s            \n","\u001b[?25hCollecting gast>=0.2.0\n","  Downloading gast-0.5.4-py3-none-any.whl (19 kB)\n","Collecting six>=1.10.0\n","  Downloading six-1.16.0-py2.py3-none-any.whl (11 kB)\n","Collecting termcolor>=1.1.0\n","  Downloading termcolor-1.1.0.tar.gz (3.9 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting tensorboard<1.14.0,>=1.13.0\n","  Downloading tensorboard-1.13.1-py3-none-any.whl (3.2 MB)\n","     |████████████████████████████████| 3.2 MB 38.6 MB/s            \n","\u001b[?25hCollecting tensorflow-estimator<1.14.0rc0,>=1.13.0\n","  Downloading tensorflow_estimator-1.13.0-py2.py3-none-any.whl (367 kB)\n","     |████████████████████████████████| 367 kB 65.2 MB/s            \n","\u001b[?25hCollecting protobuf>=3.6.1\n","  Downloading protobuf-3.19.6-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n","     |████████████████████████████████| 1.1 MB 60.3 MB/s            \n","\u001b[?25hCollecting h5py\n","  Downloading h5py-3.1.0-cp36-cp36m-manylinux1_x86_64.whl (4.0 MB)\n","     |████████████████████████████████| 4.0 MB 54.2 MB/s            \n","\u001b[?25hCollecting markdown>=2.6.8\n","  Downloading Markdown-3.3.7-py3-none-any.whl (97 kB)\n","     |████████████████████████████████| 97 kB 7.3 MB/s             \n","\u001b[?25hCollecting werkzeug>=0.11.15\n","  Downloading Werkzeug-2.0.3-py3-none-any.whl (289 kB)\n","     |████████████████████████████████| 289 kB 36.5 MB/s            \n","\u001b[?25hCollecting mock>=2.0.0\n","  Downloading mock-5.0.2-py3-none-any.whl (30 kB)\n","Collecting importlib-metadata>=4.4\n","  Downloading importlib_metadata-4.8.3-py3-none-any.whl (17 kB)\n","Collecting dataclasses\n","  Downloading dataclasses-0.8-py3-none-any.whl (19 kB)\n","Collecting cached-property\n","  Downloading cached_property-1.5.2-py2.py3-none-any.whl (7.6 kB)\n","Collecting zipp>=0.5\n","  Downloading zipp-3.6.0-py3-none-any.whl (5.3 kB)\n","Collecting typing-extensions>=3.6.4\n","  Downloading typing_extensions-4.1.1-py3-none-any.whl (26 kB)\n","Building wheels for collected packages: termcolor\n","  Building wheel for termcolor (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4830 sha256=fcc655af80d771fe6f6e5221067bf749075d7be0a03a0450efe03f0093a7c358\n","  Stored in directory: /root/.cache/pip/wheels/93/2a/eb/e58dbcbc963549ee4f065ff80a59f274cc7210b6eab962acdc\n","Successfully built termcolor\n","Installing collected packages: zipp, typing-extensions, six, numpy, importlib-metadata, dataclasses, cached-property, werkzeug, protobuf, mock, markdown, h5py, grpcio, absl-py, termcolor, tensorflow-estimator, tensorboard, keras-preprocessing, keras-applications, gast, astor, tensorflow\n","Successfully installed absl-py-1.4.0 astor-0.8.1 cached-property-1.5.2 dataclasses-0.8 gast-0.5.4 grpcio-1.48.2 h5py-3.1.0 importlib-metadata-4.8.3 keras-applications-1.0.8 keras-preprocessing-1.1.2 markdown-3.3.7 mock-5.0.2 numpy-1.19.5 protobuf-3.19.6 six-1.16.0 tensorboard-1.13.1 tensorflow-1.13.1 tensorflow-estimator-1.13.0 termcolor-1.1.0 typing-extensions-4.1.1 werkzeug-2.0.3 zipp-3.6.0\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["six"]}}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Python 3.6.15\n"]}],"source":["!python -V\n","!sudo apt-get install python3.6\n","!sudo update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.6 3\n","#!sudo update-alternatives --config python3\n","!sudo apt-get install python3.6-distutils\n","!sudo apt install python3-pip\n","!python -m pip install --upgrade pip\n","!pip uninstall six -y\n","#!pip install tensorflow==1.13.1\n","!pip install tensorflow-gpu==1.13.1\n","!python -V"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hqeVu-2uYsdj","executionInfo":{"status":"ok","timestamp":1684740980854,"user_tz":-480,"elapsed":24866,"user":{"displayName":"Brian Shen","userId":"08246478872294528508"}},"outputId":"1c32c7a9-f7b8-4137-f640-b148e971c9c1"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","metadata":{"id":"KPY8RrZI5YR_"},"source":["Install Cuda10.0 and CuDNN7.4 to cope with Tensorflow1.13.1."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hWP_NtSp9WKZ"},"outputs":[],"source":["%cd /content/drive/MyDrive/libs\n","!apt-get --purge remove cuda nvidia* libnvidia-*\n","!dpkg -l | grep cuda- | awk '{print $2}' | xargs -n1 dpkg --purge\n","!apt-get remove cuda-*\n","!apt autoremove\n","!apt-get update\n","\n","#!wget  --no-clobber https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64/cuda-repo-ubuntu1804_10.0.130-1_amd64.deb\n","#install CUDA kit dpkg\n","!dpkg -i cuda-repo-ubuntu1804_10.0.130-1_amd64.deb\n","!sudo apt-key adv --fetch-keys https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64/7fa2af80.pub\n","!apt-get update\n","!apt-get install cuda-10-0\n","#%cd /content/drive/MyDrive/Code\n","#!wget https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64/libcudnn7-dev_7.4.2.24-1+cuda10.0_amd64.deb\n","#!wget https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64/libcudnn7_7.4.2.24-1+cuda10.0_amd64.deb\n","!dpkg -i libcudnn7_7.4.2.24-1+cuda10.0_amd64.deb\n","!dpkg -i libcudnn7-dev_7.4.2.24-1+cuda10.0_amd64.deb"]},{"cell_type":"markdown","metadata":{"id":"Dtt8dzleAgKN"},"source":["0.GLUE data"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"duZ-FtjqyOM9","outputId":"0d955328-ed25-49ae-aefe-0d517e839552"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/drive/MyDrive/Code\n","Downloading and extracting CoLA...\n","\tCompleted!\n","Downloading and extracting SST...\n","\tCompleted!\n","Processing MRPC...\n","\tCompleted!\n","Downloading and extracting QQP...\n","\tCompleted!\n","Downloading and extracting STS...\n","\tCompleted!\n","Downloading and extracting MNLI...\n","\tNote (12/10/20): This script no longer downloads SNLI. You will need to manually download and format the data to use SNLI.\n","\tCompleted!\n","Downloading and extracting QNLI...\n","\tCompleted!\n","Downloading and extracting RTE...\n","\tCompleted!\n","Downloading and extracting WNLI...\n","\tCompleted!\n","Downloading and extracting diagnostic...\n","\tCompleted!\n"]}],"source":["# %cd /content/drive/MyDrive/Code\n","# %pwd\n","# for i in [\"CoLA\", \"SST\", \"MRPC\", \"QQP\", \"STS\", \"MNLI\", \"QNLI\", \"RTE\", \"WNLI\", \"diagnostic\"]:\n","#   !python download_glue.py --data_dir data --tasks $i"]},{"cell_type":"code","source":["%cd /content/drive/MyDrive/Code_pretrain\n","!wget https://storage.googleapis.com/bert_models/2020_02_20/uncased_L-4_H-256_A-4.zip\n","!unzip uncased_L-4_H-256_A-4.zip -d uncased_L-4_H-256_A-4"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"g4Dls6PWHZr6","executionInfo":{"status":"ok","timestamp":1684736476327,"user_tz":-480,"elapsed":4437,"user":{"displayName":"Brian Shen","userId":"08246478872294528508"}},"outputId":"f4d10f10-e448-4d7f-8b44-997f9d6f0015"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Code_pretrain\n","--2023-05-22 06:21:10--  https://storage.googleapis.com/bert_models/2020_02_20/uncased_L-4_H-256_A-4.zip\n","Resolving storage.googleapis.com (storage.googleapis.com)... 172.217.194.128, 74.125.200.128, 74.125.68.128, ...\n","Connecting to storage.googleapis.com (storage.googleapis.com)|172.217.194.128|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 41854126 (40M) [application/zip]\n","Saving to: ‘uncased_L-4_H-256_A-4.zip’\n","\n","uncased_L-4_H-256_A 100%[===================>]  39.92M  12.5MB/s    in 3.2s    \n","\n","2023-05-22 06:21:14 (12.5 MB/s) - ‘uncased_L-4_H-256_A-4.zip’ saved [41854126/41854126]\n","\n","Archive:  uncased_L-4_H-256_A-4.zip\n","  inflating: uncased_L-4_H-256_A-4/bert_model.ckpt.data-00000-of-00001  \n","  inflating: uncased_L-4_H-256_A-4/bert_config.json  \n","  inflating: uncased_L-4_H-256_A-4/vocab.txt  \n","  inflating: uncased_L-4_H-256_A-4/bert_model.ckpt.index  \n"]}]},{"cell_type":"markdown","metadata":{"id":"CJRoUEBmoPS7"},"source":["#BERT-Mini\n","Use a mini model to walk through finetuning steps."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UGYrRjusyp4h","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1684736659010,"user_tz":-480,"elapsed":71844,"user":{"displayName":"Brian Shen","userId":"08246478872294528508"}},"outputId":"6fcee564-5ea6-48d2-b000-80786b6001bb"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Code_pretrain\n","env: BERT_BASE_DIR=uncased_L-4_H-256_A-4\n","env: GLUE_DIR=data\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n","\n","WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n","For more information, please see:\n","  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n","  * https://github.com/tensorflow/addons\n","If you depend on functionality not listed there, please file an issue.\n","\n","WARNING:tensorflow:Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7ff8442dbb70>) includes params argument, but params are not passed to Estimator.\n","INFO:tensorflow:Using config: {'_model_dir': '/content/trained_output', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 1000, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n","graph_options {\n","  rewrite_options {\n","    meta_optimizer_iterations: ONE\n","  }\n","}\n",", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7ff844799ba8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=1000, num_shards=8, num_cores_per_replica=None, per_host_input_for_training=3, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None), '_cluster': None}\n","INFO:tensorflow:_TPUContext: eval_on_tpu True\n","WARNING:tensorflow:eval_on_tpu ignored because use_tpu is False.\n","INFO:tensorflow:Writing example 0 of 8551\n","INFO:tensorflow:*** Example ***\n","INFO:tensorflow:guid: train-0\n","INFO:tensorflow:tokens: [CLS] our friends won ' t buy this analysis , let alone the next one we propose . [SEP]\n","INFO:tensorflow:input_ids: 101 2256 2814 2180 1005 1056 4965 2023 4106 1010 2292 2894 1996 2279 2028 2057 16599 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:label: 1 (id = 1)\n","INFO:tensorflow:*** Example ***\n","INFO:tensorflow:guid: train-1\n","INFO:tensorflow:tokens: [CLS] one more pseudo general ##ization and i ' m giving up . [SEP]\n","INFO:tensorflow:input_ids: 101 2028 2062 18404 2236 3989 1998 1045 1005 1049 3228 2039 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:label: 1 (id = 1)\n","INFO:tensorflow:*** Example ***\n","INFO:tensorflow:guid: train-2\n","INFO:tensorflow:tokens: [CLS] one more pseudo general ##ization or i ' m giving up . [SEP]\n","INFO:tensorflow:input_ids: 101 2028 2062 18404 2236 3989 2030 1045 1005 1049 3228 2039 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:label: 1 (id = 1)\n","INFO:tensorflow:*** Example ***\n","INFO:tensorflow:guid: train-3\n","INFO:tensorflow:tokens: [CLS] the more we study verbs , the cr ##azi ##er they get . [SEP]\n","INFO:tensorflow:input_ids: 101 1996 2062 2057 2817 16025 1010 1996 13675 16103 2121 2027 2131 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:label: 1 (id = 1)\n","INFO:tensorflow:*** Example ***\n","INFO:tensorflow:guid: train-4\n","INFO:tensorflow:tokens: [CLS] day by day the facts are getting mu ##rk ##ier . [SEP]\n","INFO:tensorflow:input_ids: 101 2154 2011 2154 1996 8866 2024 2893 14163 8024 3771 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:label: 1 (id = 1)\n","INFO:tensorflow:***** Running training *****\n","INFO:tensorflow:  Num examples = 8551\n","INFO:tensorflow:  Batch size = 4\n","INFO:tensorflow:  Num steps = 2137\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Colocations handled automatically by placer.\n","WARNING:tensorflow:From run_classifier.py:890: map_and_batch (from tensorflow.contrib.data.python.ops.batching) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.experimental.map_and_batch(...)`.\n","WARNING:tensorflow:From run_classifier.py:870: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.cast instead.\n","INFO:tensorflow:Calling model_fn.\n","INFO:tensorflow:Running train on CPU\n","INFO:tensorflow:*** Features ***\n","INFO:tensorflow:  name = input_ids, shape = (4, 128)\n","INFO:tensorflow:  name = input_mask, shape = (4, 128)\n","INFO:tensorflow:  name = is_real_example, shape = (4,)\n","INFO:tensorflow:  name = label_ids, shape = (4,)\n","INFO:tensorflow:  name = segment_ids, shape = (4, 128)\n","WARNING:tensorflow:From /content/drive/MyDrive/Code_pretrain/modeling.py:358: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n","WARNING:tensorflow:From /content/drive/MyDrive/Code_pretrain/modeling.py:671: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use keras.layers.dense instead.\n","INFO:tensorflow:**** Trainable Variables ****\n","INFO:tensorflow:  name = bert/embeddings/word_embeddings:0, shape = (30522, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/embeddings/token_type_embeddings:0, shape = (2, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/embeddings/position_embeddings:0, shape = (512, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/embeddings/LayerNorm/beta:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/embeddings/LayerNorm/gamma:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/query/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/query/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/key/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/key/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/value/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/value/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/dense/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/dense/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/LayerNorm/beta:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/LayerNorm/gamma:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/intermediate/dense/kernel:0, shape = (256, 1024), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/intermediate/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/output/dense/kernel:0, shape = (1024, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/output/dense/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/output/LayerNorm/beta:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/output/LayerNorm/gamma:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/query/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/query/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/key/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/key/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/value/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/value/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/dense/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/dense/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/LayerNorm/beta:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/LayerNorm/gamma:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/intermediate/dense/kernel:0, shape = (256, 1024), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/intermediate/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/output/dense/kernel:0, shape = (1024, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/output/dense/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/output/LayerNorm/beta:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/output/LayerNorm/gamma:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/query/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/query/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/key/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/key/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/value/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/value/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/dense/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/dense/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/LayerNorm/beta:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/LayerNorm/gamma:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/intermediate/dense/kernel:0, shape = (256, 1024), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/intermediate/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/output/dense/kernel:0, shape = (1024, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/output/dense/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/output/LayerNorm/beta:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/output/LayerNorm/gamma:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/query/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/query/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/key/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/key/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/value/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/value/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/dense/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/dense/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/LayerNorm/beta:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/LayerNorm/gamma:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/intermediate/dense/kernel:0, shape = (256, 1024), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/intermediate/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/output/dense/kernel:0, shape = (1024, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/output/dense/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/output/LayerNorm/beta:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/output/LayerNorm/gamma:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/pooler/dense/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/pooler/dense/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = output_weights:0, shape = (2, 256)\n","INFO:tensorflow:  name = output_bias:0, shape = (2,)\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/learning_rate_decay_v2.py:321: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Deprecated in favor of operator or tf.math.divide.\n","INFO:tensorflow:Done calling model_fn.\n","INFO:tensorflow:Create CheckpointSaverHook.\n","INFO:tensorflow:Graph was finalized.\n","2023-05-22 06:23:20.607588: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA\n","2023-05-22 06:23:20.771101: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2023-05-22 06:23:20.771543: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x5e79e20 executing computations on platform CUDA. Devices:\n","2023-05-22 06:23:20.771584: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n","2023-05-22 06:23:20.798494: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2000185000 Hz\n","2023-05-22 06:23:20.798668: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x23e2f60 executing computations on platform Host. Devices:\n","2023-05-22 06:23:20.798707: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>\n","2023-05-22 06:23:20.798899: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 0 with properties: \n","name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n","pciBusID: 0000:00:04.0\n","totalMemory: 14.75GiB freeMemory: 14.65GiB\n","2023-05-22 06:23:20.798925: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0\n","2023-05-22 06:23:20.800189: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2023-05-22 06:23:20.800219: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0 \n","2023-05-22 06:23:20.800229: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N \n","2023-05-22 06:23:20.800322: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","2023-05-22 06:23:20.800372: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14248 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n","INFO:tensorflow:Running local_init_op.\n","INFO:tensorflow:Done running local_init_op.\n","INFO:tensorflow:Saving checkpoints for 0 into /content/trained_output/model.ckpt.\n","2023-05-22 06:23:28.372569: I tensorflow/stream_executor/dso_loader.cc:152] successfully opened CUDA library libcublas.so.10.0 locally\n","INFO:tensorflow:global_step/sec: 30.7815\n","INFO:tensorflow:examples/sec: 123.126\n","INFO:tensorflow:global_step/sec: 50.6507\n","INFO:tensorflow:examples/sec: 202.603\n","INFO:tensorflow:global_step/sec: 50.293\n","INFO:tensorflow:examples/sec: 201.172\n","INFO:tensorflow:global_step/sec: 50.2294\n","INFO:tensorflow:examples/sec: 200.918\n","INFO:tensorflow:global_step/sec: 53.648\n","INFO:tensorflow:examples/sec: 214.592\n","INFO:tensorflow:global_step/sec: 53.5059\n","INFO:tensorflow:examples/sec: 214.023\n","INFO:tensorflow:global_step/sec: 53.8923\n","INFO:tensorflow:examples/sec: 215.569\n","INFO:tensorflow:global_step/sec: 53.7968\n","INFO:tensorflow:examples/sec: 215.187\n","INFO:tensorflow:global_step/sec: 54.0546\n","INFO:tensorflow:examples/sec: 216.218\n","INFO:tensorflow:Saving checkpoints for 1000 into /content/trained_output/model.ckpt.\n","INFO:tensorflow:global_step/sec: 35.7871\n","INFO:tensorflow:examples/sec: 143.148\n","INFO:tensorflow:global_step/sec: 49.1104\n","INFO:tensorflow:examples/sec: 196.442\n","INFO:tensorflow:global_step/sec: 48.2487\n","INFO:tensorflow:examples/sec: 192.995\n","INFO:tensorflow:global_step/sec: 51.5302\n","INFO:tensorflow:examples/sec: 206.121\n","INFO:tensorflow:global_step/sec: 53.4212\n","INFO:tensorflow:examples/sec: 213.685\n","INFO:tensorflow:global_step/sec: 53.4872\n","INFO:tensorflow:examples/sec: 213.949\n","INFO:tensorflow:global_step/sec: 53.2081\n","INFO:tensorflow:examples/sec: 212.832\n","INFO:tensorflow:global_step/sec: 53.1481\n","INFO:tensorflow:examples/sec: 212.592\n","INFO:tensorflow:global_step/sec: 52.6044\n","INFO:tensorflow:examples/sec: 210.418\n","INFO:tensorflow:global_step/sec: 49.4786\n","INFO:tensorflow:examples/sec: 197.914\n","INFO:tensorflow:Saving checkpoints for 2000 into /content/trained_output/model.ckpt.\n","INFO:tensorflow:global_step/sec: 35.985\n","INFO:tensorflow:examples/sec: 143.94\n","INFO:tensorflow:global_step/sec: 48.6369\n","INFO:tensorflow:examples/sec: 194.548\n","INFO:tensorflow:Saving checkpoints for 2137 into /content/trained_output/model.ckpt.\n","INFO:tensorflow:Loss for final step: 0.5221486.\n","INFO:tensorflow:training_loop marked as finished\n","INFO:tensorflow:Writing example 0 of 1043\n","INFO:tensorflow:*** Example ***\n","INFO:tensorflow:guid: dev-0\n","INFO:tensorflow:tokens: [CLS] the sailors rode the breeze clear of the rocks . [SEP]\n","INFO:tensorflow:input_ids: 101 1996 11279 8469 1996 9478 3154 1997 1996 5749 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:label: 1 (id = 1)\n","INFO:tensorflow:*** Example ***\n","INFO:tensorflow:guid: dev-1\n","INFO:tensorflow:tokens: [CLS] the weights made the rope stretch over the pull ##ey . [SEP]\n","INFO:tensorflow:input_ids: 101 1996 15871 2081 1996 8164 7683 2058 1996 4139 3240 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:label: 1 (id = 1)\n","INFO:tensorflow:*** Example ***\n","INFO:tensorflow:guid: dev-2\n","INFO:tensorflow:tokens: [CLS] the mechanical doll wr ##ig ##gled itself loose . [SEP]\n","INFO:tensorflow:input_ids: 101 1996 6228 10658 23277 8004 11533 2993 6065 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:label: 1 (id = 1)\n","INFO:tensorflow:*** Example ***\n","INFO:tensorflow:guid: dev-3\n","INFO:tensorflow:tokens: [CLS] if you had eaten more , you would want less . [SEP]\n","INFO:tensorflow:input_ids: 101 2065 2017 2018 8828 2062 1010 2017 2052 2215 2625 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:label: 1 (id = 1)\n","INFO:tensorflow:*** Example ***\n","INFO:tensorflow:guid: dev-4\n","INFO:tensorflow:tokens: [CLS] as you eat the most , you want the least . [SEP]\n","INFO:tensorflow:input_ids: 101 2004 2017 4521 1996 2087 1010 2017 2215 1996 2560 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:label: 0 (id = 0)\n","INFO:tensorflow:***** Running evaluation *****\n","INFO:tensorflow:  Num examples = 1043 (1043 actual, 0 padding)\n","INFO:tensorflow:  Batch size = 8\n","INFO:tensorflow:Calling model_fn.\n","INFO:tensorflow:Running eval on CPU\n","INFO:tensorflow:*** Features ***\n","INFO:tensorflow:  name = input_ids, shape = (?, 128)\n","INFO:tensorflow:  name = input_mask, shape = (?, 128)\n","INFO:tensorflow:  name = is_real_example, shape = (?,)\n","INFO:tensorflow:  name = label_ids, shape = (?,)\n","INFO:tensorflow:  name = segment_ids, shape = (?, 128)\n","INFO:tensorflow:**** Trainable Variables ****\n","INFO:tensorflow:  name = bert/embeddings/word_embeddings:0, shape = (30522, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/embeddings/token_type_embeddings:0, shape = (2, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/embeddings/position_embeddings:0, shape = (512, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/embeddings/LayerNorm/beta:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/embeddings/LayerNorm/gamma:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/query/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/query/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/key/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/key/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/value/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/value/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/dense/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/dense/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/LayerNorm/beta:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/LayerNorm/gamma:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/intermediate/dense/kernel:0, shape = (256, 1024), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/intermediate/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/output/dense/kernel:0, shape = (1024, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/output/dense/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/output/LayerNorm/beta:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/output/LayerNorm/gamma:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/query/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/query/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/key/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/key/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/value/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/value/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/dense/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/dense/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/LayerNorm/beta:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/LayerNorm/gamma:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/intermediate/dense/kernel:0, shape = (256, 1024), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/intermediate/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/output/dense/kernel:0, shape = (1024, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/output/dense/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/output/LayerNorm/beta:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/output/LayerNorm/gamma:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/query/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/query/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/key/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/key/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/value/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/value/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/dense/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/dense/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/LayerNorm/beta:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/LayerNorm/gamma:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/intermediate/dense/kernel:0, shape = (256, 1024), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/intermediate/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/output/dense/kernel:0, shape = (1024, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/output/dense/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/output/LayerNorm/beta:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/output/LayerNorm/gamma:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/query/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/query/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/key/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/key/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/value/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/value/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/dense/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/dense/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/LayerNorm/beta:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/LayerNorm/gamma:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/intermediate/dense/kernel:0, shape = (256, 1024), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/intermediate/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/output/dense/kernel:0, shape = (1024, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/output/dense/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/output/LayerNorm/beta:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/output/LayerNorm/gamma:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/pooler/dense/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/pooler/dense/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = output_weights:0, shape = (2, 256)\n","INFO:tensorflow:  name = output_bias:0, shape = (2,)\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/metrics_impl.py:455: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.cast instead.\n","INFO:tensorflow:Done calling model_fn.\n","INFO:tensorflow:Starting evaluation at 2023-05-22T06:24:16Z\n","INFO:tensorflow:Graph was finalized.\n","2023-05-22 06:24:16.474461: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0\n","2023-05-22 06:24:16.474522: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2023-05-22 06:24:16.474542: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0 \n","2023-05-22 06:24:16.474552: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N \n","2023-05-22 06:24:16.474652: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14248 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use standard file APIs to check for files with this prefix.\n","INFO:tensorflow:Restoring parameters from /content/trained_output/model.ckpt-2137\n","INFO:tensorflow:Running local_init_op.\n","INFO:tensorflow:Done running local_init_op.\n","INFO:tensorflow:Finished evaluation at 2023-05-22-06:24:17\n","INFO:tensorflow:Saving dict for global step 2137: eval_accuracy = 0.6912752, eval_loss = 0.63406587, global_step = 2137, loss = 0.63434684\n","INFO:tensorflow:Saving 'checkpoint_path' summary for global step 2137: /content/trained_output/model.ckpt-2137\n","INFO:tensorflow:evaluation_loop marked as finished\n","INFO:tensorflow:***** Eval results *****\n","INFO:tensorflow:  eval_accuracy = 0.6912752\n","INFO:tensorflow:  eval_loss = 0.63406587\n","INFO:tensorflow:  global_step = 2137\n","INFO:tensorflow:  loss = 0.63434684\n"]}],"source":["%cd /content/drive/MyDrive/Code_pretrain\n","%pwd\n","%env BERT_BASE_DIR=uncased_L-4_H-256_A-4\n","%env GLUE_DIR=data\n","!rm -rf /content/trained_output\n","\n","!python3 run_classifier.py \\\n","  --task_name=CoLA \\\n","  --do_train=true \\\n","  --do_eval=true \\\n","  --data_dir=$GLUE_DIR/CoLA \\\n","  --vocab_file=$BERT_BASE_DIR/vocab.txt \\\n","  --bert_config_file=$BERT_BASE_DIR/bert_config.json \\\n","  --init_checkpoint=$BERT_BASE_DIR/bert_model.ckpt \\\n","  --max_seq_length=128 \\\n","  --train_batch_size=4 \\\n","  --learning_rate=2e-5 \\\n","  --num_train_epochs=1.0 \\\n","  --output_dir=/content/trained_output\n","\n","# result metric.\n","# INFO:tensorflow:***** Eval results *****\n","# INFO:tensorflow:  eval_accuracy = 0.6912752\n","# INFO:tensorflow:  eval_loss = 0.6332376\n","# INFO:tensorflow:  global_step = 2137\n","# INFO:tensorflow:  loss = 0.63339067\n","\n","# INFO:tensorflow:  eval_accuracy = 0.6912752\n","# INFO:tensorflow:  eval_loss = 0.63406587\n","# INFO:tensorflow:  global_step = 2137\n","# INFO:tensorflow:  loss = 0.63434684"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":164368,"status":"ok","timestamp":1684737049146,"user":{"displayName":"Brian Shen","userId":"08246478872294528508"},"user_tz":-480},"id":"aNnVMJOKbbvd","outputId":"c07e05c7-1194-407e-9eb7-70381efe2a3a"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Code_pretrain\n","env: BERT_BASE_DIR=uncased_L-4_H-256_A-4\n","env: GLUE_DIR=data\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n","\n","WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n","For more information, please see:\n","  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n","  * https://github.com/tensorflow/addons\n","If you depend on functionality not listed there, please file an issue.\n","\n","WARNING:tensorflow:Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f909fd3f2f0>) includes params argument, but params are not passed to Estimator.\n","INFO:tensorflow:Using config: {'_model_dir': '/content/trained_output', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 1000, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n","graph_options {\n","  rewrite_options {\n","    meta_optimizer_iterations: ONE\n","  }\n","}\n",", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f909edeaa20>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=1000, num_shards=8, num_cores_per_replica=None, per_host_input_for_training=3, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None), '_cluster': None}\n","INFO:tensorflow:_TPUContext: eval_on_tpu True\n","WARNING:tensorflow:eval_on_tpu ignored because use_tpu is False.\n","INFO:tensorflow:Writing example 0 of 67349\n","INFO:tensorflow:*** Example ***\n","INFO:tensorflow:guid: train-1\n","INFO:tensorflow:tokens: [CLS] hide new secret ##ions from the parental units [SEP]\n","INFO:tensorflow:input_ids: 101 5342 2047 3595 8496 2013 1996 18643 3197 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:label: 0 (id = 0)\n","INFO:tensorflow:*** Example ***\n","INFO:tensorflow:guid: train-2\n","INFO:tensorflow:tokens: [CLS] contains no wit , only labor ##ed gag ##s [SEP]\n","INFO:tensorflow:input_ids: 101 3397 2053 15966 1010 2069 4450 2098 18201 2015 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:label: 0 (id = 0)\n","INFO:tensorflow:*** Example ***\n","INFO:tensorflow:guid: train-3\n","INFO:tensorflow:tokens: [CLS] that loves its characters and communicate ##s something rather beautiful about human nature [SEP]\n","INFO:tensorflow:input_ids: 101 2008 7459 2049 3494 1998 10639 2015 2242 2738 3376 2055 2529 3267 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:label: 1 (id = 1)\n","INFO:tensorflow:*** Example ***\n","INFO:tensorflow:guid: train-4\n","INFO:tensorflow:tokens: [CLS] remains utterly satisfied to remain the same throughout [SEP]\n","INFO:tensorflow:input_ids: 101 3464 12580 8510 2000 3961 1996 2168 2802 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:label: 0 (id = 0)\n","INFO:tensorflow:*** Example ***\n","INFO:tensorflow:guid: train-5\n","INFO:tensorflow:tokens: [CLS] on the worst revenge - of - the - ne ##rds cl ##iche ##s the filmmakers could dr ##edge up [SEP]\n","INFO:tensorflow:input_ids: 101 2006 1996 5409 7195 1011 1997 1011 1996 1011 11265 17811 18856 17322 2015 1996 16587 2071 2852 24225 2039 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:label: 0 (id = 0)\n","INFO:tensorflow:Writing example 10000 of 67349\n","INFO:tensorflow:Writing example 20000 of 67349\n","INFO:tensorflow:Writing example 30000 of 67349\n","INFO:tensorflow:Writing example 40000 of 67349\n","INFO:tensorflow:Writing example 50000 of 67349\n","INFO:tensorflow:Writing example 60000 of 67349\n","INFO:tensorflow:***** Running training *****\n","INFO:tensorflow:  Num examples = 67349\n","INFO:tensorflow:  Batch size = 4\n","INFO:tensorflow:  Num steps = 16837\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Colocations handled automatically by placer.\n","WARNING:tensorflow:From run_classifier.py:890: map_and_batch (from tensorflow.contrib.data.python.ops.batching) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.experimental.map_and_batch(...)`.\n","WARNING:tensorflow:From run_classifier.py:870: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.cast instead.\n","INFO:tensorflow:Calling model_fn.\n","INFO:tensorflow:Running train on CPU\n","INFO:tensorflow:*** Features ***\n","INFO:tensorflow:  name = input_ids, shape = (4, 128)\n","INFO:tensorflow:  name = input_mask, shape = (4, 128)\n","INFO:tensorflow:  name = is_real_example, shape = (4,)\n","INFO:tensorflow:  name = label_ids, shape = (4,)\n","INFO:tensorflow:  name = segment_ids, shape = (4, 128)\n","WARNING:tensorflow:From /content/drive/MyDrive/Code_pretrain/modeling.py:358: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n","WARNING:tensorflow:From /content/drive/MyDrive/Code_pretrain/modeling.py:671: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use keras.layers.dense instead.\n","INFO:tensorflow:**** Trainable Variables ****\n","INFO:tensorflow:  name = bert/embeddings/word_embeddings:0, shape = (30522, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/embeddings/token_type_embeddings:0, shape = (2, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/embeddings/position_embeddings:0, shape = (512, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/embeddings/LayerNorm/beta:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/embeddings/LayerNorm/gamma:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/query/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/query/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/key/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/key/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/value/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/value/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/dense/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/dense/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/LayerNorm/beta:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/LayerNorm/gamma:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/intermediate/dense/kernel:0, shape = (256, 1024), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/intermediate/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/output/dense/kernel:0, shape = (1024, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/output/dense/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/output/LayerNorm/beta:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/output/LayerNorm/gamma:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/query/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/query/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/key/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/key/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/value/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/value/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/dense/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/dense/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/LayerNorm/beta:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/LayerNorm/gamma:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/intermediate/dense/kernel:0, shape = (256, 1024), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/intermediate/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/output/dense/kernel:0, shape = (1024, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/output/dense/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/output/LayerNorm/beta:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/output/LayerNorm/gamma:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/query/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/query/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/key/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/key/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/value/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/value/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/dense/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/dense/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/LayerNorm/beta:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/LayerNorm/gamma:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/intermediate/dense/kernel:0, shape = (256, 1024), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/intermediate/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/output/dense/kernel:0, shape = (1024, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/output/dense/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/output/LayerNorm/beta:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/output/LayerNorm/gamma:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/query/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/query/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/key/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/key/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/value/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/value/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/dense/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/dense/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/LayerNorm/beta:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/LayerNorm/gamma:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/intermediate/dense/kernel:0, shape = (256, 1024), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/intermediate/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/output/dense/kernel:0, shape = (1024, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/output/dense/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/output/LayerNorm/beta:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/output/LayerNorm/gamma:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/pooler/dense/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/pooler/dense/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = output_weights:0, shape = (2, 256)\n","INFO:tensorflow:  name = output_bias:0, shape = (2,)\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/learning_rate_decay_v2.py:321: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Deprecated in favor of operator or tf.math.divide.\n","INFO:tensorflow:Done calling model_fn.\n","INFO:tensorflow:Create CheckpointSaverHook.\n","INFO:tensorflow:Graph was finalized.\n","2023-05-22 06:24:54.313986: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA\n","2023-05-22 06:24:54.413347: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2023-05-22 06:24:54.413649: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x653fc30 executing computations on platform CUDA. Devices:\n","2023-05-22 06:24:54.413680: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n","2023-05-22 06:24:54.415690: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2000185000 Hz\n","2023-05-22 06:24:54.415867: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x3730a60 executing computations on platform Host. Devices:\n","2023-05-22 06:24:54.415898: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>\n","2023-05-22 06:24:54.416042: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 0 with properties: \n","name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n","pciBusID: 0000:00:04.0\n","totalMemory: 14.75GiB freeMemory: 14.65GiB\n","2023-05-22 06:24:54.416068: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0\n","2023-05-22 06:24:54.416344: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2023-05-22 06:24:54.416363: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0 \n","2023-05-22 06:24:54.416372: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N \n","2023-05-22 06:24:54.416424: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","2023-05-22 06:24:54.416483: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14248 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n","INFO:tensorflow:Running local_init_op.\n","INFO:tensorflow:Done running local_init_op.\n","INFO:tensorflow:Saving checkpoints for 0 into /content/trained_output/model.ckpt.\n","2023-05-22 06:25:00.114394: I tensorflow/stream_executor/dso_loader.cc:152] successfully opened CUDA library libcublas.so.10.0 locally\n","INFO:tensorflow:global_step/sec: 27.0832\n","INFO:tensorflow:examples/sec: 108.333\n","INFO:tensorflow:global_step/sec: 49.3145\n","INFO:tensorflow:examples/sec: 197.258\n","INFO:tensorflow:global_step/sec: 52.507\n","INFO:tensorflow:examples/sec: 210.028\n","INFO:tensorflow:global_step/sec: 53.4762\n","INFO:tensorflow:examples/sec: 213.905\n","INFO:tensorflow:global_step/sec: 53.0425\n","INFO:tensorflow:examples/sec: 212.17\n","INFO:tensorflow:global_step/sec: 53.2484\n","INFO:tensorflow:examples/sec: 212.993\n","INFO:tensorflow:global_step/sec: 53.0382\n","INFO:tensorflow:examples/sec: 212.153\n","INFO:tensorflow:global_step/sec: 51.0605\n","INFO:tensorflow:examples/sec: 204.242\n","INFO:tensorflow:global_step/sec: 48.9169\n","INFO:tensorflow:examples/sec: 195.668\n","INFO:tensorflow:Saving checkpoints for 1000 into /content/trained_output/model.ckpt.\n","INFO:tensorflow:global_step/sec: 36.8065\n","INFO:tensorflow:examples/sec: 147.226\n","INFO:tensorflow:global_step/sec: 49.7114\n","INFO:tensorflow:examples/sec: 198.845\n","INFO:tensorflow:global_step/sec: 52.6969\n","INFO:tensorflow:examples/sec: 210.788\n","INFO:tensorflow:global_step/sec: 52.7516\n","INFO:tensorflow:examples/sec: 211.006\n","INFO:tensorflow:global_step/sec: 52.3374\n","INFO:tensorflow:examples/sec: 209.35\n","INFO:tensorflow:global_step/sec: 52.6341\n","INFO:tensorflow:examples/sec: 210.536\n","INFO:tensorflow:global_step/sec: 52.0711\n","INFO:tensorflow:examples/sec: 208.285\n","INFO:tensorflow:global_step/sec: 49.3879\n","INFO:tensorflow:examples/sec: 197.552\n","INFO:tensorflow:global_step/sec: 49.4584\n","INFO:tensorflow:examples/sec: 197.834\n","INFO:tensorflow:global_step/sec: 48.4915\n","INFO:tensorflow:examples/sec: 193.966\n","INFO:tensorflow:Saving checkpoints for 2000 into /content/trained_output/model.ckpt.\n","INFO:tensorflow:global_step/sec: 39.6211\n","INFO:tensorflow:examples/sec: 158.484\n","INFO:tensorflow:global_step/sec: 52.4218\n","INFO:tensorflow:examples/sec: 209.687\n","INFO:tensorflow:global_step/sec: 52.1574\n","INFO:tensorflow:examples/sec: 208.63\n","INFO:tensorflow:global_step/sec: 52.1195\n","INFO:tensorflow:examples/sec: 208.478\n","INFO:tensorflow:global_step/sec: 52.1062\n","INFO:tensorflow:examples/sec: 208.425\n","INFO:tensorflow:global_step/sec: 51.2795\n","INFO:tensorflow:examples/sec: 205.118\n","INFO:tensorflow:global_step/sec: 49.3947\n","INFO:tensorflow:examples/sec: 197.579\n","INFO:tensorflow:global_step/sec: 48.9292\n","INFO:tensorflow:examples/sec: 195.717\n","INFO:tensorflow:global_step/sec: 48.5209\n","INFO:tensorflow:examples/sec: 194.084\n","INFO:tensorflow:global_step/sec: 50.6515\n","INFO:tensorflow:examples/sec: 202.606\n","INFO:tensorflow:Saving checkpoints for 3000 into /content/trained_output/model.ckpt.\n","INFO:tensorflow:global_step/sec: 41.8576\n","INFO:tensorflow:examples/sec: 167.43\n","INFO:tensorflow:global_step/sec: 52.5864\n","INFO:tensorflow:examples/sec: 210.345\n","INFO:tensorflow:global_step/sec: 52.4706\n","INFO:tensorflow:examples/sec: 209.882\n","INFO:tensorflow:global_step/sec: 52.3975\n","INFO:tensorflow:examples/sec: 209.59\n","INFO:tensorflow:global_step/sec: 51.1635\n","INFO:tensorflow:examples/sec: 204.654\n","INFO:tensorflow:global_step/sec: 48.7088\n","INFO:tensorflow:examples/sec: 194.835\n","INFO:tensorflow:global_step/sec: 49.1264\n","INFO:tensorflow:examples/sec: 196.506\n","INFO:tensorflow:global_step/sec: 48.8948\n","INFO:tensorflow:examples/sec: 195.579\n","INFO:tensorflow:global_step/sec: 51.3259\n","INFO:tensorflow:examples/sec: 205.304\n","INFO:tensorflow:global_step/sec: 52.5312\n","INFO:tensorflow:examples/sec: 210.125\n","INFO:tensorflow:Saving checkpoints for 4000 into /content/trained_output/model.ckpt.\n","INFO:tensorflow:global_step/sec: 42.2619\n","INFO:tensorflow:examples/sec: 169.047\n","INFO:tensorflow:global_step/sec: 52.1516\n","INFO:tensorflow:examples/sec: 208.606\n","INFO:tensorflow:global_step/sec: 52.6243\n","INFO:tensorflow:examples/sec: 210.497\n","INFO:tensorflow:global_step/sec: 50.552\n","INFO:tensorflow:examples/sec: 202.208\n","INFO:tensorflow:global_step/sec: 49.2653\n","INFO:tensorflow:examples/sec: 197.061\n","INFO:tensorflow:global_step/sec: 49.4108\n","INFO:tensorflow:examples/sec: 197.643\n","INFO:tensorflow:global_step/sec: 48.9405\n","INFO:tensorflow:examples/sec: 195.762\n","INFO:tensorflow:global_step/sec: 52.2114\n","INFO:tensorflow:examples/sec: 208.846\n","INFO:tensorflow:global_step/sec: 52.8424\n","INFO:tensorflow:examples/sec: 211.37\n","INFO:tensorflow:global_step/sec: 52.5723\n","INFO:tensorflow:examples/sec: 210.289\n","INFO:tensorflow:Saving checkpoints for 5000 into /content/trained_output/model.ckpt.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:966: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use standard file APIs to delete files with this prefix.\n","INFO:tensorflow:global_step/sec: 41.8572\n","INFO:tensorflow:examples/sec: 167.429\n","INFO:tensorflow:global_step/sec: 52.9214\n","INFO:tensorflow:examples/sec: 211.685\n","INFO:tensorflow:global_step/sec: 49.5289\n","INFO:tensorflow:examples/sec: 198.116\n","INFO:tensorflow:global_step/sec: 48.9219\n","INFO:tensorflow:examples/sec: 195.688\n","INFO:tensorflow:global_step/sec: 49.1348\n","INFO:tensorflow:examples/sec: 196.539\n","INFO:tensorflow:global_step/sec: 49.4533\n","INFO:tensorflow:examples/sec: 197.813\n","INFO:tensorflow:global_step/sec: 52.5389\n","INFO:tensorflow:examples/sec: 210.156\n","INFO:tensorflow:global_step/sec: 52.6136\n","INFO:tensorflow:examples/sec: 210.454\n","INFO:tensorflow:global_step/sec: 52.6353\n","INFO:tensorflow:examples/sec: 210.541\n","INFO:tensorflow:global_step/sec: 52.4652\n","INFO:tensorflow:examples/sec: 209.861\n","INFO:tensorflow:Saving checkpoints for 6000 into /content/trained_output/model.ckpt.\n","INFO:tensorflow:global_step/sec: 38.5378\n","INFO:tensorflow:examples/sec: 154.151\n","INFO:tensorflow:global_step/sec: 49.6112\n","INFO:tensorflow:examples/sec: 198.445\n","INFO:tensorflow:global_step/sec: 49.4517\n","INFO:tensorflow:examples/sec: 197.807\n","INFO:tensorflow:global_step/sec: 49.4943\n","INFO:tensorflow:examples/sec: 197.977\n","INFO:tensorflow:global_step/sec: 51.1105\n","INFO:tensorflow:examples/sec: 204.442\n","INFO:tensorflow:global_step/sec: 52.6793\n","INFO:tensorflow:examples/sec: 210.717\n","INFO:tensorflow:global_step/sec: 52.3265\n","INFO:tensorflow:examples/sec: 209.306\n","INFO:tensorflow:global_step/sec: 52.4892\n","INFO:tensorflow:examples/sec: 209.957\n","INFO:tensorflow:global_step/sec: 52.3498\n","INFO:tensorflow:examples/sec: 209.399\n","INFO:tensorflow:global_step/sec: 52.0119\n","INFO:tensorflow:examples/sec: 208.048\n","INFO:tensorflow:Saving checkpoints for 7000 into /content/trained_output/model.ckpt.\n","INFO:tensorflow:global_step/sec: 36.3816\n","INFO:tensorflow:examples/sec: 145.527\n","INFO:tensorflow:global_step/sec: 49.7355\n","INFO:tensorflow:examples/sec: 198.942\n","INFO:tensorflow:global_step/sec: 48.8478\n","INFO:tensorflow:examples/sec: 195.391\n","INFO:tensorflow:global_step/sec: 51.3162\n","INFO:tensorflow:examples/sec: 205.265\n","INFO:tensorflow:global_step/sec: 52.8078\n","INFO:tensorflow:examples/sec: 211.231\n","INFO:tensorflow:global_step/sec: 52.6435\n","INFO:tensorflow:examples/sec: 210.574\n","INFO:tensorflow:global_step/sec: 52.3\n","INFO:tensorflow:examples/sec: 209.2\n","INFO:tensorflow:global_step/sec: 52.3842\n","INFO:tensorflow:examples/sec: 209.537\n","INFO:tensorflow:global_step/sec: 50.4705\n","INFO:tensorflow:examples/sec: 201.882\n","INFO:tensorflow:global_step/sec: 48.5078\n","INFO:tensorflow:examples/sec: 194.031\n","INFO:tensorflow:Saving checkpoints for 8000 into /content/trained_output/model.ckpt.\n","INFO:tensorflow:global_step/sec: 35.9216\n","INFO:tensorflow:examples/sec: 143.687\n","INFO:tensorflow:global_step/sec: 49.7269\n","INFO:tensorflow:examples/sec: 198.908\n","INFO:tensorflow:global_step/sec: 52.677\n","INFO:tensorflow:examples/sec: 210.708\n","INFO:tensorflow:global_step/sec: 52.619\n","INFO:tensorflow:examples/sec: 210.476\n","INFO:tensorflow:global_step/sec: 52.5211\n","INFO:tensorflow:examples/sec: 210.084\n","INFO:tensorflow:global_step/sec: 52.4842\n","INFO:tensorflow:examples/sec: 209.937\n","INFO:tensorflow:global_step/sec: 52.5195\n","INFO:tensorflow:examples/sec: 210.078\n","INFO:tensorflow:global_step/sec: 49.046\n","INFO:tensorflow:examples/sec: 196.184\n","INFO:tensorflow:global_step/sec: 49.0701\n","INFO:tensorflow:examples/sec: 196.28\n","INFO:tensorflow:global_step/sec: 49.1856\n","INFO:tensorflow:examples/sec: 196.742\n","INFO:tensorflow:Saving checkpoints for 9000 into /content/trained_output/model.ckpt.\n","INFO:tensorflow:global_step/sec: 39.9273\n","INFO:tensorflow:examples/sec: 159.709\n","INFO:tensorflow:global_step/sec: 52.8266\n","INFO:tensorflow:examples/sec: 211.306\n","INFO:tensorflow:global_step/sec: 52.6657\n","INFO:tensorflow:examples/sec: 210.663\n","INFO:tensorflow:global_step/sec: 52.5372\n","INFO:tensorflow:examples/sec: 210.149\n","INFO:tensorflow:global_step/sec: 52.7244\n","INFO:tensorflow:examples/sec: 210.898\n","INFO:tensorflow:global_step/sec: 51.8647\n","INFO:tensorflow:examples/sec: 207.459\n","INFO:tensorflow:global_step/sec: 49.0101\n","INFO:tensorflow:examples/sec: 196.04\n","INFO:tensorflow:global_step/sec: 49.2651\n","INFO:tensorflow:examples/sec: 197.06\n","INFO:tensorflow:global_step/sec: 49.3681\n","INFO:tensorflow:examples/sec: 197.472\n","INFO:tensorflow:global_step/sec: 50.7788\n","INFO:tensorflow:examples/sec: 203.115\n","INFO:tensorflow:Saving checkpoints for 10000 into /content/trained_output/model.ckpt.\n","INFO:tensorflow:global_step/sec: 41.968\n","INFO:tensorflow:examples/sec: 167.872\n","INFO:tensorflow:global_step/sec: 52.7189\n","INFO:tensorflow:examples/sec: 210.875\n","INFO:tensorflow:global_step/sec: 52.6144\n","INFO:tensorflow:examples/sec: 210.458\n","INFO:tensorflow:global_step/sec: 52.4225\n","INFO:tensorflow:examples/sec: 209.69\n","INFO:tensorflow:global_step/sec: 50.8232\n","INFO:tensorflow:examples/sec: 203.293\n","INFO:tensorflow:global_step/sec: 49.6466\n","INFO:tensorflow:examples/sec: 198.587\n","INFO:tensorflow:global_step/sec: 48.9629\n","INFO:tensorflow:examples/sec: 195.852\n","INFO:tensorflow:global_step/sec: 49.024\n","INFO:tensorflow:examples/sec: 196.096\n","INFO:tensorflow:global_step/sec: 52.0097\n","INFO:tensorflow:examples/sec: 208.039\n","INFO:tensorflow:global_step/sec: 52.2848\n","INFO:tensorflow:examples/sec: 209.139\n","INFO:tensorflow:Saving checkpoints for 11000 into /content/trained_output/model.ckpt.\n","INFO:tensorflow:global_step/sec: 42.28\n","INFO:tensorflow:examples/sec: 169.12\n","INFO:tensorflow:global_step/sec: 52.3809\n","INFO:tensorflow:examples/sec: 209.524\n","INFO:tensorflow:global_step/sec: 52.5384\n","INFO:tensorflow:examples/sec: 210.154\n","INFO:tensorflow:global_step/sec: 49.6825\n","INFO:tensorflow:examples/sec: 198.73\n","INFO:tensorflow:global_step/sec: 48.9617\n","INFO:tensorflow:examples/sec: 195.847\n","INFO:tensorflow:global_step/sec: 48.938\n","INFO:tensorflow:examples/sec: 195.752\n","INFO:tensorflow:global_step/sec: 50.1358\n","INFO:tensorflow:examples/sec: 200.543\n","INFO:tensorflow:global_step/sec: 52.5934\n","INFO:tensorflow:examples/sec: 210.374\n","INFO:tensorflow:global_step/sec: 52.5008\n","INFO:tensorflow:examples/sec: 210.003\n","INFO:tensorflow:global_step/sec: 52.2961\n","INFO:tensorflow:examples/sec: 209.184\n","INFO:tensorflow:Saving checkpoints for 12000 into /content/trained_output/model.ckpt.\n","INFO:tensorflow:global_step/sec: 42.2287\n","INFO:tensorflow:examples/sec: 168.915\n","INFO:tensorflow:global_step/sec: 51.2044\n","INFO:tensorflow:examples/sec: 204.818\n","INFO:tensorflow:global_step/sec: 47.749\n","INFO:tensorflow:examples/sec: 190.996\n","INFO:tensorflow:global_step/sec: 48.5831\n","INFO:tensorflow:examples/sec: 194.332\n","INFO:tensorflow:global_step/sec: 48.9867\n","INFO:tensorflow:examples/sec: 195.947\n","INFO:tensorflow:global_step/sec: 49.895\n","INFO:tensorflow:examples/sec: 199.58\n","INFO:tensorflow:global_step/sec: 52.2462\n","INFO:tensorflow:examples/sec: 208.985\n","INFO:tensorflow:global_step/sec: 52.5743\n","INFO:tensorflow:examples/sec: 210.297\n","INFO:tensorflow:global_step/sec: 52.5381\n","INFO:tensorflow:examples/sec: 210.153\n","INFO:tensorflow:global_step/sec: 52.5766\n","INFO:tensorflow:examples/sec: 210.306\n","INFO:tensorflow:Saving checkpoints for 13000 into /content/trained_output/model.ckpt.\n","INFO:tensorflow:global_step/sec: 35.6469\n","INFO:tensorflow:examples/sec: 142.587\n","INFO:tensorflow:global_step/sec: 46.0435\n","INFO:tensorflow:examples/sec: 184.174\n","INFO:tensorflow:global_step/sec: 45.4445\n","INFO:tensorflow:examples/sec: 181.778\n","INFO:tensorflow:global_step/sec: 47.1986\n","INFO:tensorflow:examples/sec: 188.794\n","INFO:tensorflow:global_step/sec: 51.2238\n","INFO:tensorflow:examples/sec: 204.895\n","INFO:tensorflow:global_step/sec: 51.6757\n","INFO:tensorflow:examples/sec: 206.703\n","INFO:tensorflow:global_step/sec: 51.3076\n","INFO:tensorflow:examples/sec: 205.23\n","INFO:tensorflow:global_step/sec: 51.3825\n","INFO:tensorflow:examples/sec: 205.53\n","INFO:tensorflow:global_step/sec: 52.3274\n","INFO:tensorflow:examples/sec: 209.31\n","INFO:tensorflow:global_step/sec: 49.4653\n","INFO:tensorflow:examples/sec: 197.861\n","INFO:tensorflow:Saving checkpoints for 14000 into /content/trained_output/model.ckpt.\n","INFO:tensorflow:global_step/sec: 34.7316\n","INFO:tensorflow:examples/sec: 138.926\n","INFO:tensorflow:global_step/sec: 44.5682\n","INFO:tensorflow:examples/sec: 178.273\n","INFO:tensorflow:global_step/sec: 46.3928\n","INFO:tensorflow:examples/sec: 185.571\n","INFO:tensorflow:global_step/sec: 49.8571\n","INFO:tensorflow:examples/sec: 199.428\n","INFO:tensorflow:global_step/sec: 50.1795\n","INFO:tensorflow:examples/sec: 200.718\n","INFO:tensorflow:global_step/sec: 50.1558\n","INFO:tensorflow:examples/sec: 200.623\n","INFO:tensorflow:global_step/sec: 50.4294\n","INFO:tensorflow:examples/sec: 201.718\n","INFO:tensorflow:global_step/sec: 48.9174\n","INFO:tensorflow:examples/sec: 195.67\n","INFO:tensorflow:global_step/sec: 45.1963\n","INFO:tensorflow:examples/sec: 180.785\n","INFO:tensorflow:global_step/sec: 47.3809\n","INFO:tensorflow:examples/sec: 189.524\n","INFO:tensorflow:Saving checkpoints for 15000 into /content/trained_output/model.ckpt.\n","INFO:tensorflow:global_step/sec: 35.9926\n","INFO:tensorflow:examples/sec: 143.97\n","INFO:tensorflow:global_step/sec: 52.2248\n","INFO:tensorflow:examples/sec: 208.899\n","INFO:tensorflow:global_step/sec: 52.5308\n","INFO:tensorflow:examples/sec: 210.123\n","INFO:tensorflow:global_step/sec: 52.4753\n","INFO:tensorflow:examples/sec: 209.901\n","INFO:tensorflow:global_step/sec: 52.7391\n","INFO:tensorflow:examples/sec: 210.956\n","INFO:tensorflow:global_step/sec: 52.1296\n","INFO:tensorflow:examples/sec: 208.518\n","INFO:tensorflow:global_step/sec: 50.4818\n","INFO:tensorflow:examples/sec: 201.927\n","INFO:tensorflow:global_step/sec: 49.2953\n","INFO:tensorflow:examples/sec: 197.181\n","INFO:tensorflow:global_step/sec: 48.65\n","INFO:tensorflow:examples/sec: 194.6\n","INFO:tensorflow:global_step/sec: 48.3421\n","INFO:tensorflow:examples/sec: 193.369\n","INFO:tensorflow:Saving checkpoints for 16000 into /content/trained_output/model.ckpt.\n","INFO:tensorflow:global_step/sec: 41.8936\n","INFO:tensorflow:examples/sec: 167.574\n","INFO:tensorflow:global_step/sec: 52.436\n","INFO:tensorflow:examples/sec: 209.744\n","INFO:tensorflow:global_step/sec: 52.4591\n","INFO:tensorflow:examples/sec: 209.836\n","INFO:tensorflow:global_step/sec: 52.4385\n","INFO:tensorflow:examples/sec: 209.754\n","INFO:tensorflow:global_step/sec: 52.439\n","INFO:tensorflow:examples/sec: 209.756\n","INFO:tensorflow:global_step/sec: 49.1732\n","INFO:tensorflow:examples/sec: 196.693\n","INFO:tensorflow:global_step/sec: 48.6815\n","INFO:tensorflow:examples/sec: 194.726\n","INFO:tensorflow:global_step/sec: 49.3411\n","INFO:tensorflow:examples/sec: 197.364\n","INFO:tensorflow:global_step/sec: 49.2637\n","INFO:tensorflow:examples/sec: 197.055\n","INFO:tensorflow:Saving checkpoints for 16837 into /content/trained_output/model.ckpt.\n","INFO:tensorflow:Loss for final step: 0.023414904.\n","INFO:tensorflow:training_loop marked as finished\n","INFO:tensorflow:Writing example 0 of 872\n","INFO:tensorflow:*** Example ***\n","INFO:tensorflow:guid: dev-1\n","INFO:tensorflow:tokens: [CLS] it ' s a charming and often affecting journey . [SEP]\n","INFO:tensorflow:input_ids: 101 2009 1005 1055 1037 11951 1998 2411 12473 4990 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:label: 1 (id = 1)\n","INFO:tensorflow:*** Example ***\n","INFO:tensorflow:guid: dev-2\n","INFO:tensorflow:tokens: [CLS] un ##fl ##in ##ching ##ly bleak and desperate [SEP]\n","INFO:tensorflow:input_ids: 101 4895 10258 2378 8450 2135 21657 1998 7143 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:label: 0 (id = 0)\n","INFO:tensorflow:*** Example ***\n","INFO:tensorflow:guid: dev-3\n","INFO:tensorflow:tokens: [CLS] allows us to hope that nolan is poised to embark a major career as a commercial yet in ##vent ##ive filmmaker . [SEP]\n","INFO:tensorflow:input_ids: 101 4473 2149 2000 3246 2008 13401 2003 22303 2000 28866 1037 2350 2476 2004 1037 3293 2664 1999 15338 3512 12127 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:label: 1 (id = 1)\n","INFO:tensorflow:*** Example ***\n","INFO:tensorflow:guid: dev-4\n","INFO:tensorflow:tokens: [CLS] the acting , costumes , music , cinematography and sound are all as ##tou ##nding given the production ' s aus ##ter ##e local ##es . [SEP]\n","INFO:tensorflow:input_ids: 101 1996 3772 1010 12703 1010 2189 1010 16434 1998 2614 2024 2035 2004 24826 15683 2445 1996 2537 1005 1055 17151 3334 2063 2334 2229 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:label: 1 (id = 1)\n","INFO:tensorflow:*** Example ***\n","INFO:tensorflow:guid: dev-5\n","INFO:tensorflow:tokens: [CLS] it ' s slow - - very , very slow . [SEP]\n","INFO:tensorflow:input_ids: 101 2009 1005 1055 4030 1011 1011 2200 1010 2200 4030 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:label: 0 (id = 0)\n","INFO:tensorflow:***** Running evaluation *****\n","INFO:tensorflow:  Num examples = 872 (872 actual, 0 padding)\n","INFO:tensorflow:  Batch size = 8\n","INFO:tensorflow:Calling model_fn.\n","INFO:tensorflow:Running eval on CPU\n","INFO:tensorflow:*** Features ***\n","INFO:tensorflow:  name = input_ids, shape = (?, 128)\n","INFO:tensorflow:  name = input_mask, shape = (?, 128)\n","INFO:tensorflow:  name = is_real_example, shape = (?,)\n","INFO:tensorflow:  name = label_ids, shape = (?,)\n","INFO:tensorflow:  name = segment_ids, shape = (?, 128)\n","INFO:tensorflow:**** Trainable Variables ****\n","INFO:tensorflow:  name = bert/embeddings/word_embeddings:0, shape = (30522, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/embeddings/token_type_embeddings:0, shape = (2, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/embeddings/position_embeddings:0, shape = (512, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/embeddings/LayerNorm/beta:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/embeddings/LayerNorm/gamma:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/query/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/query/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/key/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/key/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/value/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/value/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/dense/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/dense/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/LayerNorm/beta:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/LayerNorm/gamma:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/intermediate/dense/kernel:0, shape = (256, 1024), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/intermediate/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/output/dense/kernel:0, shape = (1024, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/output/dense/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/output/LayerNorm/beta:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/output/LayerNorm/gamma:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/query/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/query/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/key/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/key/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/value/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/value/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/dense/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/dense/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/LayerNorm/beta:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/LayerNorm/gamma:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/intermediate/dense/kernel:0, shape = (256, 1024), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/intermediate/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/output/dense/kernel:0, shape = (1024, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/output/dense/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/output/LayerNorm/beta:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/output/LayerNorm/gamma:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/query/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/query/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/key/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/key/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/value/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/value/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/dense/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/dense/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/LayerNorm/beta:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/LayerNorm/gamma:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/intermediate/dense/kernel:0, shape = (256, 1024), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/intermediate/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/output/dense/kernel:0, shape = (1024, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/output/dense/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/output/LayerNorm/beta:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/output/LayerNorm/gamma:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/query/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/query/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/key/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/key/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/value/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/value/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/dense/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/dense/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/LayerNorm/beta:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/LayerNorm/gamma:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/intermediate/dense/kernel:0, shape = (256, 1024), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/intermediate/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/output/dense/kernel:0, shape = (1024, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/output/dense/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/output/LayerNorm/beta:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/output/LayerNorm/gamma:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/pooler/dense/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/pooler/dense/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = output_weights:0, shape = (2, 256)\n","INFO:tensorflow:  name = output_bias:0, shape = (2,)\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/metrics_impl.py:455: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.cast instead.\n","INFO:tensorflow:Done calling model_fn.\n","INFO:tensorflow:Starting evaluation at 2023-05-22T06:30:46Z\n","INFO:tensorflow:Graph was finalized.\n","2023-05-22 06:30:46.527574: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0\n","2023-05-22 06:30:46.527663: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2023-05-22 06:30:46.527679: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0 \n","2023-05-22 06:30:46.527691: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N \n","2023-05-22 06:30:46.527812: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14248 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use standard file APIs to check for files with this prefix.\n","INFO:tensorflow:Restoring parameters from /content/trained_output/model.ckpt-16837\n","INFO:tensorflow:Running local_init_op.\n","INFO:tensorflow:Done running local_init_op.\n","INFO:tensorflow:Finished evaluation at 2023-05-22-06:30:47\n","INFO:tensorflow:Saving dict for global step 16837: eval_accuracy = 0.83600914, eval_loss = 0.6130721, global_step = 16837, loss = 0.6130721\n","INFO:tensorflow:Saving 'checkpoint_path' summary for global step 16837: /content/trained_output/model.ckpt-16837\n","INFO:tensorflow:evaluation_loop marked as finished\n","INFO:tensorflow:***** Eval results *****\n","INFO:tensorflow:  eval_accuracy = 0.83600914\n","INFO:tensorflow:  eval_loss = 0.6130721\n","INFO:tensorflow:  global_step = 16837\n","INFO:tensorflow:  loss = 0.6130721\n"]}],"source":["%cd /content/drive/MyDrive/Code_pretrain\n","%pwd\n","%env BERT_BASE_DIR=uncased_L-4_H-256_A-4\n","%env GLUE_DIR=data\n","!rm -rf /content/trained_output\n","\n","!python3 run_classifier.py \\\n","  --task_name=SST-2 \\\n","  --do_train=true \\\n","  --do_eval=true \\\n","  --data_dir=$GLUE_DIR/SST-2 \\\n","  --vocab_file=$BERT_BASE_DIR/vocab.txt \\\n","  --bert_config_file=$BERT_BASE_DIR/bert_config.json \\\n","  --init_checkpoint=$BERT_BASE_DIR/bert_model.ckpt \\\n","  --max_seq_length=128 \\\n","  --train_batch_size=4 \\\n","  --learning_rate=2e-5 \\\n","  --num_train_epochs=1.0 \\\n","  --output_dir=/content/trained_output\n","\n","# result metric.\n","# INFO:tensorflow:  eval_accuracy = 0.7912844\n","# INFO:tensorflow:  eval_loss = 0.6541138\n","# INFO:tensorflow:  global_step = 16837\n","# INFO:tensorflow:  loss = 0.6541138\n","\n","# INFO:tensorflow:  eval_accuracy = 0.83600914\n","# INFO:tensorflow:  eval_loss = 0.6130721\n","# INFO:tensorflow:  global_step = 16837\n","# INFO:tensorflow:  loss = 0.6130721\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":45270,"status":"ok","timestamp":1684737094412,"user":{"displayName":"Brian Shen","userId":"08246478872294528508"},"user_tz":-480},"id":"svi4c43CgJMn","outputId":"86610de5-2223-44b9-a8af-28c128532d7e"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Code_pretrain\n","env: BERT_BASE_DIR=uncased_L-4_H-256_A-4\n","env: GLUE_DIR=data\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n","\n","WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n","For more information, please see:\n","  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n","  * https://github.com/tensorflow/addons\n","If you depend on functionality not listed there, please file an issue.\n","\n","WARNING:tensorflow:Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f40e6cf3620>) includes params argument, but params are not passed to Estimator.\n","INFO:tensorflow:Using config: {'_model_dir': '/content/trained_output', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 1000, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n","graph_options {\n","  rewrite_options {\n","    meta_optimizer_iterations: ONE\n","  }\n","}\n",", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f40e7251c18>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=1000, num_shards=8, num_cores_per_replica=None, per_host_input_for_training=3, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None), '_cluster': None}\n","INFO:tensorflow:_TPUContext: eval_on_tpu True\n","WARNING:tensorflow:eval_on_tpu ignored because use_tpu is False.\n","INFO:tensorflow:Writing example 0 of 3668\n","INFO:tensorflow:*** Example ***\n","INFO:tensorflow:guid: train-1\n","INFO:tensorflow:tokens: [CLS] am ##ro ##zi accused his brother , whom he called \" the witness \" , of deliberately di ##stor ##ting his evidence . [SEP] referring to him as only \" the witness \" , am ##ro ##zi accused his brother of deliberately di ##stor ##ting his evidence . [SEP]\n","INFO:tensorflow:input_ids: 101 2572 3217 5831 5496 2010 2567 1010 3183 2002 2170 1000 1996 7409 1000 1010 1997 9969 4487 23809 3436 2010 3350 1012 102 7727 2000 2032 2004 2069 1000 1996 7409 1000 1010 2572 3217 5831 5496 2010 2567 1997 9969 4487 23809 3436 2010 3350 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:label: 1 (id = 1)\n","INFO:tensorflow:*** Example ***\n","INFO:tensorflow:guid: train-2\n","INFO:tensorflow:tokens: [CLS] yu ##ca ##ip ##a owned dominic ##k ' s before selling the chain to safe ##way in 1998 for $ 2 . 5 billion . [SEP] yu ##ca ##ip ##a bought dominic ##k ' s in 1995 for $ 69 ##3 million and sold it to safe ##way for $ 1 . 8 billion in 1998 . [SEP]\n","INFO:tensorflow:input_ids: 101 9805 3540 11514 2050 3079 11282 2243 1005 1055 2077 4855 1996 4677 2000 3647 4576 1999 2687 2005 1002 1016 1012 1019 4551 1012 102 9805 3540 11514 2050 4149 11282 2243 1005 1055 1999 2786 2005 1002 6353 2509 2454 1998 2853 2009 2000 3647 4576 2005 1002 1015 1012 1022 4551 1999 2687 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:label: 0 (id = 0)\n","INFO:tensorflow:*** Example ***\n","INFO:tensorflow:guid: train-3\n","INFO:tensorflow:tokens: [CLS] they had published an advertisement on the internet on june 10 , offering the cargo for sale , he added . [SEP] on june 10 , the ship ' s owners had published an advertisement on the internet , offering the explosives for sale . [SEP]\n","INFO:tensorflow:input_ids: 101 2027 2018 2405 2019 15147 2006 1996 4274 2006 2238 2184 1010 5378 1996 6636 2005 5096 1010 2002 2794 1012 102 2006 2238 2184 1010 1996 2911 1005 1055 5608 2018 2405 2019 15147 2006 1996 4274 1010 5378 1996 14792 2005 5096 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:label: 1 (id = 1)\n","INFO:tensorflow:*** Example ***\n","INFO:tensorflow:guid: train-4\n","INFO:tensorflow:tokens: [CLS] around 03 ##35 gm ##t , tab shares were up 19 cents , or 4 . 4 % , at a $ 4 . 56 , having earlier set a record high of a $ 4 . 57 . [SEP] tab shares jumped 20 cents , or 4 . 6 % , to set a record closing high at a $ 4 . 57 . [SEP]\n","INFO:tensorflow:input_ids: 101 2105 6021 19481 13938 2102 1010 21628 6661 2020 2039 2539 16653 1010 2030 1018 1012 1018 1003 1010 2012 1037 1002 1018 1012 5179 1010 2383 3041 2275 1037 2501 2152 1997 1037 1002 1018 1012 5401 1012 102 21628 6661 5598 2322 16653 1010 2030 1018 1012 1020 1003 1010 2000 2275 1037 2501 5494 2152 2012 1037 1002 1018 1012 5401 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:label: 0 (id = 0)\n","INFO:tensorflow:*** Example ***\n","INFO:tensorflow:guid: train-5\n","INFO:tensorflow:tokens: [CLS] the stock rose $ 2 . 11 , or about 11 percent , to close friday at $ 21 . 51 on the new york stock exchange . [SEP] pg & e corp . shares jumped $ 1 . 63 or 8 percent to $ 21 . 03 on the new york stock exchange on friday . [SEP]\n","INFO:tensorflow:input_ids: 101 1996 4518 3123 1002 1016 1012 2340 1010 2030 2055 2340 3867 1010 2000 2485 5958 2012 1002 2538 1012 4868 2006 1996 2047 2259 4518 3863 1012 102 18720 1004 1041 13058 1012 6661 5598 1002 1015 1012 6191 2030 1022 3867 2000 1002 2538 1012 6021 2006 1996 2047 2259 4518 3863 2006 5958 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:label: 1 (id = 1)\n","INFO:tensorflow:***** Running training *****\n","INFO:tensorflow:  Num examples = 3668\n","INFO:tensorflow:  Batch size = 4\n","INFO:tensorflow:  Num steps = 917\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Colocations handled automatically by placer.\n","WARNING:tensorflow:From run_classifier.py:890: map_and_batch (from tensorflow.contrib.data.python.ops.batching) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.experimental.map_and_batch(...)`.\n","WARNING:tensorflow:From run_classifier.py:870: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.cast instead.\n","INFO:tensorflow:Calling model_fn.\n","INFO:tensorflow:Running train on CPU\n","INFO:tensorflow:*** Features ***\n","INFO:tensorflow:  name = input_ids, shape = (4, 128)\n","INFO:tensorflow:  name = input_mask, shape = (4, 128)\n","INFO:tensorflow:  name = is_real_example, shape = (4,)\n","INFO:tensorflow:  name = label_ids, shape = (4,)\n","INFO:tensorflow:  name = segment_ids, shape = (4, 128)\n","WARNING:tensorflow:From /content/drive/MyDrive/Code_pretrain/modeling.py:358: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n","WARNING:tensorflow:From /content/drive/MyDrive/Code_pretrain/modeling.py:671: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use keras.layers.dense instead.\n","INFO:tensorflow:**** Trainable Variables ****\n","INFO:tensorflow:  name = bert/embeddings/word_embeddings:0, shape = (30522, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/embeddings/token_type_embeddings:0, shape = (2, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/embeddings/position_embeddings:0, shape = (512, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/embeddings/LayerNorm/beta:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/embeddings/LayerNorm/gamma:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/query/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/query/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/key/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/key/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/value/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/value/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/dense/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/dense/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/LayerNorm/beta:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/LayerNorm/gamma:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/intermediate/dense/kernel:0, shape = (256, 1024), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/intermediate/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/output/dense/kernel:0, shape = (1024, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/output/dense/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/output/LayerNorm/beta:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/output/LayerNorm/gamma:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/query/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/query/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/key/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/key/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/value/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/value/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/dense/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/dense/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/LayerNorm/beta:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/LayerNorm/gamma:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/intermediate/dense/kernel:0, shape = (256, 1024), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/intermediate/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/output/dense/kernel:0, shape = (1024, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/output/dense/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/output/LayerNorm/beta:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/output/LayerNorm/gamma:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/query/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/query/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/key/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/key/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/value/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/value/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/dense/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/dense/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/LayerNorm/beta:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/LayerNorm/gamma:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/intermediate/dense/kernel:0, shape = (256, 1024), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/intermediate/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/output/dense/kernel:0, shape = (1024, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/output/dense/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/output/LayerNorm/beta:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/output/LayerNorm/gamma:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/query/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/query/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/key/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/key/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/value/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/value/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/dense/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/dense/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/LayerNorm/beta:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/LayerNorm/gamma:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/intermediate/dense/kernel:0, shape = (256, 1024), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/intermediate/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/output/dense/kernel:0, shape = (1024, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/output/dense/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/output/LayerNorm/beta:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/output/LayerNorm/gamma:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/pooler/dense/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/pooler/dense/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = output_weights:0, shape = (2, 256)\n","INFO:tensorflow:  name = output_bias:0, shape = (2,)\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/learning_rate_decay_v2.py:321: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Deprecated in favor of operator or tf.math.divide.\n","INFO:tensorflow:Done calling model_fn.\n","INFO:tensorflow:Create CheckpointSaverHook.\n","INFO:tensorflow:Graph was finalized.\n","2023-05-22 06:31:01.762580: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA\n","2023-05-22 06:31:01.866952: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2023-05-22 06:31:01.867295: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x6ff5840 executing computations on platform CUDA. Devices:\n","2023-05-22 06:31:01.867328: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n","2023-05-22 06:31:01.869368: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2000185000 Hz\n","2023-05-22 06:31:01.869557: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x34e4e30 executing computations on platform Host. Devices:\n","2023-05-22 06:31:01.869587: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>\n","2023-05-22 06:31:01.869751: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 0 with properties: \n","name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n","pciBusID: 0000:00:04.0\n","totalMemory: 14.75GiB freeMemory: 14.65GiB\n","2023-05-22 06:31:01.869777: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0\n","2023-05-22 06:31:01.870066: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2023-05-22 06:31:01.870085: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0 \n","2023-05-22 06:31:01.870095: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N \n","2023-05-22 06:31:01.870158: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","2023-05-22 06:31:01.870195: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14248 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n","INFO:tensorflow:Running local_init_op.\n","INFO:tensorflow:Done running local_init_op.\n","INFO:tensorflow:Saving checkpoints for 0 into /content/trained_output/model.ckpt.\n","2023-05-22 06:31:07.067541: I tensorflow/stream_executor/dso_loader.cc:152] successfully opened CUDA library libcublas.so.10.0 locally\n","INFO:tensorflow:global_step/sec: 33.1856\n","INFO:tensorflow:examples/sec: 132.742\n","INFO:tensorflow:global_step/sec: 49.4642\n","INFO:tensorflow:examples/sec: 197.857\n","INFO:tensorflow:global_step/sec: 49.0014\n","INFO:tensorflow:examples/sec: 196.006\n","INFO:tensorflow:global_step/sec: 48.2842\n","INFO:tensorflow:examples/sec: 193.137\n","INFO:tensorflow:global_step/sec: 49.728\n","INFO:tensorflow:examples/sec: 198.912\n","INFO:tensorflow:global_step/sec: 51.9379\n","INFO:tensorflow:examples/sec: 207.752\n","INFO:tensorflow:global_step/sec: 51.7013\n","INFO:tensorflow:examples/sec: 206.805\n","INFO:tensorflow:global_step/sec: 51.5746\n","INFO:tensorflow:examples/sec: 206.298\n","INFO:tensorflow:global_step/sec: 51.8821\n","INFO:tensorflow:examples/sec: 207.528\n","INFO:tensorflow:Saving checkpoints for 917 into /content/trained_output/model.ckpt.\n","INFO:tensorflow:Loss for final step: 0.8171483.\n","INFO:tensorflow:training_loop marked as finished\n","INFO:tensorflow:Writing example 0 of 408\n","INFO:tensorflow:*** Example ***\n","INFO:tensorflow:guid: dev-1\n","INFO:tensorflow:tokens: [CLS] he said the foods ##er ##vic ##e pie business doesn ' t fit the company ' s long - term growth strategy . [SEP] \" the foods ##er ##vic ##e pie business does not fit our long - term growth strategy . [SEP]\n","INFO:tensorflow:input_ids: 101 2002 2056 1996 9440 2121 7903 2063 11345 2449 2987 1005 1056 4906 1996 2194 1005 1055 2146 1011 2744 3930 5656 1012 102 1000 1996 9440 2121 7903 2063 11345 2449 2515 2025 4906 2256 2146 1011 2744 3930 5656 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:label: 1 (id = 1)\n","INFO:tensorflow:*** Example ***\n","INFO:tensorflow:guid: dev-2\n","INFO:tensorflow:tokens: [CLS] magna ##relli said ra ##cic ##ot hated the iraqi regime and looked forward to using his long years of training in the war . [SEP] his wife said he was \" 100 percent behind george bush \" and looked forward to using his years of training in the war . [SEP]\n","INFO:tensorflow:input_ids: 101 20201 22948 2056 10958 19053 4140 6283 1996 8956 6939 1998 2246 2830 2000 2478 2010 2146 2086 1997 2731 1999 1996 2162 1012 102 2010 2564 2056 2002 2001 1000 2531 3867 2369 2577 5747 1000 1998 2246 2830 2000 2478 2010 2086 1997 2731 1999 1996 2162 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:label: 0 (id = 0)\n","INFO:tensorflow:*** Example ***\n","INFO:tensorflow:guid: dev-3\n","INFO:tensorflow:tokens: [CLS] the dollar was at 116 . 92 yen against the yen , flat on the session , and at 1 . 289 ##1 against the swiss fran ##c , also flat . [SEP] the dollar was at 116 . 78 yen jp ##y = , virtually flat on the session , and at 1 . 287 ##1 against the swiss fran ##c ch ##f = , down 0 . 1 percent . [SEP]\n","INFO:tensorflow:input_ids: 101 1996 7922 2001 2012 12904 1012 6227 18371 2114 1996 18371 1010 4257 2006 1996 5219 1010 1998 2012 1015 1012 27054 2487 2114 1996 5364 23151 2278 1010 2036 4257 1012 102 1996 7922 2001 2012 12904 1012 6275 18371 16545 2100 1027 1010 8990 4257 2006 1996 5219 1010 1998 2012 1015 1012 23090 2487 2114 1996 5364 23151 2278 10381 2546 1027 1010 2091 1014 1012 1015 3867 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:label: 0 (id = 0)\n","INFO:tensorflow:*** Example ***\n","INFO:tensorflow:guid: dev-4\n","INFO:tensorflow:tokens: [CLS] the afl - ci ##o is waiting until october to decide if it will end ##ors ##e a candidate . [SEP] the afl - ci ##o announced wednesday that it will decide in october whether to end ##ors ##e a candidate before the primaries . [SEP]\n","INFO:tensorflow:input_ids: 101 1996 10028 1011 25022 2080 2003 3403 2127 2255 2000 5630 2065 2009 2097 2203 5668 2063 1037 4018 1012 102 1996 10028 1011 25022 2080 2623 9317 2008 2009 2097 5630 1999 2255 3251 2000 2203 5668 2063 1037 4018 2077 1996 27419 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:label: 1 (id = 1)\n","INFO:tensorflow:*** Example ***\n","INFO:tensorflow:guid: dev-5\n","INFO:tensorflow:tokens: [CLS] no dates have been set for the civil or the criminal trial . [SEP] no dates have been set for the criminal or civil cases , but shan ##ley has pleaded not guilty . [SEP]\n","INFO:tensorflow:input_ids: 101 2053 5246 2031 2042 2275 2005 1996 2942 2030 1996 4735 3979 1012 102 2053 5246 2031 2042 2275 2005 1996 4735 2030 2942 3572 1010 2021 17137 3051 2038 12254 2025 5905 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:label: 0 (id = 0)\n","INFO:tensorflow:***** Running evaluation *****\n","INFO:tensorflow:  Num examples = 408 (408 actual, 0 padding)\n","INFO:tensorflow:  Batch size = 8\n","INFO:tensorflow:Calling model_fn.\n","INFO:tensorflow:Running eval on CPU\n","INFO:tensorflow:*** Features ***\n","INFO:tensorflow:  name = input_ids, shape = (?, 128)\n","INFO:tensorflow:  name = input_mask, shape = (?, 128)\n","INFO:tensorflow:  name = is_real_example, shape = (?,)\n","INFO:tensorflow:  name = label_ids, shape = (?,)\n","INFO:tensorflow:  name = segment_ids, shape = (?, 128)\n","INFO:tensorflow:**** Trainable Variables ****\n","INFO:tensorflow:  name = bert/embeddings/word_embeddings:0, shape = (30522, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/embeddings/token_type_embeddings:0, shape = (2, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/embeddings/position_embeddings:0, shape = (512, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/embeddings/LayerNorm/beta:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/embeddings/LayerNorm/gamma:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/query/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/query/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/key/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/key/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/value/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/value/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/dense/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/dense/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/LayerNorm/beta:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/LayerNorm/gamma:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/intermediate/dense/kernel:0, shape = (256, 1024), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/intermediate/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/output/dense/kernel:0, shape = (1024, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/output/dense/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/output/LayerNorm/beta:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/output/LayerNorm/gamma:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/query/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/query/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/key/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/key/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/value/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/value/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/dense/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/dense/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/LayerNorm/beta:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/LayerNorm/gamma:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/intermediate/dense/kernel:0, shape = (256, 1024), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/intermediate/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/output/dense/kernel:0, shape = (1024, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/output/dense/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/output/LayerNorm/beta:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/output/LayerNorm/gamma:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/query/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/query/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/key/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/key/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/value/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/value/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/dense/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/dense/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/LayerNorm/beta:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/LayerNorm/gamma:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/intermediate/dense/kernel:0, shape = (256, 1024), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/intermediate/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/output/dense/kernel:0, shape = (1024, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/output/dense/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/output/LayerNorm/beta:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/output/LayerNorm/gamma:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/query/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/query/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/key/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/key/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/value/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/value/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/dense/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/dense/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/LayerNorm/beta:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/LayerNorm/gamma:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/intermediate/dense/kernel:0, shape = (256, 1024), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/intermediate/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/output/dense/kernel:0, shape = (1024, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/output/dense/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/output/LayerNorm/beta:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/output/LayerNorm/gamma:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/pooler/dense/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/pooler/dense/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = output_weights:0, shape = (2, 256)\n","INFO:tensorflow:  name = output_bias:0, shape = (2,)\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/metrics_impl.py:455: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.cast instead.\n","INFO:tensorflow:Done calling model_fn.\n","INFO:tensorflow:Starting evaluation at 2023-05-22T06:31:30Z\n","INFO:tensorflow:Graph was finalized.\n","2023-05-22 06:31:30.686953: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0\n","2023-05-22 06:31:30.687028: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2023-05-22 06:31:30.687046: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0 \n","2023-05-22 06:31:30.687057: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N \n","2023-05-22 06:31:30.687174: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14248 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use standard file APIs to check for files with this prefix.\n","INFO:tensorflow:Restoring parameters from /content/trained_output/model.ckpt-917\n","INFO:tensorflow:Running local_init_op.\n","INFO:tensorflow:Done running local_init_op.\n","INFO:tensorflow:Finished evaluation at 2023-05-22-06:31:32\n","INFO:tensorflow:Saving dict for global step 917: eval_accuracy = 0.72794116, eval_loss = 0.5443143, global_step = 917, loss = 0.5443143\n","INFO:tensorflow:Saving 'checkpoint_path' summary for global step 917: /content/trained_output/model.ckpt-917\n","INFO:tensorflow:evaluation_loop marked as finished\n","INFO:tensorflow:***** Eval results *****\n","INFO:tensorflow:  eval_accuracy = 0.72794116\n","INFO:tensorflow:  eval_loss = 0.5443143\n","INFO:tensorflow:  global_step = 917\n","INFO:tensorflow:  loss = 0.5443143\n"]}],"source":["%cd /content/drive/MyDrive/Code_pretrain\n","%pwd\n","%env BERT_BASE_DIR=uncased_L-4_H-256_A-4\n","%env GLUE_DIR=data\n","!rm -rf /content/trained_output\n","\n","!python3 run_classifier.py \\\n","  --task_name=MRPC \\\n","  --do_train=true \\\n","  --do_eval=true \\\n","  --data_dir=$GLUE_DIR/MRPC \\\n","  --vocab_file=$BERT_BASE_DIR/vocab.txt \\\n","  --bert_config_file=$BERT_BASE_DIR/bert_config.json \\\n","  --init_checkpoint=$BERT_BASE_DIR/bert_model.ckpt \\\n","  --max_seq_length=128 \\\n","  --train_batch_size=4 \\\n","  --learning_rate=2e-5 \\\n","  --num_train_epochs=1.0 \\\n","  --output_dir=/content/trained_output\n","\n","# result metric.\n","# INFO:tensorflow:  eval_accuracy = 0.70343137\n","# INFO:tensorflow:  eval_loss = 0.605878\n","# INFO:tensorflow:  global_step = 917\n","# INFO:tensorflow:  loss = 0.605878\n","\n","# INFO:tensorflow:  eval_accuracy = 0.72794116\n","# INFO:tensorflow:  eval_loss = 0.5443143\n","# INFO:tensorflow:  global_step = 917\n","# INFO:tensorflow:  loss = 0.5443143"]},{"cell_type":"markdown","metadata":{"id":"q58eAB7ix6AO"},"source":["#MNLI is slow"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"ckZQNblOgWVd","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1684739438067,"user_tz":-480,"elapsed":2239041,"user":{"displayName":"Brian Shen","userId":"08246478872294528508"}},"outputId":"328926ae-9983-4470-835f-6728c3db3ec1"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Code_pretrain\n","env: BERT_BASE_DIR=uncased_L-4_H-256_A-4\n","env: GLUE_DIR=data\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n","\n","WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n","For more information, please see:\n","  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n","  * https://github.com/tensorflow/addons\n","If you depend on functionality not listed there, please file an issue.\n","\n","WARNING:tensorflow:Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f58e010ba60>) includes params argument, but params are not passed to Estimator.\n","INFO:tensorflow:Using config: {'_model_dir': '/content/trained_output', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 1000, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n","graph_options {\n","  rewrite_options {\n","    meta_optimizer_iterations: ONE\n","  }\n","}\n",", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f58da643cc0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=1000, num_shards=8, num_cores_per_replica=None, per_host_input_for_training=3, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None), '_cluster': None}\n","INFO:tensorflow:_TPUContext: eval_on_tpu True\n","WARNING:tensorflow:eval_on_tpu ignored because use_tpu is False.\n","INFO:tensorflow:Writing example 0 of 392702\n","INFO:tensorflow:*** Example ***\n","INFO:tensorflow:guid: train-0\n","INFO:tensorflow:tokens: [CLS] conceptual ##ly cream ski ##mming has two basic dimensions - product and geography . [SEP] product and geography are what make cream ski ##mming work . [SEP]\n","INFO:tensorflow:input_ids: 101 17158 2135 6949 8301 25057 2038 2048 3937 9646 1011 4031 1998 10505 1012 102 4031 1998 10505 2024 2054 2191 6949 8301 25057 2147 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:label: neutral (id = 2)\n","INFO:tensorflow:*** Example ***\n","INFO:tensorflow:guid: train-1\n","INFO:tensorflow:tokens: [CLS] you know during the season and i guess at at your level uh you lose them to the next level if if they decide to recall the the parent team the braves decide to call to recall a guy from triple a then a double a guy goes up to replace him and a single a guy goes up to replace him [SEP] you lose the things to the following level if the people recall . [SEP]\n","INFO:tensorflow:input_ids: 101 2017 2113 2076 1996 2161 1998 1045 3984 2012 2012 2115 2504 7910 2017 4558 2068 2000 1996 2279 2504 2065 2065 2027 5630 2000 9131 1996 1996 6687 2136 1996 13980 5630 2000 2655 2000 9131 1037 3124 2013 6420 1037 2059 1037 3313 1037 3124 3632 2039 2000 5672 2032 1998 1037 2309 1037 3124 3632 2039 2000 5672 2032 102 2017 4558 1996 2477 2000 1996 2206 2504 2065 1996 2111 9131 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:label: entailment (id = 1)\n","INFO:tensorflow:*** Example ***\n","INFO:tensorflow:guid: train-2\n","INFO:tensorflow:tokens: [CLS] one of our number will carry out your instructions minute ##ly . [SEP] a member of my team will execute your orders with immense precision . [SEP]\n","INFO:tensorflow:input_ids: 101 2028 1997 2256 2193 2097 4287 2041 2115 8128 3371 2135 1012 102 1037 2266 1997 2026 2136 2097 15389 2115 4449 2007 14269 11718 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:label: entailment (id = 1)\n","INFO:tensorflow:*** Example ***\n","INFO:tensorflow:guid: train-3\n","INFO:tensorflow:tokens: [CLS] how do you know ? all this is their information again . [SEP] this information belongs to them . [SEP]\n","INFO:tensorflow:input_ids: 101 2129 2079 2017 2113 1029 2035 2023 2003 2037 2592 2153 1012 102 2023 2592 7460 2000 2068 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:label: entailment (id = 1)\n","INFO:tensorflow:*** Example ***\n","INFO:tensorflow:guid: train-4\n","INFO:tensorflow:tokens: [CLS] yeah i tell you what though if you go price some of those tennis shoes i can see why now you know they ' re getting up in the hundred dollar range [SEP] the tennis shoes have a range of prices . [SEP]\n","INFO:tensorflow:input_ids: 101 3398 1045 2425 2017 2054 2295 2065 2017 2175 3976 2070 1997 2216 5093 6007 1045 2064 2156 2339 2085 2017 2113 2027 1005 2128 2893 2039 1999 1996 3634 7922 2846 102 1996 5093 6007 2031 1037 2846 1997 7597 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:label: neutral (id = 2)\n","INFO:tensorflow:Writing example 10000 of 392702\n","INFO:tensorflow:Writing example 20000 of 392702\n","INFO:tensorflow:Writing example 30000 of 392702\n","INFO:tensorflow:Writing example 40000 of 392702\n","INFO:tensorflow:Writing example 50000 of 392702\n","INFO:tensorflow:Writing example 60000 of 392702\n","INFO:tensorflow:Writing example 70000 of 392702\n","INFO:tensorflow:Writing example 80000 of 392702\n","INFO:tensorflow:Writing example 90000 of 392702\n","INFO:tensorflow:Writing example 100000 of 392702\n","INFO:tensorflow:Writing example 110000 of 392702\n","INFO:tensorflow:Writing example 120000 of 392702\n","INFO:tensorflow:Writing example 130000 of 392702\n","INFO:tensorflow:Writing example 140000 of 392702\n","INFO:tensorflow:Writing example 150000 of 392702\n","INFO:tensorflow:Writing example 160000 of 392702\n","INFO:tensorflow:Writing example 170000 of 392702\n","INFO:tensorflow:Writing example 180000 of 392702\n","INFO:tensorflow:Writing example 190000 of 392702\n","INFO:tensorflow:Writing example 200000 of 392702\n","INFO:tensorflow:Writing example 210000 of 392702\n","INFO:tensorflow:Writing example 220000 of 392702\n","INFO:tensorflow:Writing example 230000 of 392702\n","INFO:tensorflow:Writing example 240000 of 392702\n","INFO:tensorflow:Writing example 250000 of 392702\n","INFO:tensorflow:Writing example 260000 of 392702\n","INFO:tensorflow:Writing example 270000 of 392702\n","INFO:tensorflow:Writing example 280000 of 392702\n","INFO:tensorflow:Writing example 290000 of 392702\n","INFO:tensorflow:Writing example 300000 of 392702\n","INFO:tensorflow:Writing example 310000 of 392702\n","INFO:tensorflow:Writing example 320000 of 392702\n","INFO:tensorflow:Writing example 330000 of 392702\n","INFO:tensorflow:Writing example 340000 of 392702\n","INFO:tensorflow:Writing example 350000 of 392702\n","INFO:tensorflow:Writing example 360000 of 392702\n","INFO:tensorflow:Writing example 370000 of 392702\n","INFO:tensorflow:Writing example 380000 of 392702\n","INFO:tensorflow:Writing example 390000 of 392702\n","INFO:tensorflow:***** Running training *****\n","INFO:tensorflow:  Num examples = 392702\n","INFO:tensorflow:  Batch size = 4\n","INFO:tensorflow:  Num steps = 98175\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Colocations handled automatically by placer.\n","WARNING:tensorflow:From run_classifier.py:890: map_and_batch (from tensorflow.contrib.data.python.ops.batching) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.experimental.map_and_batch(...)`.\n","WARNING:tensorflow:From run_classifier.py:870: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.cast instead.\n","INFO:tensorflow:Calling model_fn.\n","INFO:tensorflow:Running train on CPU\n","INFO:tensorflow:*** Features ***\n","INFO:tensorflow:  name = input_ids, shape = (4, 128)\n","INFO:tensorflow:  name = input_mask, shape = (4, 128)\n","INFO:tensorflow:  name = is_real_example, shape = (4,)\n","INFO:tensorflow:  name = label_ids, shape = (4,)\n","INFO:tensorflow:  name = segment_ids, shape = (4, 128)\n","WARNING:tensorflow:From /content/drive/MyDrive/Code_pretrain/modeling.py:358: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n","WARNING:tensorflow:From /content/drive/MyDrive/Code_pretrain/modeling.py:671: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use keras.layers.dense instead.\n","INFO:tensorflow:**** Trainable Variables ****\n","INFO:tensorflow:  name = bert/embeddings/word_embeddings:0, shape = (30522, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/embeddings/token_type_embeddings:0, shape = (2, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/embeddings/position_embeddings:0, shape = (512, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/embeddings/LayerNorm/beta:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/embeddings/LayerNorm/gamma:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/query/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/query/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/key/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/key/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/value/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/value/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/dense/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/dense/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/LayerNorm/beta:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/LayerNorm/gamma:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/intermediate/dense/kernel:0, shape = (256, 1024), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/intermediate/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/output/dense/kernel:0, shape = (1024, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/output/dense/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/output/LayerNorm/beta:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/output/LayerNorm/gamma:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/query/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/query/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/key/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/key/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/value/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/value/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/dense/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/dense/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/LayerNorm/beta:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/LayerNorm/gamma:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/intermediate/dense/kernel:0, shape = (256, 1024), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/intermediate/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/output/dense/kernel:0, shape = (1024, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/output/dense/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/output/LayerNorm/beta:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/output/LayerNorm/gamma:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/query/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/query/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/key/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/key/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/value/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/value/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/dense/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/dense/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/LayerNorm/beta:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/LayerNorm/gamma:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/intermediate/dense/kernel:0, shape = (256, 1024), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/intermediate/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/output/dense/kernel:0, shape = (1024, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/output/dense/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/output/LayerNorm/beta:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/output/LayerNorm/gamma:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/query/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/query/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/key/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/key/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/value/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/value/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/dense/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/dense/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/LayerNorm/beta:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/LayerNorm/gamma:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/intermediate/dense/kernel:0, shape = (256, 1024), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/intermediate/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/output/dense/kernel:0, shape = (1024, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/output/dense/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/output/LayerNorm/beta:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/output/LayerNorm/gamma:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/pooler/dense/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/pooler/dense/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = output_weights:0, shape = (3, 256)\n","INFO:tensorflow:  name = output_bias:0, shape = (3,)\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/learning_rate_decay_v2.py:321: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Deprecated in favor of operator or tf.math.divide.\n","INFO:tensorflow:Done calling model_fn.\n","INFO:tensorflow:Create CheckpointSaverHook.\n","INFO:tensorflow:Graph was finalized.\n","2023-05-22 06:36:49.189676: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA\n","2023-05-22 06:36:49.326234: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2023-05-22 06:36:49.326607: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x7210810 executing computations on platform CUDA. Devices:\n","2023-05-22 06:36:49.326642: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n","2023-05-22 06:36:49.329415: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2000185000 Hz\n","2023-05-22 06:36:49.329592: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x2687980 executing computations on platform Host. Devices:\n","2023-05-22 06:36:49.329611: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>\n","2023-05-22 06:36:49.329764: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 0 with properties: \n","name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n","pciBusID: 0000:00:04.0\n","totalMemory: 14.75GiB freeMemory: 14.65GiB\n","2023-05-22 06:36:49.329788: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0\n","2023-05-22 06:36:49.330166: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2023-05-22 06:36:49.330184: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0 \n","2023-05-22 06:36:49.330194: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N \n","2023-05-22 06:36:49.330249: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","2023-05-22 06:36:49.330290: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14248 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n","INFO:tensorflow:Running local_init_op.\n","INFO:tensorflow:Done running local_init_op.\n","INFO:tensorflow:Saving checkpoints for 0 into /content/trained_output/model.ckpt.\n","2023-05-22 06:36:57.388663: I tensorflow/stream_executor/dso_loader.cc:152] successfully opened CUDA library libcublas.so.10.0 locally\n","INFO:tensorflow:global_step/sec: 33.2071\n","INFO:tensorflow:examples/sec: 132.828\n","INFO:tensorflow:global_step/sec: 53.849\n","INFO:tensorflow:examples/sec: 215.396\n","INFO:tensorflow:global_step/sec: 53.6472\n","INFO:tensorflow:examples/sec: 214.589\n","INFO:tensorflow:global_step/sec: 51.5783\n","INFO:tensorflow:examples/sec: 206.313\n","INFO:tensorflow:global_step/sec: 49.4602\n","INFO:tensorflow:examples/sec: 197.841\n","INFO:tensorflow:global_step/sec: 50.7294\n","INFO:tensorflow:examples/sec: 202.918\n","INFO:tensorflow:global_step/sec: 49.4355\n","INFO:tensorflow:examples/sec: 197.742\n","INFO:tensorflow:global_step/sec: 52.4853\n","INFO:tensorflow:examples/sec: 209.941\n","INFO:tensorflow:global_step/sec: 53.7144\n","INFO:tensorflow:examples/sec: 214.858\n","INFO:tensorflow:Saving checkpoints for 1000 into /content/trained_output/model.ckpt.\n","INFO:tensorflow:global_step/sec: 41.5038\n","INFO:tensorflow:examples/sec: 166.015\n","INFO:tensorflow:global_step/sec: 53.3536\n","INFO:tensorflow:examples/sec: 213.414\n","INFO:tensorflow:global_step/sec: 53.1023\n","INFO:tensorflow:examples/sec: 212.409\n","INFO:tensorflow:global_step/sec: 49.8787\n","INFO:tensorflow:examples/sec: 199.515\n","INFO:tensorflow:global_step/sec: 49.5694\n","INFO:tensorflow:examples/sec: 198.278\n","INFO:tensorflow:global_step/sec: 50.2014\n","INFO:tensorflow:examples/sec: 200.805\n","INFO:tensorflow:global_step/sec: 48.8826\n","INFO:tensorflow:examples/sec: 195.53\n","INFO:tensorflow:global_step/sec: 52.8731\n","INFO:tensorflow:examples/sec: 211.492\n","INFO:tensorflow:global_step/sec: 52.6209\n","INFO:tensorflow:examples/sec: 210.484\n","INFO:tensorflow:global_step/sec: 52.8192\n","INFO:tensorflow:examples/sec: 211.277\n","INFO:tensorflow:Saving checkpoints for 2000 into /content/trained_output/model.ckpt.\n","INFO:tensorflow:global_step/sec: 42.3234\n","INFO:tensorflow:examples/sec: 169.294\n","INFO:tensorflow:global_step/sec: 52.7552\n","INFO:tensorflow:examples/sec: 211.021\n","INFO:tensorflow:global_step/sec: 49.1954\n","INFO:tensorflow:examples/sec: 196.782\n","INFO:tensorflow:global_step/sec: 49.3562\n","INFO:tensorflow:examples/sec: 197.425\n","INFO:tensorflow:global_step/sec: 48.778\n","INFO:tensorflow:examples/sec: 195.112\n","INFO:tensorflow:global_step/sec: 49.381\n","INFO:tensorflow:examples/sec: 197.524\n","INFO:tensorflow:global_step/sec: 52.4642\n","INFO:tensorflow:examples/sec: 209.857\n","INFO:tensorflow:global_step/sec: 52.2983\n","INFO:tensorflow:examples/sec: 209.193\n","INFO:tensorflow:global_step/sec: 52.026\n","INFO:tensorflow:examples/sec: 208.104\n","INFO:tensorflow:global_step/sec: 52.2436\n","INFO:tensorflow:examples/sec: 208.975\n","INFO:tensorflow:Saving checkpoints for 3000 into /content/trained_output/model.ckpt.\n","INFO:tensorflow:global_step/sec: 36.9184\n","INFO:tensorflow:examples/sec: 147.674\n","INFO:tensorflow:global_step/sec: 48.2363\n","INFO:tensorflow:examples/sec: 192.945\n","INFO:tensorflow:global_step/sec: 48.6137\n","INFO:tensorflow:examples/sec: 194.455\n","INFO:tensorflow:global_step/sec: 48.8977\n","INFO:tensorflow:examples/sec: 195.591\n","INFO:tensorflow:global_step/sec: 51.2432\n","INFO:tensorflow:examples/sec: 204.973\n","INFO:tensorflow:global_step/sec: 51.8714\n","INFO:tensorflow:examples/sec: 207.486\n","INFO:tensorflow:global_step/sec: 51.8823\n","INFO:tensorflow:examples/sec: 207.529\n","INFO:tensorflow:global_step/sec: 51.71\n","INFO:tensorflow:examples/sec: 206.84\n","INFO:tensorflow:global_step/sec: 51.7959\n","INFO:tensorflow:examples/sec: 207.183\n","INFO:tensorflow:global_step/sec: 50.0017\n","INFO:tensorflow:examples/sec: 200.007\n","INFO:tensorflow:Saving checkpoints for 4000 into /content/trained_output/model.ckpt.\n","INFO:tensorflow:global_step/sec: 35.264\n","INFO:tensorflow:examples/sec: 141.056\n","INFO:tensorflow:global_step/sec: 49.1465\n","INFO:tensorflow:examples/sec: 196.586\n","INFO:tensorflow:global_step/sec: 48.934\n","INFO:tensorflow:examples/sec: 195.736\n","INFO:tensorflow:global_step/sec: 51.752\n","INFO:tensorflow:examples/sec: 207.008\n","INFO:tensorflow:global_step/sec: 52.0344\n","INFO:tensorflow:examples/sec: 208.138\n","INFO:tensorflow:global_step/sec: 52.018\n","INFO:tensorflow:examples/sec: 208.072\n","INFO:tensorflow:global_step/sec: 52.3675\n","INFO:tensorflow:examples/sec: 209.47\n","INFO:tensorflow:global_step/sec: 52.127\n","INFO:tensorflow:examples/sec: 208.508\n","INFO:tensorflow:global_step/sec: 49.0668\n","INFO:tensorflow:examples/sec: 196.267\n","INFO:tensorflow:global_step/sec: 48.8506\n","INFO:tensorflow:examples/sec: 195.402\n","INFO:tensorflow:Saving checkpoints for 5000 into /content/trained_output/model.ckpt.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:966: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use standard file APIs to delete files with this prefix.\n","INFO:tensorflow:global_step/sec: 34.3092\n","INFO:tensorflow:examples/sec: 137.237\n","INFO:tensorflow:global_step/sec: 50.8884\n","INFO:tensorflow:examples/sec: 203.554\n","INFO:tensorflow:global_step/sec: 52.2594\n","INFO:tensorflow:examples/sec: 209.037\n","INFO:tensorflow:global_step/sec: 52.4311\n","INFO:tensorflow:examples/sec: 209.724\n","INFO:tensorflow:global_step/sec: 52.6357\n","INFO:tensorflow:examples/sec: 210.543\n","INFO:tensorflow:global_step/sec: 52.5368\n","INFO:tensorflow:examples/sec: 210.147\n","INFO:tensorflow:global_step/sec: 50.9382\n","INFO:tensorflow:examples/sec: 203.753\n","INFO:tensorflow:global_step/sec: 48.9172\n","INFO:tensorflow:examples/sec: 195.669\n","INFO:tensorflow:global_step/sec: 48.6319\n","INFO:tensorflow:examples/sec: 194.528\n","INFO:tensorflow:global_step/sec: 48.5674\n","INFO:tensorflow:examples/sec: 194.27\n","INFO:tensorflow:Saving checkpoints for 6000 into /content/trained_output/model.ckpt.\n","INFO:tensorflow:global_step/sec: 40.773\n","INFO:tensorflow:examples/sec: 163.092\n","INFO:tensorflow:global_step/sec: 52.5494\n","INFO:tensorflow:examples/sec: 210.198\n","INFO:tensorflow:global_step/sec: 52.3756\n","INFO:tensorflow:examples/sec: 209.503\n","INFO:tensorflow:global_step/sec: 52.5336\n","INFO:tensorflow:examples/sec: 210.134\n","INFO:tensorflow:global_step/sec: 52.5309\n","INFO:tensorflow:examples/sec: 210.124\n","INFO:tensorflow:global_step/sec: 49.878\n","INFO:tensorflow:examples/sec: 199.512\n","INFO:tensorflow:global_step/sec: 48.8641\n","INFO:tensorflow:examples/sec: 195.456\n","INFO:tensorflow:global_step/sec: 48.9346\n","INFO:tensorflow:examples/sec: 195.738\n","INFO:tensorflow:global_step/sec: 48.5195\n","INFO:tensorflow:examples/sec: 194.078\n","INFO:tensorflow:global_step/sec: 52.3521\n","INFO:tensorflow:examples/sec: 209.409\n","INFO:tensorflow:Saving checkpoints for 7000 into /content/trained_output/model.ckpt.\n","INFO:tensorflow:global_step/sec: 40.9818\n","INFO:tensorflow:examples/sec: 163.927\n","INFO:tensorflow:global_step/sec: 52.2544\n","INFO:tensorflow:examples/sec: 209.018\n","INFO:tensorflow:global_step/sec: 52.1478\n","INFO:tensorflow:examples/sec: 208.591\n","INFO:tensorflow:global_step/sec: 51.713\n","INFO:tensorflow:examples/sec: 206.852\n","INFO:tensorflow:global_step/sec: 47.8408\n","INFO:tensorflow:examples/sec: 191.363\n","INFO:tensorflow:global_step/sec: 48.4014\n","INFO:tensorflow:examples/sec: 193.606\n","INFO:tensorflow:global_step/sec: 48.673\n","INFO:tensorflow:examples/sec: 194.692\n","INFO:tensorflow:global_step/sec: 49.1127\n","INFO:tensorflow:examples/sec: 196.451\n","INFO:tensorflow:global_step/sec: 52.1063\n","INFO:tensorflow:examples/sec: 208.425\n","INFO:tensorflow:global_step/sec: 52.1985\n","INFO:tensorflow:examples/sec: 208.794\n","INFO:tensorflow:Saving checkpoints for 8000 into /content/trained_output/model.ckpt.\n","INFO:tensorflow:global_step/sec: 41.626\n","INFO:tensorflow:examples/sec: 166.504\n","INFO:tensorflow:global_step/sec: 52.2862\n","INFO:tensorflow:examples/sec: 209.145\n","INFO:tensorflow:global_step/sec: 50.7495\n","INFO:tensorflow:examples/sec: 202.998\n","INFO:tensorflow:global_step/sec: 47.7644\n","INFO:tensorflow:examples/sec: 191.058\n","INFO:tensorflow:global_step/sec: 48.6768\n","INFO:tensorflow:examples/sec: 194.707\n","INFO:tensorflow:global_step/sec: 48.4244\n","INFO:tensorflow:examples/sec: 193.698\n","INFO:tensorflow:global_step/sec: 50.8306\n","INFO:tensorflow:examples/sec: 203.323\n","INFO:tensorflow:global_step/sec: 52.0651\n","INFO:tensorflow:examples/sec: 208.26\n","INFO:tensorflow:global_step/sec: 52.1957\n","INFO:tensorflow:examples/sec: 208.783\n","INFO:tensorflow:global_step/sec: 51.8736\n","INFO:tensorflow:examples/sec: 207.494\n","INFO:tensorflow:Saving checkpoints for 9000 into /content/trained_output/model.ckpt.\n","INFO:tensorflow:global_step/sec: 41.6285\n","INFO:tensorflow:examples/sec: 166.514\n","INFO:tensorflow:global_step/sec: 49.1169\n","INFO:tensorflow:examples/sec: 196.468\n","INFO:tensorflow:global_step/sec: 48.6023\n","INFO:tensorflow:examples/sec: 194.409\n","INFO:tensorflow:global_step/sec: 48.9058\n","INFO:tensorflow:examples/sec: 195.623\n","INFO:tensorflow:global_step/sec: 49.2489\n","INFO:tensorflow:examples/sec: 196.996\n","INFO:tensorflow:global_step/sec: 52.3245\n","INFO:tensorflow:examples/sec: 209.298\n","INFO:tensorflow:global_step/sec: 52.1554\n","INFO:tensorflow:examples/sec: 208.622\n","INFO:tensorflow:global_step/sec: 52.4762\n","INFO:tensorflow:examples/sec: 209.905\n","INFO:tensorflow:global_step/sec: 52.1586\n","INFO:tensorflow:examples/sec: 208.634\n","INFO:tensorflow:global_step/sec: 52.26\n","INFO:tensorflow:examples/sec: 209.04\n","INFO:tensorflow:Saving checkpoints for 10000 into /content/trained_output/model.ckpt.\n","INFO:tensorflow:global_step/sec: 35.5707\n","INFO:tensorflow:examples/sec: 142.283\n","INFO:tensorflow:global_step/sec: 48.2139\n","INFO:tensorflow:examples/sec: 192.856\n","INFO:tensorflow:global_step/sec: 49.0225\n","INFO:tensorflow:examples/sec: 196.09\n","INFO:tensorflow:global_step/sec: 50.6292\n","INFO:tensorflow:examples/sec: 202.517\n","INFO:tensorflow:global_step/sec: 52.0304\n","INFO:tensorflow:examples/sec: 208.121\n","INFO:tensorflow:global_step/sec: 52.0655\n","INFO:tensorflow:examples/sec: 208.262\n","INFO:tensorflow:global_step/sec: 52.3743\n","INFO:tensorflow:examples/sec: 209.497\n","INFO:tensorflow:global_step/sec: 52.4226\n","INFO:tensorflow:examples/sec: 209.69\n","INFO:tensorflow:global_step/sec: 51.562\n","INFO:tensorflow:examples/sec: 206.248\n","INFO:tensorflow:global_step/sec: 48.2029\n","INFO:tensorflow:examples/sec: 192.811\n","INFO:tensorflow:Saving checkpoints for 11000 into /content/trained_output/model.ckpt.\n","INFO:tensorflow:global_step/sec: 35.2117\n","INFO:tensorflow:examples/sec: 140.847\n","INFO:tensorflow:global_step/sec: 48.7552\n","INFO:tensorflow:examples/sec: 195.021\n","INFO:tensorflow:global_step/sec: 51.7921\n","INFO:tensorflow:examples/sec: 207.168\n","INFO:tensorflow:global_step/sec: 52.2795\n","INFO:tensorflow:examples/sec: 209.118\n","INFO:tensorflow:global_step/sec: 52.3053\n","INFO:tensorflow:examples/sec: 209.221\n","INFO:tensorflow:global_step/sec: 52.2005\n","INFO:tensorflow:examples/sec: 208.802\n","INFO:tensorflow:global_step/sec: 52.2884\n","INFO:tensorflow:examples/sec: 209.153\n","INFO:tensorflow:global_step/sec: 49.5993\n","INFO:tensorflow:examples/sec: 198.397\n","INFO:tensorflow:global_step/sec: 49.3922\n","INFO:tensorflow:examples/sec: 197.569\n","INFO:tensorflow:global_step/sec: 48.1809\n","INFO:tensorflow:examples/sec: 192.724\n","INFO:tensorflow:Saving checkpoints for 12000 into /content/trained_output/model.ckpt.\n","INFO:tensorflow:global_step/sec: 37.2\n","INFO:tensorflow:examples/sec: 148.8\n","INFO:tensorflow:global_step/sec: 51.7451\n","INFO:tensorflow:examples/sec: 206.981\n","INFO:tensorflow:global_step/sec: 51.6938\n","INFO:tensorflow:examples/sec: 206.775\n","INFO:tensorflow:global_step/sec: 51.4315\n","INFO:tensorflow:examples/sec: 205.726\n","INFO:tensorflow:global_step/sec: 52.1005\n","INFO:tensorflow:examples/sec: 208.402\n","INFO:tensorflow:global_step/sec: 52.0528\n","INFO:tensorflow:examples/sec: 208.211\n","INFO:tensorflow:global_step/sec: 49.0539\n","INFO:tensorflow:examples/sec: 196.216\n","INFO:tensorflow:global_step/sec: 48.1762\n","INFO:tensorflow:examples/sec: 192.705\n","INFO:tensorflow:global_step/sec: 48.1391\n","INFO:tensorflow:examples/sec: 192.556\n","INFO:tensorflow:global_step/sec: 49.5348\n","INFO:tensorflow:examples/sec: 198.139\n","INFO:tensorflow:Saving checkpoints for 13000 into /content/trained_output/model.ckpt.\n","INFO:tensorflow:global_step/sec: 41.0429\n","INFO:tensorflow:examples/sec: 164.172\n","INFO:tensorflow:global_step/sec: 51.9475\n","INFO:tensorflow:examples/sec: 207.79\n","INFO:tensorflow:global_step/sec: 52.4087\n","INFO:tensorflow:examples/sec: 209.635\n","INFO:tensorflow:global_step/sec: 52.307\n","INFO:tensorflow:examples/sec: 209.228\n","INFO:tensorflow:global_step/sec: 50.6652\n","INFO:tensorflow:examples/sec: 202.661\n","INFO:tensorflow:global_step/sec: 49.1531\n","INFO:tensorflow:examples/sec: 196.613\n","INFO:tensorflow:global_step/sec: 48.3017\n","INFO:tensorflow:examples/sec: 193.207\n","INFO:tensorflow:global_step/sec: 48.9187\n","INFO:tensorflow:examples/sec: 195.675\n","INFO:tensorflow:global_step/sec: 50.5628\n","INFO:tensorflow:examples/sec: 202.251\n","INFO:tensorflow:global_step/sec: 52.3773\n","INFO:tensorflow:examples/sec: 209.509\n","INFO:tensorflow:Saving checkpoints for 14000 into /content/trained_output/model.ckpt.\n","INFO:tensorflow:global_step/sec: 41.0572\n","INFO:tensorflow:examples/sec: 164.229\n","INFO:tensorflow:global_step/sec: 52.2484\n","INFO:tensorflow:examples/sec: 208.994\n","INFO:tensorflow:global_step/sec: 52.3158\n","INFO:tensorflow:examples/sec: 209.263\n","INFO:tensorflow:global_step/sec: 50.3929\n","INFO:tensorflow:examples/sec: 201.571\n","INFO:tensorflow:global_step/sec: 48.8343\n","INFO:tensorflow:examples/sec: 195.337\n","INFO:tensorflow:global_step/sec: 48.2284\n","INFO:tensorflow:examples/sec: 192.913\n","INFO:tensorflow:global_step/sec: 48.7649\n","INFO:tensorflow:examples/sec: 195.059\n","INFO:tensorflow:global_step/sec: 52.0431\n","INFO:tensorflow:examples/sec: 208.173\n","INFO:tensorflow:global_step/sec: 52.4584\n","INFO:tensorflow:examples/sec: 209.834\n","INFO:tensorflow:global_step/sec: 52.1695\n","INFO:tensorflow:examples/sec: 208.678\n","INFO:tensorflow:Saving checkpoints for 15000 into /content/trained_output/model.ckpt.\n","INFO:tensorflow:global_step/sec: 41.3578\n","INFO:tensorflow:examples/sec: 165.431\n","INFO:tensorflow:global_step/sec: 52.3044\n","INFO:tensorflow:examples/sec: 209.218\n","INFO:tensorflow:global_step/sec: 48.6629\n","INFO:tensorflow:examples/sec: 194.652\n","INFO:tensorflow:global_step/sec: 47.7447\n","INFO:tensorflow:examples/sec: 190.979\n","INFO:tensorflow:global_step/sec: 47.8206\n","INFO:tensorflow:examples/sec: 191.283\n","INFO:tensorflow:global_step/sec: 48.0536\n","INFO:tensorflow:examples/sec: 192.215\n","INFO:tensorflow:global_step/sec: 51.4254\n","INFO:tensorflow:examples/sec: 205.702\n","INFO:tensorflow:global_step/sec: 51.5901\n","INFO:tensorflow:examples/sec: 206.36\n","INFO:tensorflow:global_step/sec: 51.4824\n","INFO:tensorflow:examples/sec: 205.929\n","INFO:tensorflow:global_step/sec: 51.7897\n","INFO:tensorflow:examples/sec: 207.159\n","INFO:tensorflow:Saving checkpoints for 16000 into /content/trained_output/model.ckpt.\n","INFO:tensorflow:global_step/sec: 36.3372\n","INFO:tensorflow:examples/sec: 145.349\n","INFO:tensorflow:global_step/sec: 47.416\n","INFO:tensorflow:examples/sec: 189.664\n","INFO:tensorflow:global_step/sec: 47.4745\n","INFO:tensorflow:examples/sec: 189.898\n","INFO:tensorflow:global_step/sec: 47.0244\n","INFO:tensorflow:examples/sec: 188.098\n","INFO:tensorflow:global_step/sec: 50.0319\n","INFO:tensorflow:examples/sec: 200.128\n","INFO:tensorflow:global_step/sec: 52.1313\n","INFO:tensorflow:examples/sec: 208.525\n","INFO:tensorflow:global_step/sec: 52.4564\n","INFO:tensorflow:examples/sec: 209.825\n","INFO:tensorflow:global_step/sec: 51.7528\n","INFO:tensorflow:examples/sec: 207.011\n","INFO:tensorflow:global_step/sec: 52.0627\n","INFO:tensorflow:examples/sec: 208.251\n","INFO:tensorflow:global_step/sec: 50.4178\n","INFO:tensorflow:examples/sec: 201.671\n","INFO:tensorflow:Saving checkpoints for 17000 into /content/trained_output/model.ckpt.\n","INFO:tensorflow:global_step/sec: 35.5883\n","INFO:tensorflow:examples/sec: 142.353\n","INFO:tensorflow:global_step/sec: 47.7574\n","INFO:tensorflow:examples/sec: 191.03\n","INFO:tensorflow:global_step/sec: 49.0827\n","INFO:tensorflow:examples/sec: 196.331\n","INFO:tensorflow:global_step/sec: 52.4999\n","INFO:tensorflow:examples/sec: 210\n","INFO:tensorflow:global_step/sec: 52.433\n","INFO:tensorflow:examples/sec: 209.732\n","INFO:tensorflow:global_step/sec: 52.3665\n","INFO:tensorflow:examples/sec: 209.466\n","INFO:tensorflow:global_step/sec: 52.3705\n","INFO:tensorflow:examples/sec: 209.482\n","INFO:tensorflow:global_step/sec: 52.1306\n","INFO:tensorflow:examples/sec: 208.523\n","INFO:tensorflow:global_step/sec: 50.2468\n","INFO:tensorflow:examples/sec: 200.987\n","INFO:tensorflow:global_step/sec: 49.4302\n","INFO:tensorflow:examples/sec: 197.721\n","INFO:tensorflow:Saving checkpoints for 18000 into /content/trained_output/model.ckpt.\n","INFO:tensorflow:global_step/sec: 36.3193\n","INFO:tensorflow:examples/sec: 145.277\n","INFO:tensorflow:global_step/sec: 49.8164\n","INFO:tensorflow:examples/sec: 199.266\n","INFO:tensorflow:global_step/sec: 52.2778\n","INFO:tensorflow:examples/sec: 209.111\n","INFO:tensorflow:global_step/sec: 52.2284\n","INFO:tensorflow:examples/sec: 208.914\n","INFO:tensorflow:global_step/sec: 52.4187\n","INFO:tensorflow:examples/sec: 209.675\n","INFO:tensorflow:global_step/sec: 52.5881\n","INFO:tensorflow:examples/sec: 210.353\n","INFO:tensorflow:global_step/sec: 51.4982\n","INFO:tensorflow:examples/sec: 205.993\n","INFO:tensorflow:global_step/sec: 49.5388\n","INFO:tensorflow:examples/sec: 198.155\n","INFO:tensorflow:global_step/sec: 48.4036\n","INFO:tensorflow:examples/sec: 193.614\n","INFO:tensorflow:global_step/sec: 49.4725\n","INFO:tensorflow:examples/sec: 197.89\n","INFO:tensorflow:Saving checkpoints for 19000 into /content/trained_output/model.ckpt.\n","INFO:tensorflow:global_step/sec: 40.3563\n","INFO:tensorflow:examples/sec: 161.425\n","INFO:tensorflow:global_step/sec: 52.1214\n","INFO:tensorflow:examples/sec: 208.486\n","INFO:tensorflow:global_step/sec: 52.0335\n","INFO:tensorflow:examples/sec: 208.134\n","INFO:tensorflow:global_step/sec: 52.2406\n","INFO:tensorflow:examples/sec: 208.962\n","INFO:tensorflow:global_step/sec: 52.1161\n","INFO:tensorflow:examples/sec: 208.464\n","INFO:tensorflow:global_step/sec: 50.5635\n","INFO:tensorflow:examples/sec: 202.254\n","INFO:tensorflow:global_step/sec: 48.6096\n","INFO:tensorflow:examples/sec: 194.438\n","INFO:tensorflow:global_step/sec: 48.8776\n","INFO:tensorflow:examples/sec: 195.51\n","INFO:tensorflow:global_step/sec: 48.9326\n","INFO:tensorflow:examples/sec: 195.731\n","INFO:tensorflow:global_step/sec: 51.1671\n","INFO:tensorflow:examples/sec: 204.668\n","INFO:tensorflow:Saving checkpoints for 20000 into /content/trained_output/model.ckpt.\n","INFO:tensorflow:global_step/sec: 41.2032\n","INFO:tensorflow:examples/sec: 164.813\n","INFO:tensorflow:global_step/sec: 52.1409\n","INFO:tensorflow:examples/sec: 208.564\n","INFO:tensorflow:global_step/sec: 52.2503\n","INFO:tensorflow:examples/sec: 209.001\n","INFO:tensorflow:global_step/sec: 52.507\n","INFO:tensorflow:examples/sec: 210.028\n","INFO:tensorflow:global_step/sec: 49.6008\n","INFO:tensorflow:examples/sec: 198.403\n","INFO:tensorflow:global_step/sec: 48.6549\n","INFO:tensorflow:examples/sec: 194.62\n","INFO:tensorflow:global_step/sec: 48.5547\n","INFO:tensorflow:examples/sec: 194.219\n","INFO:tensorflow:global_step/sec: 49.3004\n","INFO:tensorflow:examples/sec: 197.202\n","INFO:tensorflow:global_step/sec: 52.2242\n","INFO:tensorflow:examples/sec: 208.897\n","INFO:tensorflow:global_step/sec: 52.1391\n","INFO:tensorflow:examples/sec: 208.556\n","INFO:tensorflow:Saving checkpoints for 21000 into /content/trained_output/model.ckpt.\n","INFO:tensorflow:global_step/sec: 41.5955\n","INFO:tensorflow:examples/sec: 166.382\n","INFO:tensorflow:global_step/sec: 52.3112\n","INFO:tensorflow:examples/sec: 209.245\n","INFO:tensorflow:global_step/sec: 51.2992\n","INFO:tensorflow:examples/sec: 205.197\n","INFO:tensorflow:global_step/sec: 49.5045\n","INFO:tensorflow:examples/sec: 198.018\n","INFO:tensorflow:global_step/sec: 49.0406\n","INFO:tensorflow:examples/sec: 196.162\n","INFO:tensorflow:global_step/sec: 48.8214\n","INFO:tensorflow:examples/sec: 195.286\n","INFO:tensorflow:global_step/sec: 50.1644\n","INFO:tensorflow:examples/sec: 200.658\n","INFO:tensorflow:global_step/sec: 52.2425\n","INFO:tensorflow:examples/sec: 208.97\n","INFO:tensorflow:global_step/sec: 52.4398\n","INFO:tensorflow:examples/sec: 209.759\n","INFO:tensorflow:global_step/sec: 52.3605\n","INFO:tensorflow:examples/sec: 209.442\n","INFO:tensorflow:Saving checkpoints for 22000 into /content/trained_output/model.ckpt.\n","INFO:tensorflow:global_step/sec: 41.7153\n","INFO:tensorflow:examples/sec: 166.861\n","INFO:tensorflow:global_step/sec: 50.5916\n","INFO:tensorflow:examples/sec: 202.366\n","INFO:tensorflow:global_step/sec: 48.9961\n","INFO:tensorflow:examples/sec: 195.984\n","INFO:tensorflow:global_step/sec: 48.5071\n","INFO:tensorflow:examples/sec: 194.028\n","INFO:tensorflow:global_step/sec: 48.2684\n","INFO:tensorflow:examples/sec: 193.074\n","INFO:tensorflow:global_step/sec: 51.1689\n","INFO:tensorflow:examples/sec: 204.676\n","INFO:tensorflow:global_step/sec: 52.4414\n","INFO:tensorflow:examples/sec: 209.766\n","INFO:tensorflow:global_step/sec: 52.0854\n","INFO:tensorflow:examples/sec: 208.341\n","INFO:tensorflow:global_step/sec: 52.247\n","INFO:tensorflow:examples/sec: 208.988\n","INFO:tensorflow:global_step/sec: 52.3106\n","INFO:tensorflow:examples/sec: 209.242\n","INFO:tensorflow:Saving checkpoints for 23000 into /content/trained_output/model.ckpt.\n","INFO:tensorflow:global_step/sec: 35.9982\n","INFO:tensorflow:examples/sec: 143.993\n","INFO:tensorflow:global_step/sec: 48.8469\n","INFO:tensorflow:examples/sec: 195.388\n","INFO:tensorflow:global_step/sec: 48.7938\n","INFO:tensorflow:examples/sec: 195.175\n","INFO:tensorflow:global_step/sec: 49.6091\n","INFO:tensorflow:examples/sec: 198.436\n","INFO:tensorflow:global_step/sec: 52.4293\n","INFO:tensorflow:examples/sec: 209.717\n","INFO:tensorflow:global_step/sec: 52.0827\n","INFO:tensorflow:examples/sec: 208.331\n","INFO:tensorflow:global_step/sec: 52.3505\n","INFO:tensorflow:examples/sec: 209.402\n","INFO:tensorflow:global_step/sec: 52.5462\n","INFO:tensorflow:examples/sec: 210.185\n","INFO:tensorflow:global_step/sec: 52.3565\n","INFO:tensorflow:examples/sec: 209.426\n","INFO:tensorflow:global_step/sec: 49.2773\n","INFO:tensorflow:examples/sec: 197.109\n","INFO:tensorflow:Saving checkpoints for 24000 into /content/trained_output/model.ckpt.\n","INFO:tensorflow:global_step/sec: 35.8856\n","INFO:tensorflow:examples/sec: 143.542\n","INFO:tensorflow:global_step/sec: 48.3801\n","INFO:tensorflow:examples/sec: 193.52\n","INFO:tensorflow:global_step/sec: 50.761\n","INFO:tensorflow:examples/sec: 203.044\n","INFO:tensorflow:global_step/sec: 52.2293\n","INFO:tensorflow:examples/sec: 208.917\n","INFO:tensorflow:global_step/sec: 52.4134\n","INFO:tensorflow:examples/sec: 209.654\n","INFO:tensorflow:global_step/sec: 52.3535\n","INFO:tensorflow:examples/sec: 209.414\n","INFO:tensorflow:global_step/sec: 52.3049\n","INFO:tensorflow:examples/sec: 209.22\n","INFO:tensorflow:global_step/sec: 50.7425\n","INFO:tensorflow:examples/sec: 202.97\n","INFO:tensorflow:global_step/sec: 48.383\n","INFO:tensorflow:examples/sec: 193.532\n","INFO:tensorflow:global_step/sec: 49.1063\n","INFO:tensorflow:examples/sec: 196.425\n","INFO:tensorflow:Saving checkpoints for 25000 into /content/trained_output/model.ckpt.\n","INFO:tensorflow:global_step/sec: 35.3772\n","INFO:tensorflow:examples/sec: 141.509\n","INFO:tensorflow:global_step/sec: 52.1122\n","INFO:tensorflow:examples/sec: 208.449\n","INFO:tensorflow:global_step/sec: 52.32\n","INFO:tensorflow:examples/sec: 209.28\n","INFO:tensorflow:global_step/sec: 51.9071\n","INFO:tensorflow:examples/sec: 207.629\n","INFO:tensorflow:global_step/sec: 52.2897\n","INFO:tensorflow:examples/sec: 209.159\n","INFO:tensorflow:global_step/sec: 52.5259\n","INFO:tensorflow:examples/sec: 210.103\n","INFO:tensorflow:global_step/sec: 49.7907\n","INFO:tensorflow:examples/sec: 199.163\n","INFO:tensorflow:global_step/sec: 48.3491\n","INFO:tensorflow:examples/sec: 193.396\n","INFO:tensorflow:global_step/sec: 49.177\n","INFO:tensorflow:examples/sec: 196.708\n","INFO:tensorflow:global_step/sec: 49.3499\n","INFO:tensorflow:examples/sec: 197.4\n","INFO:tensorflow:Saving checkpoints for 26000 into /content/trained_output/model.ckpt.\n","INFO:tensorflow:global_step/sec: 40.7296\n","INFO:tensorflow:examples/sec: 162.918\n","INFO:tensorflow:global_step/sec: 51.4864\n","INFO:tensorflow:examples/sec: 205.946\n","INFO:tensorflow:global_step/sec: 51.5779\n","INFO:tensorflow:examples/sec: 206.311\n","INFO:tensorflow:global_step/sec: 51.6172\n","INFO:tensorflow:examples/sec: 206.469\n","INFO:tensorflow:global_step/sec: 51.1253\n","INFO:tensorflow:examples/sec: 204.501\n","INFO:tensorflow:global_step/sec: 49.408\n","INFO:tensorflow:examples/sec: 197.632\n","INFO:tensorflow:global_step/sec: 48.0614\n","INFO:tensorflow:examples/sec: 192.246\n","INFO:tensorflow:global_step/sec: 47.8329\n","INFO:tensorflow:examples/sec: 191.332\n","INFO:tensorflow:global_step/sec: 48.9008\n","INFO:tensorflow:examples/sec: 195.603\n","INFO:tensorflow:global_step/sec: 51.893\n","INFO:tensorflow:examples/sec: 207.572\n","INFO:tensorflow:Saving checkpoints for 27000 into /content/trained_output/model.ckpt.\n","INFO:tensorflow:global_step/sec: 34.4867\n","INFO:tensorflow:examples/sec: 137.947\n","INFO:tensorflow:global_step/sec: 51.9795\n","INFO:tensorflow:examples/sec: 207.918\n","INFO:tensorflow:global_step/sec: 51.888\n","INFO:tensorflow:examples/sec: 207.552\n","INFO:tensorflow:global_step/sec: 47.9079\n","INFO:tensorflow:examples/sec: 191.631\n","INFO:tensorflow:global_step/sec: 47.817\n","INFO:tensorflow:examples/sec: 191.268\n","INFO:tensorflow:global_step/sec: 48.2933\n","INFO:tensorflow:examples/sec: 193.173\n","INFO:tensorflow:global_step/sec: 48.5115\n","INFO:tensorflow:examples/sec: 194.046\n","INFO:tensorflow:global_step/sec: 52.0372\n","INFO:tensorflow:examples/sec: 208.149\n","INFO:tensorflow:global_step/sec: 51.9285\n","INFO:tensorflow:examples/sec: 207.714\n","INFO:tensorflow:global_step/sec: 51.6225\n","INFO:tensorflow:examples/sec: 206.49\n","INFO:tensorflow:Saving checkpoints for 28000 into /content/trained_output/model.ckpt.\n","INFO:tensorflow:global_step/sec: 40.5006\n","INFO:tensorflow:examples/sec: 162.002\n","INFO:tensorflow:global_step/sec: 50.5901\n","INFO:tensorflow:examples/sec: 202.36\n","INFO:tensorflow:global_step/sec: 48.5503\n","INFO:tensorflow:examples/sec: 194.201\n","INFO:tensorflow:global_step/sec: 48.5844\n","INFO:tensorflow:examples/sec: 194.338\n","INFO:tensorflow:global_step/sec: 49.4449\n","INFO:tensorflow:examples/sec: 197.779\n","INFO:tensorflow:global_step/sec: 50.638\n","INFO:tensorflow:examples/sec: 202.552\n","INFO:tensorflow:global_step/sec: 52.1404\n","INFO:tensorflow:examples/sec: 208.561\n","INFO:tensorflow:global_step/sec: 52.1706\n","INFO:tensorflow:examples/sec: 208.682\n","INFO:tensorflow:global_step/sec: 52.3279\n","INFO:tensorflow:examples/sec: 209.312\n","INFO:tensorflow:global_step/sec: 52.0004\n","INFO:tensorflow:examples/sec: 208.001\n","INFO:tensorflow:Saving checkpoints for 29000 into /content/trained_output/model.ckpt.\n","INFO:tensorflow:global_step/sec: 35.3593\n","INFO:tensorflow:examples/sec: 141.437\n","INFO:tensorflow:global_step/sec: 48.316\n","INFO:tensorflow:examples/sec: 193.264\n","INFO:tensorflow:global_step/sec: 48.7226\n","INFO:tensorflow:examples/sec: 194.89\n","INFO:tensorflow:global_step/sec: 48.3399\n","INFO:tensorflow:examples/sec: 193.359\n","INFO:tensorflow:global_step/sec: 52.3283\n","INFO:tensorflow:examples/sec: 209.313\n","INFO:tensorflow:global_step/sec: 52.1607\n","INFO:tensorflow:examples/sec: 208.643\n","INFO:tensorflow:global_step/sec: 52.1729\n","INFO:tensorflow:examples/sec: 208.692\n","INFO:tensorflow:global_step/sec: 52.0558\n","INFO:tensorflow:examples/sec: 208.223\n","INFO:tensorflow:global_step/sec: 52.1411\n","INFO:tensorflow:examples/sec: 208.564\n","INFO:tensorflow:global_step/sec: 48.6658\n","INFO:tensorflow:examples/sec: 194.663\n","INFO:tensorflow:Saving checkpoints for 30000 into /content/trained_output/model.ckpt.\n","INFO:tensorflow:global_step/sec: 35.291\n","INFO:tensorflow:examples/sec: 141.164\n","INFO:tensorflow:global_step/sec: 47.665\n","INFO:tensorflow:examples/sec: 190.66\n","INFO:tensorflow:global_step/sec: 50.4347\n","INFO:tensorflow:examples/sec: 201.739\n","INFO:tensorflow:global_step/sec: 52.2415\n","INFO:tensorflow:examples/sec: 208.966\n","INFO:tensorflow:global_step/sec: 52.4907\n","INFO:tensorflow:examples/sec: 209.963\n","INFO:tensorflow:global_step/sec: 52.3452\n","INFO:tensorflow:examples/sec: 209.381\n","INFO:tensorflow:global_step/sec: 52.4067\n","INFO:tensorflow:examples/sec: 209.627\n","INFO:tensorflow:global_step/sec: 51.2786\n","INFO:tensorflow:examples/sec: 205.114\n","INFO:tensorflow:global_step/sec: 49.017\n","INFO:tensorflow:examples/sec: 196.068\n","INFO:tensorflow:global_step/sec: 48.6751\n","INFO:tensorflow:examples/sec: 194.701\n","INFO:tensorflow:Saving checkpoints for 31000 into /content/trained_output/model.ckpt.\n","INFO:tensorflow:global_step/sec: 34.9203\n","INFO:tensorflow:examples/sec: 139.681\n","INFO:tensorflow:global_step/sec: 51.8188\n","INFO:tensorflow:examples/sec: 207.275\n","INFO:tensorflow:global_step/sec: 52.3337\n","INFO:tensorflow:examples/sec: 209.335\n","INFO:tensorflow:global_step/sec: 52.3945\n","INFO:tensorflow:examples/sec: 209.578\n","INFO:tensorflow:global_step/sec: 52.3382\n","INFO:tensorflow:examples/sec: 209.353\n","INFO:tensorflow:global_step/sec: 52.3712\n","INFO:tensorflow:examples/sec: 209.485\n","INFO:tensorflow:global_step/sec: 49.5099\n","INFO:tensorflow:examples/sec: 198.039\n","INFO:tensorflow:global_step/sec: 48.9307\n","INFO:tensorflow:examples/sec: 195.723\n","INFO:tensorflow:global_step/sec: 49.3734\n","INFO:tensorflow:examples/sec: 197.494\n","INFO:tensorflow:global_step/sec: 48.7649\n","INFO:tensorflow:examples/sec: 195.06\n","INFO:tensorflow:Saving checkpoints for 32000 into /content/trained_output/model.ckpt.\n","INFO:tensorflow:global_step/sec: 41.3363\n","INFO:tensorflow:examples/sec: 165.345\n","INFO:tensorflow:global_step/sec: 52.1029\n","INFO:tensorflow:examples/sec: 208.411\n","INFO:tensorflow:global_step/sec: 52.4247\n","INFO:tensorflow:examples/sec: 209.699\n","INFO:tensorflow:global_step/sec: 52.2519\n","INFO:tensorflow:examples/sec: 209.007\n","INFO:tensorflow:global_step/sec: 51.961\n","INFO:tensorflow:examples/sec: 207.844\n","INFO:tensorflow:global_step/sec: 49.3031\n","INFO:tensorflow:examples/sec: 197.212\n","INFO:tensorflow:global_step/sec: 48.6629\n","INFO:tensorflow:examples/sec: 194.652\n","INFO:tensorflow:global_step/sec: 48.7335\n","INFO:tensorflow:examples/sec: 194.934\n","INFO:tensorflow:global_step/sec: 49.6329\n","INFO:tensorflow:examples/sec: 198.531\n","INFO:tensorflow:global_step/sec: 52.2624\n","INFO:tensorflow:examples/sec: 209.05\n","INFO:tensorflow:Saving checkpoints for 33000 into /content/trained_output/model.ckpt.\n","INFO:tensorflow:global_step/sec: 40.6646\n","INFO:tensorflow:examples/sec: 162.659\n","INFO:tensorflow:global_step/sec: 51.8738\n","INFO:tensorflow:examples/sec: 207.495\n","INFO:tensorflow:global_step/sec: 52.1303\n","INFO:tensorflow:examples/sec: 208.521\n","INFO:tensorflow:global_step/sec: 51.2631\n","INFO:tensorflow:examples/sec: 205.053\n","INFO:tensorflow:global_step/sec: 48.2108\n","INFO:tensorflow:examples/sec: 192.843\n","INFO:tensorflow:global_step/sec: 49.3651\n","INFO:tensorflow:examples/sec: 197.46\n","INFO:tensorflow:global_step/sec: 48.175\n","INFO:tensorflow:examples/sec: 192.7\n","INFO:tensorflow:global_step/sec: 50.9218\n","INFO:tensorflow:examples/sec: 203.687\n","INFO:tensorflow:global_step/sec: 52.2023\n","INFO:tensorflow:examples/sec: 208.809\n","INFO:tensorflow:global_step/sec: 52.2556\n","INFO:tensorflow:examples/sec: 209.022\n","INFO:tensorflow:Saving checkpoints for 34000 into /content/trained_output/model.ckpt.\n","INFO:tensorflow:global_step/sec: 40.3956\n","INFO:tensorflow:examples/sec: 161.583\n","INFO:tensorflow:global_step/sec: 52.0888\n","INFO:tensorflow:examples/sec: 208.355\n","INFO:tensorflow:global_step/sec: 50.3576\n","INFO:tensorflow:examples/sec: 201.43\n","INFO:tensorflow:global_step/sec: 48.5954\n","INFO:tensorflow:examples/sec: 194.382\n","INFO:tensorflow:global_step/sec: 49.0561\n","INFO:tensorflow:examples/sec: 196.224\n","INFO:tensorflow:global_step/sec: 48.8607\n","INFO:tensorflow:examples/sec: 195.443\n","INFO:tensorflow:global_step/sec: 51.4798\n","INFO:tensorflow:examples/sec: 205.919\n","INFO:tensorflow:global_step/sec: 52.3776\n","INFO:tensorflow:examples/sec: 209.51\n","INFO:tensorflow:global_step/sec: 52.3696\n","INFO:tensorflow:examples/sec: 209.478\n","INFO:tensorflow:global_step/sec: 52.4853\n","INFO:tensorflow:examples/sec: 209.941\n","INFO:tensorflow:Saving checkpoints for 35000 into /content/trained_output/model.ckpt.\n","INFO:tensorflow:global_step/sec: 41.252\n","INFO:tensorflow:examples/sec: 165.008\n","INFO:tensorflow:global_step/sec: 49.0231\n","INFO:tensorflow:examples/sec: 196.092\n","INFO:tensorflow:global_step/sec: 49.3341\n","INFO:tensorflow:examples/sec: 197.336\n","INFO:tensorflow:global_step/sec: 48.7319\n","INFO:tensorflow:examples/sec: 194.928\n","INFO:tensorflow:global_step/sec: 49.8405\n","INFO:tensorflow:examples/sec: 199.362\n","INFO:tensorflow:global_step/sec: 52.3311\n","INFO:tensorflow:examples/sec: 209.324\n","INFO:tensorflow:global_step/sec: 52.0028\n","INFO:tensorflow:examples/sec: 208.011\n","INFO:tensorflow:global_step/sec: 52.369\n","INFO:tensorflow:examples/sec: 209.476\n","INFO:tensorflow:global_step/sec: 52.0507\n","INFO:tensorflow:examples/sec: 208.203\n","INFO:tensorflow:global_step/sec: 52.4441\n","INFO:tensorflow:examples/sec: 209.776\n","INFO:tensorflow:Saving checkpoints for 36000 into /content/trained_output/model.ckpt.\n","INFO:tensorflow:global_step/sec: 35.0273\n","INFO:tensorflow:examples/sec: 140.109\n","INFO:tensorflow:global_step/sec: 48.3403\n","INFO:tensorflow:examples/sec: 193.361\n","INFO:tensorflow:global_step/sec: 48.717\n","INFO:tensorflow:examples/sec: 194.868\n","INFO:tensorflow:global_step/sec: 51.106\n","INFO:tensorflow:examples/sec: 204.424\n","INFO:tensorflow:global_step/sec: 52.2853\n","INFO:tensorflow:examples/sec: 209.141\n","INFO:tensorflow:global_step/sec: 52.3596\n","INFO:tensorflow:examples/sec: 209.438\n","INFO:tensorflow:global_step/sec: 52.2967\n","INFO:tensorflow:examples/sec: 209.187\n","INFO:tensorflow:global_step/sec: 52.1912\n","INFO:tensorflow:examples/sec: 208.765\n","INFO:tensorflow:global_step/sec: 50.7982\n","INFO:tensorflow:examples/sec: 203.193\n","INFO:tensorflow:global_step/sec: 49.1546\n","INFO:tensorflow:examples/sec: 196.618\n","INFO:tensorflow:Saving checkpoints for 37000 into /content/trained_output/model.ckpt.\n","INFO:tensorflow:global_step/sec: 34.8099\n","INFO:tensorflow:examples/sec: 139.239\n","INFO:tensorflow:global_step/sec: 48.926\n","INFO:tensorflow:examples/sec: 195.704\n","INFO:tensorflow:global_step/sec: 52.1134\n","INFO:tensorflow:examples/sec: 208.454\n","INFO:tensorflow:global_step/sec: 52.2541\n","INFO:tensorflow:examples/sec: 209.017\n","INFO:tensorflow:global_step/sec: 52.5061\n","INFO:tensorflow:examples/sec: 210.024\n","INFO:tensorflow:global_step/sec: 52.4244\n","INFO:tensorflow:examples/sec: 209.698\n","INFO:tensorflow:global_step/sec: 52.2046\n","INFO:tensorflow:examples/sec: 208.818\n","INFO:tensorflow:global_step/sec: 49.5587\n","INFO:tensorflow:examples/sec: 198.235\n","INFO:tensorflow:global_step/sec: 48.8589\n","INFO:tensorflow:examples/sec: 195.436\n","INFO:tensorflow:global_step/sec: 48.9237\n","INFO:tensorflow:examples/sec: 195.695\n","INFO:tensorflow:Saving checkpoints for 38000 into /content/trained_output/model.ckpt.\n","INFO:tensorflow:global_step/sec: 38.7362\n","INFO:tensorflow:examples/sec: 154.945\n","INFO:tensorflow:global_step/sec: 52.0395\n","INFO:tensorflow:examples/sec: 208.158\n","INFO:tensorflow:global_step/sec: 51.5234\n","INFO:tensorflow:examples/sec: 206.094\n","INFO:tensorflow:global_step/sec: 51.7645\n","INFO:tensorflow:examples/sec: 207.058\n","INFO:tensorflow:global_step/sec: 51.8108\n","INFO:tensorflow:examples/sec: 207.243\n","INFO:tensorflow:global_step/sec: 50.903\n","INFO:tensorflow:examples/sec: 203.612\n","INFO:tensorflow:global_step/sec: 48.2741\n","INFO:tensorflow:examples/sec: 193.096\n","INFO:tensorflow:global_step/sec: 47.8681\n","INFO:tensorflow:examples/sec: 191.472\n","INFO:tensorflow:global_step/sec: 47.9203\n","INFO:tensorflow:examples/sec: 191.681\n","INFO:tensorflow:global_step/sec: 50.411\n","INFO:tensorflow:examples/sec: 201.644\n","INFO:tensorflow:Saving checkpoints for 39000 into /content/trained_output/model.ckpt.\n","INFO:tensorflow:global_step/sec: 40.6335\n","INFO:tensorflow:examples/sec: 162.534\n","INFO:tensorflow:global_step/sec: 51.5113\n","INFO:tensorflow:examples/sec: 206.045\n","INFO:tensorflow:global_step/sec: 51.7045\n","INFO:tensorflow:examples/sec: 206.818\n","INFO:tensorflow:global_step/sec: 51.8253\n","INFO:tensorflow:examples/sec: 207.301\n","INFO:tensorflow:global_step/sec: 49.1632\n","INFO:tensorflow:examples/sec: 196.653\n","INFO:tensorflow:global_step/sec: 47.5447\n","INFO:tensorflow:examples/sec: 190.179\n","INFO:tensorflow:global_step/sec: 47.9823\n","INFO:tensorflow:examples/sec: 191.929\n","INFO:tensorflow:global_step/sec: 47.4979\n","INFO:tensorflow:examples/sec: 189.992\n","INFO:tensorflow:global_step/sec: 51.8032\n","INFO:tensorflow:examples/sec: 207.213\n","INFO:tensorflow:global_step/sec: 51.5941\n","INFO:tensorflow:examples/sec: 206.377\n","INFO:tensorflow:Saving checkpoints for 40000 into /content/trained_output/model.ckpt.\n","INFO:tensorflow:global_step/sec: 40.491\n","INFO:tensorflow:examples/sec: 161.964\n","INFO:tensorflow:global_step/sec: 51.7645\n","INFO:tensorflow:examples/sec: 207.058\n","INFO:tensorflow:global_step/sec: 51.4359\n","INFO:tensorflow:examples/sec: 205.744\n","INFO:tensorflow:global_step/sec: 49.5558\n","INFO:tensorflow:examples/sec: 198.223\n","INFO:tensorflow:global_step/sec: 49.0484\n","INFO:tensorflow:examples/sec: 196.193\n","INFO:tensorflow:global_step/sec: 48.5735\n","INFO:tensorflow:examples/sec: 194.294\n","INFO:tensorflow:global_step/sec: 49.4649\n","INFO:tensorflow:examples/sec: 197.86\n","INFO:tensorflow:global_step/sec: 52.5107\n","INFO:tensorflow:examples/sec: 210.043\n","INFO:tensorflow:global_step/sec: 52.5175\n","INFO:tensorflow:examples/sec: 210.07\n","INFO:tensorflow:global_step/sec: 52.1935\n","INFO:tensorflow:examples/sec: 208.774\n","INFO:tensorflow:Saving checkpoints for 41000 into /content/trained_output/model.ckpt.\n","INFO:tensorflow:global_step/sec: 41.047\n","INFO:tensorflow:examples/sec: 164.188\n","INFO:tensorflow:global_step/sec: 50.8911\n","INFO:tensorflow:examples/sec: 203.564\n","INFO:tensorflow:global_step/sec: 48.5861\n","INFO:tensorflow:examples/sec: 194.344\n","INFO:tensorflow:global_step/sec: 48.8608\n","INFO:tensorflow:examples/sec: 195.443\n","INFO:tensorflow:global_step/sec: 49.3436\n","INFO:tensorflow:examples/sec: 197.375\n","INFO:tensorflow:global_step/sec: 51.7575\n","INFO:tensorflow:examples/sec: 207.03\n","INFO:tensorflow:global_step/sec: 52.5493\n","INFO:tensorflow:examples/sec: 210.197\n","INFO:tensorflow:global_step/sec: 52.2948\n","INFO:tensorflow:examples/sec: 209.179\n","INFO:tensorflow:global_step/sec: 52.3721\n","INFO:tensorflow:examples/sec: 209.488\n","INFO:tensorflow:global_step/sec: 52.5019\n","INFO:tensorflow:examples/sec: 210.008\n","INFO:tensorflow:Saving checkpoints for 42000 into /content/trained_output/model.ckpt.\n","INFO:tensorflow:global_step/sec: 36.4428\n","INFO:tensorflow:examples/sec: 145.771\n","INFO:tensorflow:global_step/sec: 48.4358\n","INFO:tensorflow:examples/sec: 193.743\n","INFO:tensorflow:global_step/sec: 48.7006\n","INFO:tensorflow:examples/sec: 194.802\n","INFO:tensorflow:global_step/sec: 48.9773\n","INFO:tensorflow:examples/sec: 195.909\n","INFO:tensorflow:global_step/sec: 52.5184\n","INFO:tensorflow:examples/sec: 210.074\n","INFO:tensorflow:global_step/sec: 52.3992\n","INFO:tensorflow:examples/sec: 209.597\n","INFO:tensorflow:global_step/sec: 52.5056\n","INFO:tensorflow:examples/sec: 210.023\n","INFO:tensorflow:global_step/sec: 52.4613\n","INFO:tensorflow:examples/sec: 209.845\n","INFO:tensorflow:global_step/sec: 52.5139\n","INFO:tensorflow:examples/sec: 210.056\n","INFO:tensorflow:global_step/sec: 49.9746\n","INFO:tensorflow:examples/sec: 199.898\n","INFO:tensorflow:Saving checkpoints for 43000 into /content/trained_output/model.ckpt.\n","INFO:tensorflow:global_step/sec: 35.6034\n","INFO:tensorflow:examples/sec: 142.414\n","INFO:tensorflow:global_step/sec: 48.755\n","INFO:tensorflow:examples/sec: 195.02\n","INFO:tensorflow:global_step/sec: 49.9547\n","INFO:tensorflow:examples/sec: 199.819\n","INFO:tensorflow:global_step/sec: 52.2318\n","INFO:tensorflow:examples/sec: 208.927\n","INFO:tensorflow:global_step/sec: 52.4651\n","INFO:tensorflow:examples/sec: 209.861\n","INFO:tensorflow:global_step/sec: 52.1625\n","INFO:tensorflow:examples/sec: 208.65\n","INFO:tensorflow:global_step/sec: 52.3666\n","INFO:tensorflow:examples/sec: 209.466\n","INFO:tensorflow:global_step/sec: 51.6384\n","INFO:tensorflow:examples/sec: 206.553\n","INFO:tensorflow:global_step/sec: 49.9423\n","INFO:tensorflow:examples/sec: 199.769\n","INFO:tensorflow:global_step/sec: 48.7769\n","INFO:tensorflow:examples/sec: 195.108\n","INFO:tensorflow:Saving checkpoints for 44000 into /content/trained_output/model.ckpt.\n","INFO:tensorflow:global_step/sec: 35.5643\n","INFO:tensorflow:examples/sec: 142.257\n","INFO:tensorflow:global_step/sec: 51.3838\n","INFO:tensorflow:examples/sec: 205.535\n","INFO:tensorflow:global_step/sec: 52.1228\n","INFO:tensorflow:examples/sec: 208.491\n","INFO:tensorflow:global_step/sec: 52.4618\n","INFO:tensorflow:examples/sec: 209.847\n","INFO:tensorflow:global_step/sec: 52.1091\n","INFO:tensorflow:examples/sec: 208.437\n","INFO:tensorflow:global_step/sec: 52.1712\n","INFO:tensorflow:examples/sec: 208.685\n","INFO:tensorflow:global_step/sec: 50.1258\n","INFO:tensorflow:examples/sec: 200.503\n","INFO:tensorflow:global_step/sec: 48.9535\n","INFO:tensorflow:examples/sec: 195.814\n","INFO:tensorflow:global_step/sec: 48.6552\n","INFO:tensorflow:examples/sec: 194.621\n","INFO:tensorflow:global_step/sec: 48.6896\n","INFO:tensorflow:examples/sec: 194.758\n","INFO:tensorflow:Saving checkpoints for 45000 into /content/trained_output/model.ckpt.\n","INFO:tensorflow:global_step/sec: 40.4638\n","INFO:tensorflow:examples/sec: 161.855\n","INFO:tensorflow:global_step/sec: 52.1495\n","INFO:tensorflow:examples/sec: 208.598\n","INFO:tensorflow:global_step/sec: 52.1215\n","INFO:tensorflow:examples/sec: 208.486\n","INFO:tensorflow:global_step/sec: 52.5227\n","INFO:tensorflow:examples/sec: 210.091\n","INFO:tensorflow:global_step/sec: 52.3509\n","INFO:tensorflow:examples/sec: 209.403\n","INFO:tensorflow:global_step/sec: 49.2467\n","INFO:tensorflow:examples/sec: 196.987\n","INFO:tensorflow:global_step/sec: 49.4586\n","INFO:tensorflow:examples/sec: 197.834\n","INFO:tensorflow:global_step/sec: 49.0104\n","INFO:tensorflow:examples/sec: 196.042\n","INFO:tensorflow:global_step/sec: 50.1791\n","INFO:tensorflow:examples/sec: 200.717\n","INFO:tensorflow:global_step/sec: 52.1975\n","INFO:tensorflow:examples/sec: 208.79\n","INFO:tensorflow:Saving checkpoints for 46000 into /content/trained_output/model.ckpt.\n","INFO:tensorflow:global_step/sec: 41.3585\n","INFO:tensorflow:examples/sec: 165.434\n","INFO:tensorflow:global_step/sec: 52.2516\n","INFO:tensorflow:examples/sec: 209.007\n","INFO:tensorflow:global_step/sec: 52.1072\n","INFO:tensorflow:examples/sec: 208.429\n","INFO:tensorflow:global_step/sec: 51.6572\n","INFO:tensorflow:examples/sec: 206.629\n","INFO:tensorflow:global_step/sec: 49.4584\n","INFO:tensorflow:examples/sec: 197.834\n","INFO:tensorflow:global_step/sec: 48.9868\n","INFO:tensorflow:examples/sec: 195.947\n","INFO:tensorflow:global_step/sec: 49.4937\n","INFO:tensorflow:examples/sec: 197.975\n","INFO:tensorflow:global_step/sec: 49.8246\n","INFO:tensorflow:examples/sec: 199.298\n","INFO:tensorflow:global_step/sec: 51.3804\n","INFO:tensorflow:examples/sec: 205.521\n","INFO:tensorflow:global_step/sec: 51.585\n","INFO:tensorflow:examples/sec: 206.34\n","INFO:tensorflow:Saving checkpoints for 47000 into /content/trained_output/model.ckpt.\n","INFO:tensorflow:global_step/sec: 40.612\n","INFO:tensorflow:examples/sec: 162.448\n","INFO:tensorflow:global_step/sec: 51.7006\n","INFO:tensorflow:examples/sec: 206.802\n","INFO:tensorflow:global_step/sec: 49.8541\n","INFO:tensorflow:examples/sec: 199.416\n","INFO:tensorflow:global_step/sec: 48.3996\n","INFO:tensorflow:examples/sec: 193.598\n","INFO:tensorflow:global_step/sec: 48.5081\n","INFO:tensorflow:examples/sec: 194.032\n","INFO:tensorflow:global_step/sec: 48.7822\n","INFO:tensorflow:examples/sec: 195.129\n","INFO:tensorflow:global_step/sec: 52.1432\n","INFO:tensorflow:examples/sec: 208.573\n","INFO:tensorflow:global_step/sec: 52.1515\n","INFO:tensorflow:examples/sec: 208.606\n","INFO:tensorflow:global_step/sec: 52.2165\n","INFO:tensorflow:examples/sec: 208.866\n","INFO:tensorflow:global_step/sec: 52.1508\n","INFO:tensorflow:examples/sec: 208.603\n","INFO:tensorflow:Saving checkpoints for 48000 into /content/trained_output/model.ckpt.\n","INFO:tensorflow:global_step/sec: 41.1327\n","INFO:tensorflow:examples/sec: 164.531\n","INFO:tensorflow:global_step/sec: 49.002\n","INFO:tensorflow:examples/sec: 196.008\n","INFO:tensorflow:global_step/sec: 48.5811\n","INFO:tensorflow:examples/sec: 194.324\n","INFO:tensorflow:global_step/sec: 49.3446\n","INFO:tensorflow:examples/sec: 197.379\n","INFO:tensorflow:global_step/sec: 49.8456\n","INFO:tensorflow:examples/sec: 199.383\n","INFO:tensorflow:global_step/sec: 51.8805\n","INFO:tensorflow:examples/sec: 207.522\n","INFO:tensorflow:global_step/sec: 52.4093\n","INFO:tensorflow:examples/sec: 209.637\n","INFO:tensorflow:global_step/sec: 52.2468\n","INFO:tensorflow:examples/sec: 208.987\n","INFO:tensorflow:global_step/sec: 52.341\n","INFO:tensorflow:examples/sec: 209.364\n","INFO:tensorflow:global_step/sec: 52.2874\n","INFO:tensorflow:examples/sec: 209.149\n","INFO:tensorflow:Saving checkpoints for 49000 into /content/trained_output/model.ckpt.\n","INFO:tensorflow:global_step/sec: 34.8406\n","INFO:tensorflow:examples/sec: 139.362\n","INFO:tensorflow:global_step/sec: 49.5268\n","INFO:tensorflow:examples/sec: 198.107\n","INFO:tensorflow:global_step/sec: 48.6693\n","INFO:tensorflow:examples/sec: 194.677\n","INFO:tensorflow:global_step/sec: 50.7361\n","INFO:tensorflow:examples/sec: 202.944\n","INFO:tensorflow:global_step/sec: 52.4512\n","INFO:tensorflow:examples/sec: 209.805\n","INFO:tensorflow:global_step/sec: 52.2956\n","INFO:tensorflow:examples/sec: 209.182\n","INFO:tensorflow:global_step/sec: 52.3517\n","INFO:tensorflow:examples/sec: 209.407\n","INFO:tensorflow:global_step/sec: 51.9542\n","INFO:tensorflow:examples/sec: 207.817\n","INFO:tensorflow:global_step/sec: 50.7195\n","INFO:tensorflow:examples/sec: 202.878\n","INFO:tensorflow:global_step/sec: 48.4543\n","INFO:tensorflow:examples/sec: 193.817\n","INFO:tensorflow:Saving checkpoints for 50000 into /content/trained_output/model.ckpt.\n","INFO:tensorflow:global_step/sec: 34.6935\n","INFO:tensorflow:examples/sec: 138.774\n","INFO:tensorflow:global_step/sec: 48.9893\n","INFO:tensorflow:examples/sec: 195.957\n","INFO:tensorflow:global_step/sec: 52.4782\n","INFO:tensorflow:examples/sec: 209.913\n","INFO:tensorflow:global_step/sec: 52.2791\n","INFO:tensorflow:examples/sec: 209.116\n","INFO:tensorflow:global_step/sec: 52.5393\n","INFO:tensorflow:examples/sec: 210.157\n","INFO:tensorflow:global_step/sec: 52.6131\n","INFO:tensorflow:examples/sec: 210.452\n","INFO:tensorflow:global_step/sec: 52.3165\n","INFO:tensorflow:examples/sec: 209.266\n","INFO:tensorflow:global_step/sec: 49.5925\n","INFO:tensorflow:examples/sec: 198.37\n","INFO:tensorflow:global_step/sec: 48.9601\n","INFO:tensorflow:examples/sec: 195.84\n","INFO:tensorflow:global_step/sec: 49.1102\n","INFO:tensorflow:examples/sec: 196.441\n","INFO:tensorflow:Saving checkpoints for 51000 into /content/trained_output/model.ckpt.\n","INFO:tensorflow:global_step/sec: 39.5474\n","INFO:tensorflow:examples/sec: 158.189\n","INFO:tensorflow:global_step/sec: 52.3828\n","INFO:tensorflow:examples/sec: 209.531\n","INFO:tensorflow:global_step/sec: 52.1236\n","INFO:tensorflow:examples/sec: 208.494\n","INFO:tensorflow:global_step/sec: 52.4268\n","INFO:tensorflow:examples/sec: 209.707\n","INFO:tensorflow:global_step/sec: 52.4642\n","INFO:tensorflow:examples/sec: 209.857\n","INFO:tensorflow:global_step/sec: 51.917\n","INFO:tensorflow:examples/sec: 207.668\n","INFO:tensorflow:global_step/sec: 49.3058\n","INFO:tensorflow:examples/sec: 197.223\n","INFO:tensorflow:global_step/sec: 48.9491\n","INFO:tensorflow:examples/sec: 195.796\n","INFO:tensorflow:global_step/sec: 48.3349\n","INFO:tensorflow:examples/sec: 193.339\n","INFO:tensorflow:global_step/sec: 50.4943\n","INFO:tensorflow:examples/sec: 201.977\n","INFO:tensorflow:Saving checkpoints for 52000 into /content/trained_output/model.ckpt.\n","INFO:tensorflow:global_step/sec: 41.6751\n","INFO:tensorflow:examples/sec: 166.7\n","INFO:tensorflow:global_step/sec: 52.4356\n","INFO:tensorflow:examples/sec: 209.742\n","INFO:tensorflow:global_step/sec: 52.0723\n","INFO:tensorflow:examples/sec: 208.289\n","INFO:tensorflow:global_step/sec: 52.0605\n","INFO:tensorflow:examples/sec: 208.242\n","INFO:tensorflow:global_step/sec: 50.7656\n","INFO:tensorflow:examples/sec: 203.063\n","INFO:tensorflow:global_step/sec: 49.4328\n","INFO:tensorflow:examples/sec: 197.731\n","INFO:tensorflow:global_step/sec: 49.184\n","INFO:tensorflow:examples/sec: 196.736\n","INFO:tensorflow:global_step/sec: 48.4488\n","INFO:tensorflow:examples/sec: 193.795\n","INFO:tensorflow:global_step/sec: 50.8761\n","INFO:tensorflow:examples/sec: 203.504\n","INFO:tensorflow:global_step/sec: 52.3237\n","INFO:tensorflow:examples/sec: 209.295\n","INFO:tensorflow:Saving checkpoints for 53000 into /content/trained_output/model.ckpt.\n","INFO:tensorflow:global_step/sec: 41.6606\n","INFO:tensorflow:examples/sec: 166.642\n","INFO:tensorflow:global_step/sec: 52.2774\n","INFO:tensorflow:examples/sec: 209.11\n","INFO:tensorflow:global_step/sec: 52.2822\n","INFO:tensorflow:examples/sec: 209.129\n","INFO:tensorflow:global_step/sec: 50.5084\n","INFO:tensorflow:examples/sec: 202.034\n","INFO:tensorflow:global_step/sec: 48.618\n","INFO:tensorflow:examples/sec: 194.472\n","INFO:tensorflow:global_step/sec: 49.5329\n","INFO:tensorflow:examples/sec: 198.132\n","INFO:tensorflow:global_step/sec: 49.2331\n","INFO:tensorflow:examples/sec: 196.932\n","INFO:tensorflow:global_step/sec: 51.9362\n","INFO:tensorflow:examples/sec: 207.745\n","INFO:tensorflow:global_step/sec: 52.4663\n","INFO:tensorflow:examples/sec: 209.865\n","INFO:tensorflow:global_step/sec: 52.3107\n","INFO:tensorflow:examples/sec: 209.243\n","INFO:tensorflow:Saving checkpoints for 54000 into /content/trained_output/model.ckpt.\n","INFO:tensorflow:global_step/sec: 41.6207\n","INFO:tensorflow:examples/sec: 166.483\n","INFO:tensorflow:global_step/sec: 52.4794\n","INFO:tensorflow:examples/sec: 209.918\n","INFO:tensorflow:global_step/sec: 49.5027\n","INFO:tensorflow:examples/sec: 198.011\n","INFO:tensorflow:global_step/sec: 48.7266\n","INFO:tensorflow:examples/sec: 194.906\n","INFO:tensorflow:global_step/sec: 49.0049\n","INFO:tensorflow:examples/sec: 196.02\n","INFO:tensorflow:global_step/sec: 50.1875\n","INFO:tensorflow:examples/sec: 200.75\n","INFO:tensorflow:global_step/sec: 52.3975\n","INFO:tensorflow:examples/sec: 209.59\n","INFO:tensorflow:global_step/sec: 52.5099\n","INFO:tensorflow:examples/sec: 210.04\n","INFO:tensorflow:global_step/sec: 52.27\n","INFO:tensorflow:examples/sec: 209.08\n","INFO:tensorflow:global_step/sec: 52.3112\n","INFO:tensorflow:examples/sec: 209.245\n","INFO:tensorflow:Saving checkpoints for 55000 into /content/trained_output/model.ckpt.\n","INFO:tensorflow:global_step/sec: 37.6652\n","INFO:tensorflow:examples/sec: 150.661\n","INFO:tensorflow:global_step/sec: 48.0204\n","INFO:tensorflow:examples/sec: 192.082\n","INFO:tensorflow:global_step/sec: 48.2925\n","INFO:tensorflow:examples/sec: 193.17\n","INFO:tensorflow:global_step/sec: 49.6284\n","INFO:tensorflow:examples/sec: 198.513\n","INFO:tensorflow:global_step/sec: 50.6588\n","INFO:tensorflow:examples/sec: 202.635\n","INFO:tensorflow:global_step/sec: 52.3922\n","INFO:tensorflow:examples/sec: 209.569\n","INFO:tensorflow:global_step/sec: 52.4321\n","INFO:tensorflow:examples/sec: 209.728\n","INFO:tensorflow:global_step/sec: 52.047\n","INFO:tensorflow:examples/sec: 208.188\n","INFO:tensorflow:global_step/sec: 52.1131\n","INFO:tensorflow:examples/sec: 208.452\n","INFO:tensorflow:global_step/sec: 51.0743\n","INFO:tensorflow:examples/sec: 204.297\n","INFO:tensorflow:Saving checkpoints for 56000 into /content/trained_output/model.ckpt.\n","INFO:tensorflow:global_step/sec: 36.1868\n","INFO:tensorflow:examples/sec: 144.747\n","INFO:tensorflow:global_step/sec: 48.3298\n","INFO:tensorflow:examples/sec: 193.319\n","INFO:tensorflow:global_step/sec: 48.6682\n","INFO:tensorflow:examples/sec: 194.673\n","INFO:tensorflow:global_step/sec: 51.9394\n","INFO:tensorflow:examples/sec: 207.758\n","INFO:tensorflow:global_step/sec: 52.0021\n","INFO:tensorflow:examples/sec: 208.008\n","INFO:tensorflow:global_step/sec: 52.3607\n","INFO:tensorflow:examples/sec: 209.443\n","INFO:tensorflow:global_step/sec: 52.174\n","INFO:tensorflow:examples/sec: 208.696\n","INFO:tensorflow:global_step/sec: 52.3243\n","INFO:tensorflow:examples/sec: 209.297\n","INFO:tensorflow:global_step/sec: 49.5465\n","INFO:tensorflow:examples/sec: 198.186\n","INFO:tensorflow:global_step/sec: 48.9952\n","INFO:tensorflow:examples/sec: 195.981\n","INFO:tensorflow:Saving checkpoints for 57000 into /content/trained_output/model.ckpt.\n","INFO:tensorflow:global_step/sec: 36.3399\n","INFO:tensorflow:examples/sec: 145.359\n","INFO:tensorflow:global_step/sec: 49.658\n","INFO:tensorflow:examples/sec: 198.632\n","INFO:tensorflow:global_step/sec: 52.1743\n","INFO:tensorflow:examples/sec: 208.697\n","INFO:tensorflow:global_step/sec: 52.5256\n","INFO:tensorflow:examples/sec: 210.103\n","INFO:tensorflow:global_step/sec: 52.4617\n","INFO:tensorflow:examples/sec: 209.847\n","INFO:tensorflow:global_step/sec: 52.2959\n","INFO:tensorflow:examples/sec: 209.184\n","INFO:tensorflow:global_step/sec: 51.9476\n","INFO:tensorflow:examples/sec: 207.791\n","INFO:tensorflow:global_step/sec: 48.9271\n","INFO:tensorflow:examples/sec: 195.708\n","INFO:tensorflow:global_step/sec: 48.9587\n","INFO:tensorflow:examples/sec: 195.835\n","INFO:tensorflow:global_step/sec: 48.7849\n","INFO:tensorflow:examples/sec: 195.14\n","INFO:tensorflow:Saving checkpoints for 58000 into /content/trained_output/model.ckpt.\n","INFO:tensorflow:global_step/sec: 39.9214\n","INFO:tensorflow:examples/sec: 159.686\n","INFO:tensorflow:global_step/sec: 52.3388\n","INFO:tensorflow:examples/sec: 209.355\n","INFO:tensorflow:global_step/sec: 52.0385\n","INFO:tensorflow:examples/sec: 208.154\n","INFO:tensorflow:global_step/sec: 52.2194\n","INFO:tensorflow:examples/sec: 208.878\n","INFO:tensorflow:global_step/sec: 52.4247\n","INFO:tensorflow:examples/sec: 209.699\n","INFO:tensorflow:global_step/sec: 51.0487\n","INFO:tensorflow:examples/sec: 204.195\n","INFO:tensorflow:global_step/sec: 49.0642\n","INFO:tensorflow:examples/sec: 196.257\n","INFO:tensorflow:global_step/sec: 48.4461\n","INFO:tensorflow:examples/sec: 193.784\n","INFO:tensorflow:global_step/sec: 49.2708\n","INFO:tensorflow:examples/sec: 197.083\n","INFO:tensorflow:global_step/sec: 51.0079\n","INFO:tensorflow:examples/sec: 204.032\n","INFO:tensorflow:Saving checkpoints for 59000 into /content/trained_output/model.ckpt.\n","INFO:tensorflow:global_step/sec: 41.9247\n","INFO:tensorflow:examples/sec: 167.699\n","INFO:tensorflow:global_step/sec: 52.5041\n","INFO:tensorflow:examples/sec: 210.016\n","INFO:tensorflow:global_step/sec: 52.1394\n","INFO:tensorflow:examples/sec: 208.557\n","INFO:tensorflow:global_step/sec: 52.4632\n","INFO:tensorflow:examples/sec: 209.853\n","INFO:tensorflow:global_step/sec: 49.4377\n","INFO:tensorflow:examples/sec: 197.751\n","INFO:tensorflow:global_step/sec: 48.587\n","INFO:tensorflow:examples/sec: 194.348\n","INFO:tensorflow:global_step/sec: 49.0006\n","INFO:tensorflow:examples/sec: 196.002\n","INFO:tensorflow:global_step/sec: 48.293\n","INFO:tensorflow:examples/sec: 193.172\n","INFO:tensorflow:global_step/sec: 52.1291\n","INFO:tensorflow:examples/sec: 208.516\n","INFO:tensorflow:global_step/sec: 52.3195\n","INFO:tensorflow:examples/sec: 209.278\n","INFO:tensorflow:Saving checkpoints for 60000 into /content/trained_output/model.ckpt.\n","INFO:tensorflow:global_step/sec: 41.5276\n","INFO:tensorflow:examples/sec: 166.111\n","INFO:tensorflow:global_step/sec: 52.3061\n","INFO:tensorflow:examples/sec: 209.224\n","INFO:tensorflow:global_step/sec: 51.7224\n","INFO:tensorflow:examples/sec: 206.89\n","INFO:tensorflow:global_step/sec: 49.442\n","INFO:tensorflow:examples/sec: 197.768\n","INFO:tensorflow:global_step/sec: 48.9927\n","INFO:tensorflow:examples/sec: 195.971\n","INFO:tensorflow:global_step/sec: 49.0283\n","INFO:tensorflow:examples/sec: 196.113\n","INFO:tensorflow:global_step/sec: 49.949\n","INFO:tensorflow:examples/sec: 199.796\n","INFO:tensorflow:global_step/sec: 52.1111\n","INFO:tensorflow:examples/sec: 208.444\n","INFO:tensorflow:global_step/sec: 52.0778\n","INFO:tensorflow:examples/sec: 208.311\n","INFO:tensorflow:global_step/sec: 52.3338\n","INFO:tensorflow:examples/sec: 209.335\n","INFO:tensorflow:Saving checkpoints for 61000 into /content/trained_output/model.ckpt.\n","INFO:tensorflow:global_step/sec: 41.4834\n","INFO:tensorflow:examples/sec: 165.934\n","INFO:tensorflow:global_step/sec: 51.3731\n","INFO:tensorflow:examples/sec: 205.492\n","INFO:tensorflow:global_step/sec: 48.118\n","INFO:tensorflow:examples/sec: 192.472\n","INFO:tensorflow:global_step/sec: 48.6599\n","INFO:tensorflow:examples/sec: 194.64\n","INFO:tensorflow:global_step/sec: 48.435\n","INFO:tensorflow:examples/sec: 193.74\n","INFO:tensorflow:global_step/sec: 51.1157\n","INFO:tensorflow:examples/sec: 204.463\n","INFO:tensorflow:global_step/sec: 52.2109\n","INFO:tensorflow:examples/sec: 208.843\n","INFO:tensorflow:global_step/sec: 52.208\n","INFO:tensorflow:examples/sec: 208.832\n","INFO:tensorflow:global_step/sec: 52.3915\n","INFO:tensorflow:examples/sec: 209.566\n","INFO:tensorflow:global_step/sec: 52.3073\n","INFO:tensorflow:examples/sec: 209.229\n","INFO:tensorflow:Saving checkpoints for 62000 into /content/trained_output/model.ckpt.\n","INFO:tensorflow:global_step/sec: 36.6825\n","INFO:tensorflow:examples/sec: 146.73\n","INFO:tensorflow:global_step/sec: 49.3483\n","INFO:tensorflow:examples/sec: 197.393\n","INFO:tensorflow:global_step/sec: 49.4174\n","INFO:tensorflow:examples/sec: 197.67\n","INFO:tensorflow:global_step/sec: 49.5838\n","INFO:tensorflow:examples/sec: 198.335\n","INFO:tensorflow:global_step/sec: 52.1039\n","INFO:tensorflow:examples/sec: 208.416\n","INFO:tensorflow:global_step/sec: 52.3371\n","INFO:tensorflow:examples/sec: 209.349\n","INFO:tensorflow:global_step/sec: 52.3345\n","INFO:tensorflow:examples/sec: 209.338\n","INFO:tensorflow:global_step/sec: 52.3383\n","INFO:tensorflow:examples/sec: 209.353\n","INFO:tensorflow:global_step/sec: 52.4451\n","INFO:tensorflow:examples/sec: 209.78\n","INFO:tensorflow:global_step/sec: 49.8417\n","INFO:tensorflow:examples/sec: 199.367\n","INFO:tensorflow:Saving checkpoints for 63000 into /content/trained_output/model.ckpt.\n","INFO:tensorflow:global_step/sec: 35.3228\n","INFO:tensorflow:examples/sec: 141.291\n","INFO:tensorflow:global_step/sec: 48.5545\n","INFO:tensorflow:examples/sec: 194.218\n","INFO:tensorflow:global_step/sec: 50.7014\n","INFO:tensorflow:examples/sec: 202.805\n","INFO:tensorflow:global_step/sec: 52.1832\n","INFO:tensorflow:examples/sec: 208.733\n","INFO:tensorflow:global_step/sec: 52.1735\n","INFO:tensorflow:examples/sec: 208.694\n","INFO:tensorflow:global_step/sec: 52.4218\n","INFO:tensorflow:examples/sec: 209.687\n","INFO:tensorflow:global_step/sec: 52.2887\n","INFO:tensorflow:examples/sec: 209.155\n","INFO:tensorflow:global_step/sec: 51.1901\n","INFO:tensorflow:examples/sec: 204.76\n","INFO:tensorflow:global_step/sec: 48.6579\n","INFO:tensorflow:examples/sec: 194.632\n","INFO:tensorflow:global_step/sec: 49.1948\n","INFO:tensorflow:examples/sec: 196.779\n","INFO:tensorflow:Saving checkpoints for 64000 into /content/trained_output/model.ckpt.\n","INFO:tensorflow:global_step/sec: 35.749\n","INFO:tensorflow:examples/sec: 142.996\n","INFO:tensorflow:global_step/sec: 51.9591\n","INFO:tensorflow:examples/sec: 207.836\n","INFO:tensorflow:global_step/sec: 51.7534\n","INFO:tensorflow:examples/sec: 207.013\n","INFO:tensorflow:global_step/sec: 52.1397\n","INFO:tensorflow:examples/sec: 208.559\n","INFO:tensorflow:global_step/sec: 52.2763\n","INFO:tensorflow:examples/sec: 209.105\n","INFO:tensorflow:global_step/sec: 52.1744\n","INFO:tensorflow:examples/sec: 208.698\n","INFO:tensorflow:global_step/sec: 49.1675\n","INFO:tensorflow:examples/sec: 196.67\n","INFO:tensorflow:global_step/sec: 49.1021\n","INFO:tensorflow:examples/sec: 196.408\n","INFO:tensorflow:global_step/sec: 48.4082\n","INFO:tensorflow:examples/sec: 193.633\n","INFO:tensorflow:global_step/sec: 48.6473\n","INFO:tensorflow:examples/sec: 194.589\n","INFO:tensorflow:Saving checkpoints for 65000 into /content/trained_output/model.ckpt.\n","INFO:tensorflow:global_step/sec: 41.3679\n","INFO:tensorflow:examples/sec: 165.472\n","INFO:tensorflow:global_step/sec: 52.3954\n","INFO:tensorflow:examples/sec: 209.581\n","INFO:tensorflow:global_step/sec: 52.2215\n","INFO:tensorflow:examples/sec: 208.886\n","INFO:tensorflow:global_step/sec: 52.355\n","INFO:tensorflow:examples/sec: 209.42\n","INFO:tensorflow:global_step/sec: 52.2338\n","INFO:tensorflow:examples/sec: 208.935\n","INFO:tensorflow:global_step/sec: 48.4967\n","INFO:tensorflow:examples/sec: 193.987\n","INFO:tensorflow:global_step/sec: 48.9905\n","INFO:tensorflow:examples/sec: 195.962\n","INFO:tensorflow:global_step/sec: 48.4629\n","INFO:tensorflow:examples/sec: 193.852\n","INFO:tensorflow:global_step/sec: 50.0554\n","INFO:tensorflow:examples/sec: 200.222\n","INFO:tensorflow:global_step/sec: 52.3101\n","INFO:tensorflow:examples/sec: 209.24\n","INFO:tensorflow:Saving checkpoints for 66000 into /content/trained_output/model.ckpt.\n","INFO:tensorflow:global_step/sec: 41.7078\n","INFO:tensorflow:examples/sec: 166.831\n","INFO:tensorflow:global_step/sec: 52.1136\n","INFO:tensorflow:examples/sec: 208.455\n","INFO:tensorflow:global_step/sec: 52.3721\n","INFO:tensorflow:examples/sec: 209.488\n","INFO:tensorflow:global_step/sec: 50.9513\n","INFO:tensorflow:examples/sec: 203.805\n","INFO:tensorflow:global_step/sec: 48.8083\n","INFO:tensorflow:examples/sec: 195.233\n","INFO:tensorflow:global_step/sec: 49.4309\n","INFO:tensorflow:examples/sec: 197.724\n","INFO:tensorflow:global_step/sec: 48.7453\n","INFO:tensorflow:examples/sec: 194.981\n","INFO:tensorflow:global_step/sec: 51.3719\n","INFO:tensorflow:examples/sec: 205.487\n","INFO:tensorflow:global_step/sec: 52.2988\n","INFO:tensorflow:examples/sec: 209.195\n","INFO:tensorflow:global_step/sec: 52.1444\n","INFO:tensorflow:examples/sec: 208.578\n","INFO:tensorflow:Saving checkpoints for 67000 into /content/trained_output/model.ckpt.\n","INFO:tensorflow:global_step/sec: 41.5407\n","INFO:tensorflow:examples/sec: 166.163\n","INFO:tensorflow:global_step/sec: 52.0848\n","INFO:tensorflow:examples/sec: 208.339\n","INFO:tensorflow:global_step/sec: 49.8833\n","INFO:tensorflow:examples/sec: 199.533\n","INFO:tensorflow:global_step/sec: 47.739\n","INFO:tensorflow:examples/sec: 190.956\n","INFO:tensorflow:global_step/sec: 47.6648\n","INFO:tensorflow:examples/sec: 190.659\n","INFO:tensorflow:global_step/sec: 48.1751\n","INFO:tensorflow:examples/sec: 192.7\n","INFO:tensorflow:global_step/sec: 51.3635\n","INFO:tensorflow:examples/sec: 205.454\n","INFO:tensorflow:global_step/sec: 51.7193\n","INFO:tensorflow:examples/sec: 206.877\n","INFO:tensorflow:global_step/sec: 51.763\n","INFO:tensorflow:examples/sec: 207.052\n","INFO:tensorflow:global_step/sec: 51.5141\n","INFO:tensorflow:examples/sec: 206.056\n","INFO:tensorflow:Saving checkpoints for 68000 into /content/trained_output/model.ckpt.\n","INFO:tensorflow:global_step/sec: 38.3373\n","INFO:tensorflow:examples/sec: 153.349\n","INFO:tensorflow:global_step/sec: 47.0558\n","INFO:tensorflow:examples/sec: 188.223\n","INFO:tensorflow:global_step/sec: 48.2542\n","INFO:tensorflow:examples/sec: 193.017\n","INFO:tensorflow:global_step/sec: 49.1567\n","INFO:tensorflow:examples/sec: 196.627\n","INFO:tensorflow:global_step/sec: 50.7884\n","INFO:tensorflow:examples/sec: 203.154\n","INFO:tensorflow:global_step/sec: 52.0016\n","INFO:tensorflow:examples/sec: 208.007\n","INFO:tensorflow:global_step/sec: 52.2007\n","INFO:tensorflow:examples/sec: 208.803\n","INFO:tensorflow:global_step/sec: 51.8224\n","INFO:tensorflow:examples/sec: 207.29\n","INFO:tensorflow:global_step/sec: 52.4003\n","INFO:tensorflow:examples/sec: 209.601\n","INFO:tensorflow:global_step/sec: 51.6271\n","INFO:tensorflow:examples/sec: 206.509\n","INFO:tensorflow:Saving checkpoints for 69000 into /content/trained_output/model.ckpt.\n","INFO:tensorflow:global_step/sec: 36.0933\n","INFO:tensorflow:examples/sec: 144.373\n","INFO:tensorflow:global_step/sec: 48.2054\n","INFO:tensorflow:examples/sec: 192.821\n","INFO:tensorflow:global_step/sec: 48.7155\n","INFO:tensorflow:examples/sec: 194.862\n","INFO:tensorflow:global_step/sec: 51.8218\n","INFO:tensorflow:examples/sec: 207.287\n","INFO:tensorflow:global_step/sec: 52.3834\n","INFO:tensorflow:examples/sec: 209.534\n","INFO:tensorflow:global_step/sec: 52.3929\n","INFO:tensorflow:examples/sec: 209.572\n","INFO:tensorflow:global_step/sec: 52.2949\n","INFO:tensorflow:examples/sec: 209.18\n","INFO:tensorflow:global_step/sec: 52.321\n","INFO:tensorflow:examples/sec: 209.284\n","INFO:tensorflow:global_step/sec: 49.0657\n","INFO:tensorflow:examples/sec: 196.263\n","INFO:tensorflow:global_step/sec: 48.6874\n","INFO:tensorflow:examples/sec: 194.749\n","INFO:tensorflow:Saving checkpoints for 70000 into /content/trained_output/model.ckpt.\n","INFO:tensorflow:global_step/sec: 35.2491\n","INFO:tensorflow:examples/sec: 140.996\n","INFO:tensorflow:global_step/sec: 50.4905\n","INFO:tensorflow:examples/sec: 201.962\n","INFO:tensorflow:global_step/sec: 52.2316\n","INFO:tensorflow:examples/sec: 208.926\n","INFO:tensorflow:global_step/sec: 52.3323\n","INFO:tensorflow:examples/sec: 209.329\n","INFO:tensorflow:global_step/sec: 52.4291\n","INFO:tensorflow:examples/sec: 209.717\n","INFO:tensorflow:global_step/sec: 52.435\n","INFO:tensorflow:examples/sec: 209.74\n","INFO:tensorflow:global_step/sec: 51.5062\n","INFO:tensorflow:examples/sec: 206.025\n","INFO:tensorflow:global_step/sec: 49.6863\n","INFO:tensorflow:examples/sec: 198.745\n","INFO:tensorflow:global_step/sec: 48.4412\n","INFO:tensorflow:examples/sec: 193.765\n","INFO:tensorflow:global_step/sec: 49.0891\n","INFO:tensorflow:examples/sec: 196.356\n","INFO:tensorflow:Saving checkpoints for 71000 into /content/trained_output/model.ckpt.\n","INFO:tensorflow:global_step/sec: 40.2171\n","INFO:tensorflow:examples/sec: 160.869\n","INFO:tensorflow:global_step/sec: 52.4383\n","INFO:tensorflow:examples/sec: 209.753\n","INFO:tensorflow:global_step/sec: 52.5123\n","INFO:tensorflow:examples/sec: 210.049\n","INFO:tensorflow:global_step/sec: 52.2705\n","INFO:tensorflow:examples/sec: 209.082\n","INFO:tensorflow:global_step/sec: 52.4412\n","INFO:tensorflow:examples/sec: 209.765\n","INFO:tensorflow:global_step/sec: 50.7672\n","INFO:tensorflow:examples/sec: 203.069\n","INFO:tensorflow:global_step/sec: 48.598\n","INFO:tensorflow:examples/sec: 194.392\n","INFO:tensorflow:global_step/sec: 49.1703\n","INFO:tensorflow:examples/sec: 196.681\n","INFO:tensorflow:global_step/sec: 49.1965\n","INFO:tensorflow:examples/sec: 196.786\n","INFO:tensorflow:global_step/sec: 51.0284\n","INFO:tensorflow:examples/sec: 204.113\n","INFO:tensorflow:Saving checkpoints for 72000 into /content/trained_output/model.ckpt.\n","INFO:tensorflow:global_step/sec: 41.6782\n","INFO:tensorflow:examples/sec: 166.713\n","INFO:tensorflow:global_step/sec: 52.4623\n","INFO:tensorflow:examples/sec: 209.849\n","INFO:tensorflow:global_step/sec: 52.2862\n","INFO:tensorflow:examples/sec: 209.145\n","INFO:tensorflow:global_step/sec: 51.8627\n","INFO:tensorflow:examples/sec: 207.451\n","INFO:tensorflow:global_step/sec: 49.7594\n","INFO:tensorflow:examples/sec: 199.038\n","INFO:tensorflow:global_step/sec: 48.5666\n","INFO:tensorflow:examples/sec: 194.267\n","INFO:tensorflow:global_step/sec: 48.9906\n","INFO:tensorflow:examples/sec: 195.962\n","INFO:tensorflow:global_step/sec: 48.1791\n","INFO:tensorflow:examples/sec: 192.716\n","INFO:tensorflow:global_step/sec: 52.2291\n","INFO:tensorflow:examples/sec: 208.916\n","INFO:tensorflow:global_step/sec: 52.0705\n","INFO:tensorflow:examples/sec: 208.282\n","INFO:tensorflow:Saving checkpoints for 73000 into /content/trained_output/model.ckpt.\n","INFO:tensorflow:global_step/sec: 41.243\n","INFO:tensorflow:examples/sec: 164.972\n","INFO:tensorflow:global_step/sec: 52.2177\n","INFO:tensorflow:examples/sec: 208.871\n","INFO:tensorflow:global_step/sec: 51.8109\n","INFO:tensorflow:examples/sec: 207.243\n","INFO:tensorflow:global_step/sec: 48.7027\n","INFO:tensorflow:examples/sec: 194.811\n","INFO:tensorflow:global_step/sec: 48.8782\n","INFO:tensorflow:examples/sec: 195.513\n","INFO:tensorflow:global_step/sec: 49.0091\n","INFO:tensorflow:examples/sec: 196.036\n","INFO:tensorflow:global_step/sec: 50.0309\n","INFO:tensorflow:examples/sec: 200.124\n","INFO:tensorflow:global_step/sec: 52.0849\n","INFO:tensorflow:examples/sec: 208.34\n","INFO:tensorflow:global_step/sec: 52.237\n","INFO:tensorflow:examples/sec: 208.948\n","INFO:tensorflow:global_step/sec: 52.406\n","INFO:tensorflow:examples/sec: 209.624\n","INFO:tensorflow:Saving checkpoints for 74000 into /content/trained_output/model.ckpt.\n","INFO:tensorflow:global_step/sec: 41.2013\n","INFO:tensorflow:examples/sec: 164.805\n","INFO:tensorflow:global_step/sec: 51.1386\n","INFO:tensorflow:examples/sec: 204.555\n","INFO:tensorflow:global_step/sec: 48.791\n","INFO:tensorflow:examples/sec: 195.164\n","INFO:tensorflow:global_step/sec: 48.6539\n","INFO:tensorflow:examples/sec: 194.615\n","INFO:tensorflow:global_step/sec: 49.5447\n","INFO:tensorflow:examples/sec: 198.179\n","INFO:tensorflow:global_step/sec: 51.1887\n","INFO:tensorflow:examples/sec: 204.755\n","INFO:tensorflow:global_step/sec: 52.3258\n","INFO:tensorflow:examples/sec: 209.303\n","INFO:tensorflow:global_step/sec: 52.091\n","INFO:tensorflow:examples/sec: 208.364\n","INFO:tensorflow:global_step/sec: 52.2989\n","INFO:tensorflow:examples/sec: 209.196\n","INFO:tensorflow:global_step/sec: 52.6666\n","INFO:tensorflow:examples/sec: 210.666\n","INFO:tensorflow:Saving checkpoints for 75000 into /content/trained_output/model.ckpt.\n","INFO:tensorflow:global_step/sec: 36.9379\n","INFO:tensorflow:examples/sec: 147.752\n","INFO:tensorflow:global_step/sec: 48.8561\n","INFO:tensorflow:examples/sec: 195.424\n","INFO:tensorflow:global_step/sec: 48.2074\n","INFO:tensorflow:examples/sec: 192.829\n","INFO:tensorflow:global_step/sec: 48.9756\n","INFO:tensorflow:examples/sec: 195.902\n","INFO:tensorflow:global_step/sec: 52.423\n","INFO:tensorflow:examples/sec: 209.692\n","INFO:tensorflow:global_step/sec: 52.4051\n","INFO:tensorflow:examples/sec: 209.621\n","INFO:tensorflow:global_step/sec: 52.4163\n","INFO:tensorflow:examples/sec: 209.665\n","INFO:tensorflow:global_step/sec: 51.9743\n","INFO:tensorflow:examples/sec: 207.897\n","INFO:tensorflow:global_step/sec: 52.4183\n","INFO:tensorflow:examples/sec: 209.673\n","INFO:tensorflow:global_step/sec: 49.5679\n","INFO:tensorflow:examples/sec: 198.272\n","INFO:tensorflow:Saving checkpoints for 76000 into /content/trained_output/model.ckpt.\n","INFO:tensorflow:global_step/sec: 35.7436\n","INFO:tensorflow:examples/sec: 142.975\n","INFO:tensorflow:global_step/sec: 49.0678\n","INFO:tensorflow:examples/sec: 196.271\n","INFO:tensorflow:global_step/sec: 49.5206\n","INFO:tensorflow:examples/sec: 198.082\n","INFO:tensorflow:global_step/sec: 52.288\n","INFO:tensorflow:examples/sec: 209.152\n","INFO:tensorflow:global_step/sec: 52.1964\n","INFO:tensorflow:examples/sec: 208.786\n","INFO:tensorflow:global_step/sec: 52.1751\n","INFO:tensorflow:examples/sec: 208.7\n","INFO:tensorflow:global_step/sec: 51.9431\n","INFO:tensorflow:examples/sec: 207.772\n","INFO:tensorflow:global_step/sec: 51.7493\n","INFO:tensorflow:examples/sec: 206.997\n","INFO:tensorflow:global_step/sec: 49.055\n","INFO:tensorflow:examples/sec: 196.22\n","INFO:tensorflow:global_step/sec: 48.6118\n","INFO:tensorflow:examples/sec: 194.447\n","INFO:tensorflow:Saving checkpoints for 77000 into /content/trained_output/model.ckpt.\n","INFO:tensorflow:global_step/sec: 35.2268\n","INFO:tensorflow:examples/sec: 140.907\n","INFO:tensorflow:global_step/sec: 51.462\n","INFO:tensorflow:examples/sec: 205.848\n","INFO:tensorflow:global_step/sec: 52.2682\n","INFO:tensorflow:examples/sec: 209.073\n","INFO:tensorflow:global_step/sec: 52.2873\n","INFO:tensorflow:examples/sec: 209.149\n","INFO:tensorflow:global_step/sec: 52.3164\n","INFO:tensorflow:examples/sec: 209.266\n","INFO:tensorflow:global_step/sec: 52.4851\n","INFO:tensorflow:examples/sec: 209.94\n","INFO:tensorflow:global_step/sec: 50.4041\n","INFO:tensorflow:examples/sec: 201.616\n","INFO:tensorflow:global_step/sec: 48.6626\n","INFO:tensorflow:examples/sec: 194.65\n","INFO:tensorflow:global_step/sec: 49.4904\n","INFO:tensorflow:examples/sec: 197.962\n","INFO:tensorflow:global_step/sec: 49.4042\n","INFO:tensorflow:examples/sec: 197.617\n","INFO:tensorflow:Saving checkpoints for 78000 into /content/trained_output/model.ckpt.\n","INFO:tensorflow:global_step/sec: 41.0353\n","INFO:tensorflow:examples/sec: 164.141\n","INFO:tensorflow:global_step/sec: 52.2992\n","INFO:tensorflow:examples/sec: 209.197\n","INFO:tensorflow:global_step/sec: 52.0675\n","INFO:tensorflow:examples/sec: 208.27\n","INFO:tensorflow:global_step/sec: 52.4087\n","INFO:tensorflow:examples/sec: 209.635\n","INFO:tensorflow:global_step/sec: 52.2393\n","INFO:tensorflow:examples/sec: 208.957\n","INFO:tensorflow:global_step/sec: 49.4105\n","INFO:tensorflow:examples/sec: 197.642\n","INFO:tensorflow:global_step/sec: 49.2131\n","INFO:tensorflow:examples/sec: 196.852\n","INFO:tensorflow:global_step/sec: 48.6888\n","INFO:tensorflow:examples/sec: 194.755\n","INFO:tensorflow:global_step/sec: 49.5499\n","INFO:tensorflow:examples/sec: 198.2\n","INFO:tensorflow:global_step/sec: 52.2637\n","INFO:tensorflow:examples/sec: 209.055\n","INFO:tensorflow:Saving checkpoints for 79000 into /content/trained_output/model.ckpt.\n","INFO:tensorflow:global_step/sec: 41.3797\n","INFO:tensorflow:examples/sec: 165.519\n","INFO:tensorflow:global_step/sec: 52.2491\n","INFO:tensorflow:examples/sec: 208.997\n","INFO:tensorflow:global_step/sec: 51.8451\n","INFO:tensorflow:examples/sec: 207.38\n","INFO:tensorflow:global_step/sec: 51.5896\n","INFO:tensorflow:examples/sec: 206.359\n","INFO:tensorflow:global_step/sec: 49.985\n","INFO:tensorflow:examples/sec: 199.94\n","INFO:tensorflow:global_step/sec: 49.4789\n","INFO:tensorflow:examples/sec: 197.915\n","INFO:tensorflow:global_step/sec: 48.6697\n","INFO:tensorflow:examples/sec: 194.679\n","INFO:tensorflow:global_step/sec: 50.4151\n","INFO:tensorflow:examples/sec: 201.66\n","INFO:tensorflow:global_step/sec: 52.1624\n","INFO:tensorflow:examples/sec: 208.65\n","INFO:tensorflow:global_step/sec: 52.2025\n","INFO:tensorflow:examples/sec: 208.81\n","INFO:tensorflow:Saving checkpoints for 80000 into /content/trained_output/model.ckpt.\n","INFO:tensorflow:global_step/sec: 40.9283\n","INFO:tensorflow:examples/sec: 163.713\n","INFO:tensorflow:global_step/sec: 52.265\n","INFO:tensorflow:examples/sec: 209.06\n","INFO:tensorflow:global_step/sec: 49.9796\n","INFO:tensorflow:examples/sec: 199.918\n","INFO:tensorflow:global_step/sec: 48.8296\n","INFO:tensorflow:examples/sec: 195.318\n","INFO:tensorflow:global_step/sec: 48.7096\n","INFO:tensorflow:examples/sec: 194.838\n","INFO:tensorflow:global_step/sec: 48.822\n","INFO:tensorflow:examples/sec: 195.288\n","INFO:tensorflow:global_step/sec: 51.3376\n","INFO:tensorflow:examples/sec: 205.35\n","INFO:tensorflow:global_step/sec: 51.7791\n","INFO:tensorflow:examples/sec: 207.117\n","INFO:tensorflow:global_step/sec: 52.3279\n","INFO:tensorflow:examples/sec: 209.312\n","INFO:tensorflow:global_step/sec: 52.2794\n","INFO:tensorflow:examples/sec: 209.118\n","INFO:tensorflow:Saving checkpoints for 81000 into /content/trained_output/model.ckpt.\n","INFO:tensorflow:global_step/sec: 41.3846\n","INFO:tensorflow:examples/sec: 165.539\n","INFO:tensorflow:global_step/sec: 49.4067\n","INFO:tensorflow:examples/sec: 197.627\n","INFO:tensorflow:global_step/sec: 48.7694\n","INFO:tensorflow:examples/sec: 195.077\n","INFO:tensorflow:global_step/sec: 49.3959\n","INFO:tensorflow:examples/sec: 197.584\n","INFO:tensorflow:global_step/sec: 48.8857\n","INFO:tensorflow:examples/sec: 195.543\n","INFO:tensorflow:global_step/sec: 52.0671\n","INFO:tensorflow:examples/sec: 208.269\n","INFO:tensorflow:global_step/sec: 52.3001\n","INFO:tensorflow:examples/sec: 209.201\n","INFO:tensorflow:global_step/sec: 52.3421\n","INFO:tensorflow:examples/sec: 209.369\n","INFO:tensorflow:global_step/sec: 52.1813\n","INFO:tensorflow:examples/sec: 208.725\n","INFO:tensorflow:global_step/sec: 52.3387\n","INFO:tensorflow:examples/sec: 209.355\n","INFO:tensorflow:Saving checkpoints for 82000 into /content/trained_output/model.ckpt.\n","INFO:tensorflow:global_step/sec: 35.4909\n","INFO:tensorflow:examples/sec: 141.963\n","INFO:tensorflow:global_step/sec: 48.9113\n","INFO:tensorflow:examples/sec: 195.645\n","INFO:tensorflow:global_step/sec: 48.4668\n","INFO:tensorflow:examples/sec: 193.867\n","INFO:tensorflow:global_step/sec: 50.7168\n","INFO:tensorflow:examples/sec: 202.867\n","INFO:tensorflow:global_step/sec: 52.3313\n","INFO:tensorflow:examples/sec: 209.325\n","INFO:tensorflow:global_step/sec: 52.3332\n","INFO:tensorflow:examples/sec: 209.333\n","INFO:tensorflow:global_step/sec: 52.2376\n","INFO:tensorflow:examples/sec: 208.95\n","INFO:tensorflow:global_step/sec: 52.1942\n","INFO:tensorflow:examples/sec: 208.777\n","INFO:tensorflow:global_step/sec: 50.5556\n","INFO:tensorflow:examples/sec: 202.223\n","INFO:tensorflow:global_step/sec: 49.0852\n","INFO:tensorflow:examples/sec: 196.341\n","INFO:tensorflow:Saving checkpoints for 83000 into /content/trained_output/model.ckpt.\n","INFO:tensorflow:global_step/sec: 35.1757\n","INFO:tensorflow:examples/sec: 140.703\n","INFO:tensorflow:global_step/sec: 48.5942\n","INFO:tensorflow:examples/sec: 194.377\n","INFO:tensorflow:global_step/sec: 52.1488\n","INFO:tensorflow:examples/sec: 208.595\n","INFO:tensorflow:global_step/sec: 52.3326\n","INFO:tensorflow:examples/sec: 209.33\n","INFO:tensorflow:global_step/sec: 52.4834\n","INFO:tensorflow:examples/sec: 209.934\n","INFO:tensorflow:global_step/sec: 52.4409\n","INFO:tensorflow:examples/sec: 209.764\n","INFO:tensorflow:global_step/sec: 52.1439\n","INFO:tensorflow:examples/sec: 208.575\n","INFO:tensorflow:global_step/sec: 49.2272\n","INFO:tensorflow:examples/sec: 196.909\n","INFO:tensorflow:global_step/sec: 49.4395\n","INFO:tensorflow:examples/sec: 197.758\n","INFO:tensorflow:global_step/sec: 49.7333\n","INFO:tensorflow:examples/sec: 198.933\n","INFO:tensorflow:Saving checkpoints for 84000 into /content/trained_output/model.ckpt.\n","INFO:tensorflow:global_step/sec: 39.2764\n","INFO:tensorflow:examples/sec: 157.106\n","INFO:tensorflow:global_step/sec: 52.3691\n","INFO:tensorflow:examples/sec: 209.476\n","INFO:tensorflow:global_step/sec: 52.1389\n","INFO:tensorflow:examples/sec: 208.556\n","INFO:tensorflow:global_step/sec: 51.6336\n","INFO:tensorflow:examples/sec: 206.534\n","INFO:tensorflow:global_step/sec: 52.3754\n","INFO:tensorflow:examples/sec: 209.501\n","INFO:tensorflow:global_step/sec: 51.3083\n","INFO:tensorflow:examples/sec: 205.233\n","INFO:tensorflow:global_step/sec: 48.6039\n","INFO:tensorflow:examples/sec: 194.415\n","INFO:tensorflow:global_step/sec: 49.2968\n","INFO:tensorflow:examples/sec: 197.187\n","INFO:tensorflow:global_step/sec: 48.824\n","INFO:tensorflow:examples/sec: 195.296\n","INFO:tensorflow:global_step/sec: 50.5447\n","INFO:tensorflow:examples/sec: 202.179\n","INFO:tensorflow:Saving checkpoints for 85000 into /content/trained_output/model.ckpt.\n","INFO:tensorflow:global_step/sec: 41.3254\n","INFO:tensorflow:examples/sec: 165.302\n","INFO:tensorflow:global_step/sec: 52.1745\n","INFO:tensorflow:examples/sec: 208.698\n","INFO:tensorflow:global_step/sec: 52.0052\n","INFO:tensorflow:examples/sec: 208.021\n","INFO:tensorflow:global_step/sec: 51.6514\n","INFO:tensorflow:examples/sec: 206.606\n","INFO:tensorflow:global_step/sec: 49.5821\n","INFO:tensorflow:examples/sec: 198.328\n","INFO:tensorflow:global_step/sec: 49.0138\n","INFO:tensorflow:examples/sec: 196.055\n","INFO:tensorflow:global_step/sec: 49.601\n","INFO:tensorflow:examples/sec: 198.404\n","INFO:tensorflow:global_step/sec: 49.1927\n","INFO:tensorflow:examples/sec: 196.771\n","INFO:tensorflow:global_step/sec: 51.5954\n","INFO:tensorflow:examples/sec: 206.382\n","INFO:tensorflow:global_step/sec: 52.3003\n","INFO:tensorflow:examples/sec: 209.201\n","INFO:tensorflow:Saving checkpoints for 86000 into /content/trained_output/model.ckpt.\n","INFO:tensorflow:global_step/sec: 41.2063\n","INFO:tensorflow:examples/sec: 164.825\n","INFO:tensorflow:global_step/sec: 52.1613\n","INFO:tensorflow:examples/sec: 208.645\n","INFO:tensorflow:global_step/sec: 52.3986\n","INFO:tensorflow:examples/sec: 209.594\n","INFO:tensorflow:global_step/sec: 48.8017\n","INFO:tensorflow:examples/sec: 195.207\n","INFO:tensorflow:global_step/sec: 48.2259\n","INFO:tensorflow:examples/sec: 192.903\n","INFO:tensorflow:global_step/sec: 47.3561\n","INFO:tensorflow:examples/sec: 189.425\n","INFO:tensorflow:global_step/sec: 48.2798\n","INFO:tensorflow:examples/sec: 193.119\n","INFO:tensorflow:global_step/sec: 51.3528\n","INFO:tensorflow:examples/sec: 205.411\n","INFO:tensorflow:global_step/sec: 51.9049\n","INFO:tensorflow:examples/sec: 207.62\n","INFO:tensorflow:global_step/sec: 52.2543\n","INFO:tensorflow:examples/sec: 209.017\n","INFO:tensorflow:Saving checkpoints for 87000 into /content/trained_output/model.ckpt.\n","INFO:tensorflow:global_step/sec: 40.8676\n","INFO:tensorflow:examples/sec: 163.471\n","INFO:tensorflow:global_step/sec: 50.7386\n","INFO:tensorflow:examples/sec: 202.955\n","INFO:tensorflow:global_step/sec: 48.5892\n","INFO:tensorflow:examples/sec: 194.357\n","INFO:tensorflow:global_step/sec: 48.3828\n","INFO:tensorflow:examples/sec: 193.531\n","INFO:tensorflow:global_step/sec: 49.1097\n","INFO:tensorflow:examples/sec: 196.439\n","INFO:tensorflow:global_step/sec: 50.7843\n","INFO:tensorflow:examples/sec: 203.137\n","INFO:tensorflow:global_step/sec: 52.181\n","INFO:tensorflow:examples/sec: 208.724\n","INFO:tensorflow:global_step/sec: 52.1662\n","INFO:tensorflow:examples/sec: 208.665\n","INFO:tensorflow:global_step/sec: 52.1617\n","INFO:tensorflow:examples/sec: 208.647\n","INFO:tensorflow:global_step/sec: 52.1403\n","INFO:tensorflow:examples/sec: 208.561\n","INFO:tensorflow:Saving checkpoints for 88000 into /content/trained_output/model.ckpt.\n","INFO:tensorflow:global_step/sec: 35.3689\n","INFO:tensorflow:examples/sec: 141.476\n","INFO:tensorflow:global_step/sec: 49.2358\n","INFO:tensorflow:examples/sec: 196.943\n","INFO:tensorflow:global_step/sec: 48.7312\n","INFO:tensorflow:examples/sec: 194.925\n","INFO:tensorflow:global_step/sec: 49.0324\n","INFO:tensorflow:examples/sec: 196.13\n","INFO:tensorflow:global_step/sec: 52.4321\n","INFO:tensorflow:examples/sec: 209.728\n","INFO:tensorflow:global_step/sec: 52.2511\n","INFO:tensorflow:examples/sec: 209.005\n","INFO:tensorflow:global_step/sec: 51.8738\n","INFO:tensorflow:examples/sec: 207.495\n","INFO:tensorflow:global_step/sec: 52.1356\n","INFO:tensorflow:examples/sec: 208.542\n","INFO:tensorflow:global_step/sec: 52.1386\n","INFO:tensorflow:examples/sec: 208.554\n","INFO:tensorflow:global_step/sec: 49.0061\n","INFO:tensorflow:examples/sec: 196.024\n","INFO:tensorflow:Saving checkpoints for 89000 into /content/trained_output/model.ckpt.\n","INFO:tensorflow:global_step/sec: 35.8796\n","INFO:tensorflow:examples/sec: 143.518\n","INFO:tensorflow:global_step/sec: 48.7063\n","INFO:tensorflow:examples/sec: 194.825\n","INFO:tensorflow:global_step/sec: 50.5651\n","INFO:tensorflow:examples/sec: 202.26\n","INFO:tensorflow:global_step/sec: 52.4781\n","INFO:tensorflow:examples/sec: 209.912\n","INFO:tensorflow:global_step/sec: 52.2424\n","INFO:tensorflow:examples/sec: 208.97\n","INFO:tensorflow:global_step/sec: 52.3362\n","INFO:tensorflow:examples/sec: 209.345\n","INFO:tensorflow:global_step/sec: 52.3368\n","INFO:tensorflow:examples/sec: 209.347\n","INFO:tensorflow:global_step/sec: 51.2655\n","INFO:tensorflow:examples/sec: 205.062\n","INFO:tensorflow:global_step/sec: 49.3654\n","INFO:tensorflow:examples/sec: 197.462\n","INFO:tensorflow:global_step/sec: 49.061\n","INFO:tensorflow:examples/sec: 196.244\n","INFO:tensorflow:Saving checkpoints for 90000 into /content/trained_output/model.ckpt.\n","INFO:tensorflow:global_step/sec: 35.4315\n","INFO:tensorflow:examples/sec: 141.726\n","INFO:tensorflow:global_step/sec: 51.7403\n","INFO:tensorflow:examples/sec: 206.961\n","INFO:tensorflow:global_step/sec: 51.9167\n","INFO:tensorflow:examples/sec: 207.667\n","INFO:tensorflow:global_step/sec: 52.2567\n","INFO:tensorflow:examples/sec: 209.027\n","INFO:tensorflow:global_step/sec: 52.3585\n","INFO:tensorflow:examples/sec: 209.434\n","INFO:tensorflow:global_step/sec: 52.3768\n","INFO:tensorflow:examples/sec: 209.507\n","INFO:tensorflow:global_step/sec: 49.7802\n","INFO:tensorflow:examples/sec: 199.121\n","INFO:tensorflow:global_step/sec: 49.2182\n","INFO:tensorflow:examples/sec: 196.873\n","INFO:tensorflow:global_step/sec: 49.4588\n","INFO:tensorflow:examples/sec: 197.835\n","INFO:tensorflow:global_step/sec: 49.2744\n","INFO:tensorflow:examples/sec: 197.098\n","INFO:tensorflow:Saving checkpoints for 91000 into /content/trained_output/model.ckpt.\n","INFO:tensorflow:global_step/sec: 40.8795\n","INFO:tensorflow:examples/sec: 163.518\n","INFO:tensorflow:global_step/sec: 52.3436\n","INFO:tensorflow:examples/sec: 209.375\n","INFO:tensorflow:global_step/sec: 52.0654\n","INFO:tensorflow:examples/sec: 208.262\n","INFO:tensorflow:global_step/sec: 52.4206\n","INFO:tensorflow:examples/sec: 209.683\n","INFO:tensorflow:global_step/sec: 52.2867\n","INFO:tensorflow:examples/sec: 209.147\n","INFO:tensorflow:global_step/sec: 48.9603\n","INFO:tensorflow:examples/sec: 195.841\n","INFO:tensorflow:global_step/sec: 48.6552\n","INFO:tensorflow:examples/sec: 194.621\n","INFO:tensorflow:global_step/sec: 48.792\n","INFO:tensorflow:examples/sec: 195.168\n","INFO:tensorflow:global_step/sec: 50.1925\n","INFO:tensorflow:examples/sec: 200.77\n","INFO:tensorflow:global_step/sec: 52.1434\n","INFO:tensorflow:examples/sec: 208.573\n","INFO:tensorflow:Saving checkpoints for 92000 into /content/trained_output/model.ckpt.\n","INFO:tensorflow:global_step/sec: 41.4594\n","INFO:tensorflow:examples/sec: 165.838\n","INFO:tensorflow:global_step/sec: 51.8961\n","INFO:tensorflow:examples/sec: 207.584\n","INFO:tensorflow:global_step/sec: 52.2362\n","INFO:tensorflow:examples/sec: 208.945\n","INFO:tensorflow:global_step/sec: 51.1985\n","INFO:tensorflow:examples/sec: 204.794\n","INFO:tensorflow:global_step/sec: 48.7662\n","INFO:tensorflow:examples/sec: 195.065\n","INFO:tensorflow:global_step/sec: 48.8858\n","INFO:tensorflow:examples/sec: 195.543\n","INFO:tensorflow:global_step/sec: 49.3947\n","INFO:tensorflow:examples/sec: 197.579\n","INFO:tensorflow:global_step/sec: 50.9601\n","INFO:tensorflow:examples/sec: 203.84\n","INFO:tensorflow:global_step/sec: 52.2123\n","INFO:tensorflow:examples/sec: 208.849\n","INFO:tensorflow:global_step/sec: 52.1294\n","INFO:tensorflow:examples/sec: 208.518\n","INFO:tensorflow:Saving checkpoints for 93000 into /content/trained_output/model.ckpt.\n","INFO:tensorflow:global_step/sec: 41.1379\n","INFO:tensorflow:examples/sec: 164.552\n","INFO:tensorflow:global_step/sec: 52.365\n","INFO:tensorflow:examples/sec: 209.46\n","INFO:tensorflow:global_step/sec: 48.8768\n","INFO:tensorflow:examples/sec: 195.507\n","INFO:tensorflow:global_step/sec: 49.0756\n","INFO:tensorflow:examples/sec: 196.302\n","INFO:tensorflow:global_step/sec: 49.2279\n","INFO:tensorflow:examples/sec: 196.911\n","INFO:tensorflow:global_step/sec: 49.1328\n","INFO:tensorflow:examples/sec: 196.531\n","INFO:tensorflow:global_step/sec: 51.8171\n","INFO:tensorflow:examples/sec: 207.268\n","INFO:tensorflow:global_step/sec: 52.3319\n","INFO:tensorflow:examples/sec: 209.328\n","INFO:tensorflow:global_step/sec: 52.3584\n","INFO:tensorflow:examples/sec: 209.434\n","INFO:tensorflow:global_step/sec: 52.4535\n","INFO:tensorflow:examples/sec: 209.814\n","INFO:tensorflow:Saving checkpoints for 94000 into /content/trained_output/model.ckpt.\n","INFO:tensorflow:global_step/sec: 41.109\n","INFO:tensorflow:examples/sec: 164.436\n","INFO:tensorflow:global_step/sec: 48.6494\n","INFO:tensorflow:examples/sec: 194.597\n","INFO:tensorflow:global_step/sec: 49.2999\n","INFO:tensorflow:examples/sec: 197.2\n","INFO:tensorflow:global_step/sec: 48.4731\n","INFO:tensorflow:examples/sec: 193.892\n","INFO:tensorflow:global_step/sec: 49.8222\n","INFO:tensorflow:examples/sec: 199.289\n","INFO:tensorflow:global_step/sec: 52.2887\n","INFO:tensorflow:examples/sec: 209.155\n","INFO:tensorflow:global_step/sec: 52.2523\n","INFO:tensorflow:examples/sec: 209.009\n","INFO:tensorflow:global_step/sec: 52.2968\n","INFO:tensorflow:examples/sec: 209.187\n","INFO:tensorflow:global_step/sec: 52.352\n","INFO:tensorflow:examples/sec: 209.408\n","INFO:tensorflow:global_step/sec: 52.5126\n","INFO:tensorflow:examples/sec: 210.05\n","INFO:tensorflow:Saving checkpoints for 95000 into /content/trained_output/model.ckpt.\n","INFO:tensorflow:global_step/sec: 34.5817\n","INFO:tensorflow:examples/sec: 138.327\n","INFO:tensorflow:global_step/sec: 48.9712\n","INFO:tensorflow:examples/sec: 195.885\n","INFO:tensorflow:global_step/sec: 48.5107\n","INFO:tensorflow:examples/sec: 194.043\n","INFO:tensorflow:global_step/sec: 51.31\n","INFO:tensorflow:examples/sec: 205.24\n","INFO:tensorflow:global_step/sec: 52.2821\n","INFO:tensorflow:examples/sec: 209.128\n","INFO:tensorflow:global_step/sec: 52.172\n","INFO:tensorflow:examples/sec: 208.688\n","INFO:tensorflow:global_step/sec: 52.3796\n","INFO:tensorflow:examples/sec: 209.518\n","INFO:tensorflow:global_step/sec: 52.2228\n","INFO:tensorflow:examples/sec: 208.891\n","INFO:tensorflow:global_step/sec: 50.0907\n","INFO:tensorflow:examples/sec: 200.363\n","INFO:tensorflow:global_step/sec: 48.681\n","INFO:tensorflow:examples/sec: 194.724\n","INFO:tensorflow:Saving checkpoints for 96000 into /content/trained_output/model.ckpt.\n","INFO:tensorflow:global_step/sec: 34.9696\n","INFO:tensorflow:examples/sec: 139.878\n","INFO:tensorflow:global_step/sec: 49.2531\n","INFO:tensorflow:examples/sec: 197.012\n","INFO:tensorflow:global_step/sec: 52.4874\n","INFO:tensorflow:examples/sec: 209.95\n","INFO:tensorflow:global_step/sec: 52.4223\n","INFO:tensorflow:examples/sec: 209.689\n","INFO:tensorflow:global_step/sec: 52.2856\n","INFO:tensorflow:examples/sec: 209.142\n","INFO:tensorflow:global_step/sec: 51.9749\n","INFO:tensorflow:examples/sec: 207.9\n","INFO:tensorflow:global_step/sec: 52.1005\n","INFO:tensorflow:examples/sec: 208.402\n","INFO:tensorflow:global_step/sec: 49.206\n","INFO:tensorflow:examples/sec: 196.824\n","INFO:tensorflow:global_step/sec: 49.1689\n","INFO:tensorflow:examples/sec: 196.676\n","INFO:tensorflow:global_step/sec: 49.2818\n","INFO:tensorflow:examples/sec: 197.127\n","INFO:tensorflow:Saving checkpoints for 97000 into /content/trained_output/model.ckpt.\n","INFO:tensorflow:global_step/sec: 40.1691\n","INFO:tensorflow:examples/sec: 160.676\n","INFO:tensorflow:global_step/sec: 52.3022\n","INFO:tensorflow:examples/sec: 209.209\n","INFO:tensorflow:global_step/sec: 52.2949\n","INFO:tensorflow:examples/sec: 209.18\n","INFO:tensorflow:global_step/sec: 52.0355\n","INFO:tensorflow:examples/sec: 208.142\n","INFO:tensorflow:global_step/sec: 52.2083\n","INFO:tensorflow:examples/sec: 208.833\n","INFO:tensorflow:global_step/sec: 51.1513\n","INFO:tensorflow:examples/sec: 204.605\n","INFO:tensorflow:global_step/sec: 48.8546\n","INFO:tensorflow:examples/sec: 195.418\n","INFO:tensorflow:global_step/sec: 48.6614\n","INFO:tensorflow:examples/sec: 194.646\n","INFO:tensorflow:global_step/sec: 48.6163\n","INFO:tensorflow:examples/sec: 194.465\n","INFO:tensorflow:global_step/sec: 51.2561\n","INFO:tensorflow:examples/sec: 205.024\n","INFO:tensorflow:Saving checkpoints for 98000 into /content/trained_output/model.ckpt.\n","INFO:tensorflow:global_step/sec: 42.0476\n","INFO:tensorflow:examples/sec: 168.19\n","INFO:tensorflow:global_step/sec: 52.3631\n","INFO:tensorflow:examples/sec: 209.452\n","INFO:tensorflow:Saving checkpoints for 98175 into /content/trained_output/model.ckpt.\n","INFO:tensorflow:Loss for final step: 2.624783.\n","INFO:tensorflow:training_loop marked as finished\n","INFO:tensorflow:Writing example 0 of 9815\n","INFO:tensorflow:*** Example ***\n","INFO:tensorflow:guid: dev_matched-0\n","INFO:tensorflow:tokens: [CLS] the new rights are nice enough [SEP] everyone really likes the newest benefits [SEP]\n","INFO:tensorflow:input_ids: 101 1996 2047 2916 2024 3835 2438 102 3071 2428 7777 1996 14751 6666 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:label: neutral (id = 2)\n","INFO:tensorflow:*** Example ***\n","INFO:tensorflow:guid: dev_matched-1\n","INFO:tensorflow:tokens: [CLS] this site includes a list of all award winners and a search ##able database of government executive articles . [SEP] the government executive articles housed on the website are not able to be searched . [SEP]\n","INFO:tensorflow:input_ids: 101 2023 2609 2950 1037 2862 1997 2035 2400 4791 1998 1037 3945 3085 7809 1997 2231 3237 4790 1012 102 1996 2231 3237 4790 7431 2006 1996 4037 2024 2025 2583 2000 2022 9022 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:label: contradiction (id = 0)\n","INFO:tensorflow:*** Example ***\n","INFO:tensorflow:guid: dev_matched-2\n","INFO:tensorflow:tokens: [CLS] uh i don ' t know i i have mixed emotions about him uh sometimes i like him but at the same times i love to see somebody beat him [SEP] i like him for the most part , but would still enjoy seeing someone beat him . [SEP]\n","INFO:tensorflow:input_ids: 101 7910 1045 2123 1005 1056 2113 1045 1045 2031 3816 6699 2055 2032 7910 2823 1045 2066 2032 2021 2012 1996 2168 2335 1045 2293 2000 2156 8307 3786 2032 102 1045 2066 2032 2005 1996 2087 2112 1010 2021 2052 2145 5959 3773 2619 3786 2032 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:label: entailment (id = 1)\n","INFO:tensorflow:*** Example ***\n","INFO:tensorflow:guid: dev_matched-3\n","INFO:tensorflow:tokens: [CLS] yeah i i think my favorite restaurant is always been the one closest you know the closest as long as it ' s it meets the minimum criteria you know of good food [SEP] my favorite restaurants are always at least a hundred miles away from my house . [SEP]\n","INFO:tensorflow:input_ids: 101 3398 1045 1045 2228 2026 5440 4825 2003 2467 2042 1996 2028 7541 2017 2113 1996 7541 2004 2146 2004 2009 1005 1055 2009 6010 1996 6263 9181 2017 2113 1997 2204 2833 102 2026 5440 7884 2024 2467 2012 2560 1037 3634 2661 2185 2013 2026 2160 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:label: contradiction (id = 0)\n","INFO:tensorflow:*** Example ***\n","INFO:tensorflow:guid: dev_matched-4\n","INFO:tensorflow:tokens: [CLS] i don ' t know um do you do a lot of camping [SEP] i know exactly . [SEP]\n","INFO:tensorflow:input_ids: 101 1045 2123 1005 1056 2113 8529 2079 2017 2079 1037 2843 1997 13215 102 1045 2113 3599 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:label: contradiction (id = 0)\n","INFO:tensorflow:***** Running evaluation *****\n","INFO:tensorflow:  Num examples = 9815 (9815 actual, 0 padding)\n","INFO:tensorflow:  Batch size = 8\n","INFO:tensorflow:Calling model_fn.\n","INFO:tensorflow:Running eval on CPU\n","INFO:tensorflow:*** Features ***\n","INFO:tensorflow:  name = input_ids, shape = (?, 128)\n","INFO:tensorflow:  name = input_mask, shape = (?, 128)\n","INFO:tensorflow:  name = is_real_example, shape = (?,)\n","INFO:tensorflow:  name = label_ids, shape = (?,)\n","INFO:tensorflow:  name = segment_ids, shape = (?, 128)\n","INFO:tensorflow:**** Trainable Variables ****\n","INFO:tensorflow:  name = bert/embeddings/word_embeddings:0, shape = (30522, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/embeddings/token_type_embeddings:0, shape = (2, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/embeddings/position_embeddings:0, shape = (512, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/embeddings/LayerNorm/beta:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/embeddings/LayerNorm/gamma:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/query/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/query/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/key/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/key/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/value/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/value/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/dense/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/dense/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/LayerNorm/beta:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/LayerNorm/gamma:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/intermediate/dense/kernel:0, shape = (256, 1024), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/intermediate/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/output/dense/kernel:0, shape = (1024, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/output/dense/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/output/LayerNorm/beta:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/output/LayerNorm/gamma:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/query/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/query/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/key/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/key/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/value/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/value/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/dense/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/dense/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/LayerNorm/beta:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/LayerNorm/gamma:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/intermediate/dense/kernel:0, shape = (256, 1024), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/intermediate/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/output/dense/kernel:0, shape = (1024, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/output/dense/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/output/LayerNorm/beta:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/output/LayerNorm/gamma:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/query/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/query/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/key/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/key/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/value/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/value/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/dense/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/dense/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/LayerNorm/beta:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/LayerNorm/gamma:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/intermediate/dense/kernel:0, shape = (256, 1024), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/intermediate/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/output/dense/kernel:0, shape = (1024, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/output/dense/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/output/LayerNorm/beta:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/output/LayerNorm/gamma:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/query/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/query/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/key/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/key/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/value/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/value/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/dense/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/dense/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/LayerNorm/beta:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/LayerNorm/gamma:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/intermediate/dense/kernel:0, shape = (256, 1024), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/intermediate/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/output/dense/kernel:0, shape = (1024, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/output/dense/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/output/LayerNorm/beta:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/output/LayerNorm/gamma:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/pooler/dense/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/pooler/dense/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = output_weights:0, shape = (3, 256)\n","INFO:tensorflow:  name = output_bias:0, shape = (3,)\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/metrics_impl.py:455: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.cast instead.\n","INFO:tensorflow:Done calling model_fn.\n","INFO:tensorflow:Starting evaluation at 2023-05-22T07:10:27Z\n","INFO:tensorflow:Graph was finalized.\n","2023-05-22 07:10:27.252965: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0\n","2023-05-22 07:10:27.253032: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2023-05-22 07:10:27.253048: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0 \n","2023-05-22 07:10:27.253058: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N \n","2023-05-22 07:10:27.253161: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14248 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use standard file APIs to check for files with this prefix.\n","INFO:tensorflow:Restoring parameters from /content/trained_output/model.ckpt-98175\n","INFO:tensorflow:Running local_init_op.\n","INFO:tensorflow:Done running local_init_op.\n","INFO:tensorflow:Finished evaluation at 2023-05-22-07:10:35\n","INFO:tensorflow:Saving dict for global step 98175: eval_accuracy = 0.71421295, eval_loss = 0.7193103, global_step = 98175, loss = 0.7192658\n","INFO:tensorflow:Saving 'checkpoint_path' summary for global step 98175: /content/trained_output/model.ckpt-98175\n","INFO:tensorflow:evaluation_loop marked as finished\n","INFO:tensorflow:***** Eval results *****\n","INFO:tensorflow:  eval_accuracy = 0.71421295\n","INFO:tensorflow:  eval_loss = 0.7193103\n","INFO:tensorflow:  global_step = 98175\n","INFO:tensorflow:  loss = 0.7192658\n"]}],"source":["%cd /content/drive/MyDrive/Code_pretrain\n","%pwd\n","%env BERT_BASE_DIR=uncased_L-4_H-256_A-4\n","%env GLUE_DIR=data\n","!rm -rf /content/trained_output\n","\n","!python3 run_classifier.py \\\n","  --task_name=MNLI \\\n","  --do_train=true \\\n","  --do_eval=true \\\n","  --data_dir=$GLUE_DIR/MNLI \\\n","  --vocab_file=$BERT_BASE_DIR/vocab.txt \\\n","  --bert_config_file=$BERT_BASE_DIR/bert_config.json \\\n","  --init_checkpoint=$BERT_BASE_DIR/bert_model.ckpt \\\n","  --max_seq_length=128 \\\n","  --train_batch_size=4 \\\n","  --learning_rate=2e-5 \\\n","  --num_train_epochs=1.0 \\\n","  --output_dir=/content/trained_output\n","\n","# result metric.\n","# INFO:tensorflow:  eval_accuracy = 0.64605194\n","# INFO:tensorflow:  eval_loss = 0.80982023\n","# INFO:tensorflow:  global_step = 98175\n","# INFO:tensorflow:  loss = 0.8097828\n","\n","# INFO:tensorflow:  eval_accuracy = 0.71421295\n","# INFO:tensorflow:  eval_loss = 0.7193103\n","# INFO:tensorflow:  global_step = 98175\n","# INFO:tensorflow:  loss = 0.7192658"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"gmIALGuA-a4l","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1684763795054,"user_tz":-480,"elapsed":1925017,"user":{"displayName":"Brian Shen","userId":"08246478872294528508"}},"outputId":"ee31449c-09f6-4a83-e6fa-33de9d68957a"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Code_pretrain\n","env: BERT_BASE_DIR=uncased_L-4_H-256_A-4\n","env: GLUE_DIR=data\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n","\n","WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n","For more information, please see:\n","  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n","  * https://github.com/tensorflow/addons\n","If you depend on functionality not listed there, please file an issue.\n","\n","WARNING:tensorflow:Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7fb7aeb9aa60>) includes params argument, but params are not passed to Estimator.\n","INFO:tensorflow:Using config: {'_model_dir': '/content/trained_output', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 1000, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n","graph_options {\n","  rewrite_options {\n","    meta_optimizer_iterations: ONE\n","  }\n","}\n",", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fb7aca559e8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=1000, num_shards=8, num_cores_per_replica=None, per_host_input_for_training=3, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None), '_cluster': None}\n","INFO:tensorflow:_TPUContext: eval_on_tpu True\n","WARNING:tensorflow:eval_on_tpu ignored because use_tpu is False.\n","INFO:tensorflow:Writing example 0 of 392702\n","INFO:tensorflow:*** Example ***\n","INFO:tensorflow:guid: train-0\n","INFO:tensorflow:tokens: [CLS] conceptual ##ly cream ski ##mming has two basic dimensions - product and geography . [SEP] product and geography are what make cream ski ##mming work . [SEP]\n","INFO:tensorflow:input_ids: 101 17158 2135 6949 8301 25057 2038 2048 3937 9646 1011 4031 1998 10505 1012 102 4031 1998 10505 2024 2054 2191 6949 8301 25057 2147 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:label: neutral (id = 2)\n","INFO:tensorflow:*** Example ***\n","INFO:tensorflow:guid: train-1\n","INFO:tensorflow:tokens: [CLS] you know during the season and i guess at at your level uh you lose them to the next level if if they decide to recall the the parent team the braves decide to call to recall a guy from triple a then a double a guy goes up to replace him and a single a guy goes up to replace him [SEP] you lose the things to the following level if the people recall . [SEP]\n","INFO:tensorflow:input_ids: 101 2017 2113 2076 1996 2161 1998 1045 3984 2012 2012 2115 2504 7910 2017 4558 2068 2000 1996 2279 2504 2065 2065 2027 5630 2000 9131 1996 1996 6687 2136 1996 13980 5630 2000 2655 2000 9131 1037 3124 2013 6420 1037 2059 1037 3313 1037 3124 3632 2039 2000 5672 2032 1998 1037 2309 1037 3124 3632 2039 2000 5672 2032 102 2017 4558 1996 2477 2000 1996 2206 2504 2065 1996 2111 9131 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:label: entailment (id = 1)\n","INFO:tensorflow:*** Example ***\n","INFO:tensorflow:guid: train-2\n","INFO:tensorflow:tokens: [CLS] one of our number will carry out your instructions minute ##ly . [SEP] a member of my team will execute your orders with immense precision . [SEP]\n","INFO:tensorflow:input_ids: 101 2028 1997 2256 2193 2097 4287 2041 2115 8128 3371 2135 1012 102 1037 2266 1997 2026 2136 2097 15389 2115 4449 2007 14269 11718 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:label: entailment (id = 1)\n","INFO:tensorflow:*** Example ***\n","INFO:tensorflow:guid: train-3\n","INFO:tensorflow:tokens: [CLS] how do you know ? all this is their information again . [SEP] this information belongs to them . [SEP]\n","INFO:tensorflow:input_ids: 101 2129 2079 2017 2113 1029 2035 2023 2003 2037 2592 2153 1012 102 2023 2592 7460 2000 2068 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:label: entailment (id = 1)\n","INFO:tensorflow:*** Example ***\n","INFO:tensorflow:guid: train-4\n","INFO:tensorflow:tokens: [CLS] yeah i tell you what though if you go price some of those tennis shoes i can see why now you know they ' re getting up in the hundred dollar range [SEP] the tennis shoes have a range of prices . [SEP]\n","INFO:tensorflow:input_ids: 101 3398 1045 2425 2017 2054 2295 2065 2017 2175 3976 2070 1997 2216 5093 6007 1045 2064 2156 2339 2085 2017 2113 2027 1005 2128 2893 2039 1999 1996 3634 7922 2846 102 1996 5093 6007 2031 1037 2846 1997 7597 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:label: neutral (id = 2)\n","INFO:tensorflow:Writing example 10000 of 392702\n","INFO:tensorflow:Writing example 20000 of 392702\n","INFO:tensorflow:Writing example 30000 of 392702\n","INFO:tensorflow:Writing example 40000 of 392702\n","INFO:tensorflow:Writing example 50000 of 392702\n","INFO:tensorflow:Writing example 60000 of 392702\n","INFO:tensorflow:Writing example 70000 of 392702\n","INFO:tensorflow:Writing example 80000 of 392702\n","INFO:tensorflow:Writing example 90000 of 392702\n","INFO:tensorflow:Writing example 100000 of 392702\n","INFO:tensorflow:Writing example 110000 of 392702\n","INFO:tensorflow:Writing example 120000 of 392702\n","INFO:tensorflow:Writing example 130000 of 392702\n","INFO:tensorflow:Writing example 140000 of 392702\n","INFO:tensorflow:Writing example 150000 of 392702\n","INFO:tensorflow:Writing example 160000 of 392702\n","INFO:tensorflow:Writing example 170000 of 392702\n","INFO:tensorflow:Writing example 180000 of 392702\n","INFO:tensorflow:Writing example 190000 of 392702\n","INFO:tensorflow:Writing example 200000 of 392702\n","INFO:tensorflow:Writing example 210000 of 392702\n","INFO:tensorflow:Writing example 220000 of 392702\n","INFO:tensorflow:Writing example 230000 of 392702\n","INFO:tensorflow:Writing example 240000 of 392702\n","INFO:tensorflow:Writing example 250000 of 392702\n","INFO:tensorflow:Writing example 260000 of 392702\n","INFO:tensorflow:Writing example 270000 of 392702\n","INFO:tensorflow:Writing example 280000 of 392702\n","INFO:tensorflow:Writing example 290000 of 392702\n","INFO:tensorflow:Writing example 300000 of 392702\n","INFO:tensorflow:Writing example 310000 of 392702\n","INFO:tensorflow:Writing example 320000 of 392702\n","INFO:tensorflow:Writing example 330000 of 392702\n","INFO:tensorflow:Writing example 340000 of 392702\n","INFO:tensorflow:Writing example 350000 of 392702\n","INFO:tensorflow:Writing example 360000 of 392702\n","INFO:tensorflow:Writing example 370000 of 392702\n","INFO:tensorflow:Writing example 380000 of 392702\n","INFO:tensorflow:Writing example 390000 of 392702\n","INFO:tensorflow:***** Running training *****\n","INFO:tensorflow:  Num examples = 392702\n","INFO:tensorflow:  Batch size = 4\n","INFO:tensorflow:  Num steps = 98175\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Colocations handled automatically by placer.\n","WARNING:tensorflow:From run_classifier.py:890: map_and_batch (from tensorflow.contrib.data.python.ops.batching) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.experimental.map_and_batch(...)`.\n","WARNING:tensorflow:From run_classifier.py:870: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.cast instead.\n","INFO:tensorflow:Calling model_fn.\n","INFO:tensorflow:Running train on CPU\n","INFO:tensorflow:*** Features ***\n","INFO:tensorflow:  name = input_ids, shape = (4, 128)\n","INFO:tensorflow:  name = input_mask, shape = (4, 128)\n","INFO:tensorflow:  name = is_real_example, shape = (4,)\n","INFO:tensorflow:  name = label_ids, shape = (4,)\n","INFO:tensorflow:  name = segment_ids, shape = (4, 128)\n","WARNING:tensorflow:From /content/drive/MyDrive/Code_pretrain/modeling.py:358: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n","WARNING:tensorflow:From /content/drive/MyDrive/Code_pretrain/modeling.py:671: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use keras.layers.dense instead.\n","INFO:tensorflow:**** Trainable Variables ****\n","INFO:tensorflow:  name = bert/embeddings/word_embeddings:0, shape = (30522, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/embeddings/token_type_embeddings:0, shape = (2, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/embeddings/position_embeddings:0, shape = (512, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/embeddings/LayerNorm/beta:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/embeddings/LayerNorm/gamma:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/query/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/query/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/key/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/key/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/value/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/value/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/dense/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/dense/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/LayerNorm/beta:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/LayerNorm/gamma:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/intermediate/dense/kernel:0, shape = (256, 1024), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/intermediate/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/output/dense/kernel:0, shape = (1024, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/output/dense/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/output/LayerNorm/beta:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/output/LayerNorm/gamma:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/query/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/query/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/key/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/key/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/value/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/value/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/dense/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/dense/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/LayerNorm/beta:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/LayerNorm/gamma:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/intermediate/dense/kernel:0, shape = (256, 1024), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/intermediate/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/output/dense/kernel:0, shape = (1024, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/output/dense/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/output/LayerNorm/beta:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/output/LayerNorm/gamma:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/query/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/query/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/key/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/key/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/value/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/value/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/dense/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/dense/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/LayerNorm/beta:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/LayerNorm/gamma:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/intermediate/dense/kernel:0, shape = (256, 1024), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/intermediate/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/output/dense/kernel:0, shape = (1024, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/output/dense/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/output/LayerNorm/beta:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/output/LayerNorm/gamma:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/query/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/query/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/key/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/key/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/value/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/value/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/dense/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/dense/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/LayerNorm/beta:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/LayerNorm/gamma:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/intermediate/dense/kernel:0, shape = (256, 1024), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/intermediate/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/output/dense/kernel:0, shape = (1024, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/output/dense/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/output/LayerNorm/beta:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/output/LayerNorm/gamma:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/pooler/dense/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/pooler/dense/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = output_weights:0, shape = (3, 256)\n","INFO:tensorflow:  name = output_bias:0, shape = (3,)\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/learning_rate_decay_v2.py:321: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Deprecated in favor of operator or tf.math.divide.\n","INFO:tensorflow:Done calling model_fn.\n","INFO:tensorflow:Create CheckpointSaverHook.\n","INFO:tensorflow:Graph was finalized.\n","2023-05-22 07:49:52.334994: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n","2023-05-22 07:49:52.342540: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2200155000 Hz\n","2023-05-22 07:49:52.342838: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x7e49b10 executing computations on platform Host. Devices:\n","2023-05-22 07:49:52.342884: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>\n","INFO:tensorflow:Running local_init_op.\n","INFO:tensorflow:Done running local_init_op.\n","INFO:tensorflow:Saving checkpoints for 0 into /content/trained_output/model.ckpt.\n","INFO:tensorflow:global_step/sec: 1.30627\n","INFO:tensorflow:examples/sec: 5.22509\n","INFO:tensorflow:global_step/sec: 1.42247\n","INFO:tensorflow:examples/sec: 5.68988\n","INFO:tensorflow:global_step/sec: 1.29324\n","INFO:tensorflow:examples/sec: 5.17295\n","INFO:tensorflow:global_step/sec: 1.34578\n","INFO:tensorflow:examples/sec: 5.38311\n","INFO:tensorflow:global_step/sec: 1.38978\n","INFO:tensorflow:examples/sec: 5.55911\n","INFO:tensorflow:global_step/sec: 1.32795\n","INFO:tensorflow:examples/sec: 5.31179\n","INFO:tensorflow:global_step/sec: 1.31707\n","INFO:tensorflow:examples/sec: 5.26828\n","INFO:tensorflow:global_step/sec: 1.34625\n","INFO:tensorflow:examples/sec: 5.38502\n","INFO:tensorflow:global_step/sec: 1.45819\n","INFO:tensorflow:examples/sec: 5.83276\n","INFO:tensorflow:Saving checkpoints for 1000 into /content/trained_output/model.ckpt.\n","INFO:tensorflow:global_step/sec: 1.41172\n","INFO:tensorflow:examples/sec: 5.64686\n","INFO:tensorflow:global_step/sec: 1.52543\n","INFO:tensorflow:examples/sec: 6.10174\n","INFO:tensorflow:global_step/sec: 1.35561\n","INFO:tensorflow:examples/sec: 5.42244\n","INFO:tensorflow:global_step/sec: 1.46973\n","INFO:tensorflow:examples/sec: 5.8789\n","INFO:tensorflow:global_step/sec: 1.48382\n","INFO:tensorflow:examples/sec: 5.93529\n","INFO:tensorflow:global_step/sec: 1.5731\n","INFO:tensorflow:examples/sec: 6.2924\n","INFO:tensorflow:global_step/sec: 1.52002\n","INFO:tensorflow:examples/sec: 6.08009\n","INFO:tensorflow:global_step/sec: 1.54421\n","INFO:tensorflow:examples/sec: 6.17685\n","INFO:tensorflow:global_step/sec: 1.55231\n","INFO:tensorflow:examples/sec: 6.20926\n","INFO:tensorflow:global_step/sec: 1.5135\n","INFO:tensorflow:examples/sec: 6.05401\n","INFO:tensorflow:Saving checkpoints for 2000 into /content/trained_output/model.ckpt.\n","INFO:tensorflow:global_step/sec: 1.53586\n","INFO:tensorflow:examples/sec: 6.14345\n","INFO:tensorflow:global_step/sec: 1.47249\n","INFO:tensorflow:examples/sec: 5.88997\n","INFO:tensorflow:global_step/sec: 1.49546\n","INFO:tensorflow:examples/sec: 5.98184\n","INFO:tensorflow:global_step/sec: 1.58789\n","INFO:tensorflow:examples/sec: 6.35156\n","INFO:tensorflow:global_step/sec: 1.53132\n","INFO:tensorflow:examples/sec: 6.12529\n","INFO:tensorflow:global_step/sec: 1.50478\n","INFO:tensorflow:examples/sec: 6.01911\n","INFO:tensorflow:global_step/sec: 1.54605\n","INFO:tensorflow:examples/sec: 6.18421\n","INFO:tensorflow:global_step/sec: 1.53096\n","INFO:tensorflow:examples/sec: 6.12386\n","INFO:tensorflow:global_step/sec: 1.53834\n","INFO:tensorflow:examples/sec: 6.15338\n","INFO:tensorflow:global_step/sec: 1.56775\n","INFO:tensorflow:examples/sec: 6.271\n","INFO:tensorflow:Saving checkpoints for 3000 into /content/trained_output/model.ckpt.\n","INFO:tensorflow:global_step/sec: 1.47505\n","INFO:tensorflow:examples/sec: 5.90022\n","INFO:tensorflow:global_step/sec: 1.58352\n","INFO:tensorflow:examples/sec: 6.33407\n","INFO:tensorflow:global_step/sec: 1.55104\n","INFO:tensorflow:examples/sec: 6.20415\n","INFO:tensorflow:global_step/sec: 1.51479\n","INFO:tensorflow:examples/sec: 6.05918\n","INFO:tensorflow:global_step/sec: 1.5689\n","INFO:tensorflow:examples/sec: 6.2756\n","INFO:tensorflow:global_step/sec: 1.48162\n","INFO:tensorflow:examples/sec: 5.9265\n","INFO:tensorflow:global_step/sec: 1.54174\n","INFO:tensorflow:examples/sec: 6.16698\n","INFO:tensorflow:global_step/sec: 1.50425\n","INFO:tensorflow:examples/sec: 6.01699\n","INFO:tensorflow:global_step/sec: 1.52847\n","INFO:tensorflow:examples/sec: 6.11389\n","INFO:tensorflow:global_step/sec: 1.55851\n","INFO:tensorflow:examples/sec: 6.23403\n","INFO:tensorflow:Saving checkpoints for 4000 into /content/trained_output/model.ckpt.\n","INFO:tensorflow:global_step/sec: 1.47859\n","INFO:tensorflow:examples/sec: 5.91434\n","INFO:tensorflow:global_step/sec: 1.56905\n","INFO:tensorflow:examples/sec: 6.27621\n","INFO:tensorflow:global_step/sec: 1.39368\n","INFO:tensorflow:examples/sec: 5.57471\n","INFO:tensorflow:global_step/sec: 1.45571\n","INFO:tensorflow:examples/sec: 5.82285\n","INFO:tensorflow:global_step/sec: 1.46315\n","INFO:tensorflow:examples/sec: 5.85261\n","INFO:tensorflow:global_step/sec: 1.44635\n","INFO:tensorflow:examples/sec: 5.78541\n","INFO:tensorflow:global_step/sec: 1.42638\n","INFO:tensorflow:examples/sec: 5.70553\n","INFO:tensorflow:global_step/sec: 1.47663\n","INFO:tensorflow:examples/sec: 5.90652\n","INFO:tensorflow:global_step/sec: 1.44514\n","INFO:tensorflow:examples/sec: 5.78056\n","INFO:tensorflow:global_step/sec: 1.50177\n","INFO:tensorflow:examples/sec: 6.00707\n","INFO:tensorflow:Saving checkpoints for 5000 into /content/trained_output/model.ckpt.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:966: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use standard file APIs to delete files with this prefix.\n","INFO:tensorflow:global_step/sec: 1.40732\n","INFO:tensorflow:examples/sec: 5.6293\n","INFO:tensorflow:global_step/sec: 1.48461\n","INFO:tensorflow:examples/sec: 5.93843\n","INFO:tensorflow:global_step/sec: 1.40805\n","INFO:tensorflow:examples/sec: 5.63218\n","INFO:tensorflow:global_step/sec: 1.4895\n","INFO:tensorflow:examples/sec: 5.95802\n","INFO:tensorflow:global_step/sec: 1.41923\n","INFO:tensorflow:examples/sec: 5.67691\n","INFO:tensorflow:global_step/sec: 1.43948\n","INFO:tensorflow:examples/sec: 5.75792\n","INFO:tensorflow:global_step/sec: 1.48682\n","INFO:tensorflow:examples/sec: 5.94727\n","INFO:tensorflow:global_step/sec: 1.44221\n","INFO:tensorflow:examples/sec: 5.76886\n","INFO:tensorflow:global_step/sec: 1.43289\n","INFO:tensorflow:examples/sec: 5.73156\n","INFO:tensorflow:global_step/sec: 1.43578\n","INFO:tensorflow:examples/sec: 5.74313\n","INFO:tensorflow:Saving checkpoints for 6000 into /content/trained_output/model.ckpt.\n","INFO:tensorflow:global_step/sec: 1.46553\n","INFO:tensorflow:examples/sec: 5.86211\n","INFO:tensorflow:global_step/sec: 1.47106\n","INFO:tensorflow:examples/sec: 5.88425\n","INFO:tensorflow:global_step/sec: 1.39282\n","INFO:tensorflow:examples/sec: 5.57126\n","INFO:tensorflow:global_step/sec: 1.369\n","INFO:tensorflow:examples/sec: 5.476\n","INFO:tensorflow:global_step/sec: 1.4647\n","INFO:tensorflow:examples/sec: 5.85881\n","INFO:tensorflow:global_step/sec: 1.43823\n","INFO:tensorflow:examples/sec: 5.75293\n","INFO:tensorflow:global_step/sec: 1.45984\n","INFO:tensorflow:examples/sec: 5.83937\n","INFO:tensorflow:global_step/sec: 1.51731\n","INFO:tensorflow:examples/sec: 6.06924\n","INFO:tensorflow:global_step/sec: 1.57377\n","INFO:tensorflow:examples/sec: 6.2951\n","INFO:tensorflow:global_step/sec: 1.49139\n","INFO:tensorflow:examples/sec: 5.96555\n","INFO:tensorflow:Saving checkpoints for 7000 into /content/trained_output/model.ckpt.\n","INFO:tensorflow:global_step/sec: 1.51737\n","INFO:tensorflow:examples/sec: 6.0695\n","INFO:tensorflow:global_step/sec: 1.46565\n","INFO:tensorflow:examples/sec: 5.8626\n","INFO:tensorflow:global_step/sec: 1.42164\n","INFO:tensorflow:examples/sec: 5.68657\n","INFO:tensorflow:global_step/sec: 1.41037\n","INFO:tensorflow:examples/sec: 5.64148\n","INFO:tensorflow:global_step/sec: 1.40917\n","INFO:tensorflow:examples/sec: 5.63668\n","INFO:tensorflow:global_step/sec: 1.40781\n","INFO:tensorflow:examples/sec: 5.63123\n","INFO:tensorflow:global_step/sec: 1.41904\n","INFO:tensorflow:examples/sec: 5.67616\n","INFO:tensorflow:global_step/sec: 1.41894\n","INFO:tensorflow:examples/sec: 5.67578\n","INFO:tensorflow:global_step/sec: 1.4452\n","INFO:tensorflow:examples/sec: 5.78079\n","INFO:tensorflow:global_step/sec: 1.44894\n","INFO:tensorflow:examples/sec: 5.79577\n","INFO:tensorflow:Saving checkpoints for 8000 into /content/trained_output/model.ckpt.\n","INFO:tensorflow:global_step/sec: 1.36414\n","INFO:tensorflow:examples/sec: 5.45656\n","INFO:tensorflow:global_step/sec: 1.46369\n","INFO:tensorflow:examples/sec: 5.85476\n","INFO:tensorflow:global_step/sec: 1.42649\n","INFO:tensorflow:examples/sec: 5.70596\n","INFO:tensorflow:global_step/sec: 1.55343\n","INFO:tensorflow:examples/sec: 6.21373\n","INFO:tensorflow:global_step/sec: 1.47554\n","INFO:tensorflow:examples/sec: 5.90218\n","INFO:tensorflow:global_step/sec: 1.5536\n","INFO:tensorflow:examples/sec: 6.21441\n","INFO:tensorflow:global_step/sec: 1.45593\n","INFO:tensorflow:examples/sec: 5.82372\n","INFO:tensorflow:global_step/sec: 1.53865\n","INFO:tensorflow:examples/sec: 6.15461\n","INFO:tensorflow:global_step/sec: 1.50098\n","INFO:tensorflow:examples/sec: 6.00394\n","INFO:tensorflow:global_step/sec: 1.48342\n","INFO:tensorflow:examples/sec: 5.93368\n","INFO:tensorflow:Saving checkpoints for 9000 into /content/trained_output/model.ckpt.\n","INFO:tensorflow:global_step/sec: 1.46201\n","INFO:tensorflow:examples/sec: 5.84805\n","INFO:tensorflow:global_step/sec: 1.45462\n","INFO:tensorflow:examples/sec: 5.81846\n","INFO:tensorflow:global_step/sec: 1.4974\n","INFO:tensorflow:examples/sec: 5.98958\n","INFO:tensorflow:global_step/sec: 1.45789\n","INFO:tensorflow:examples/sec: 5.83155\n","INFO:tensorflow:global_step/sec: 1.56263\n","INFO:tensorflow:examples/sec: 6.25051\n","INFO:tensorflow:global_step/sec: 1.47419\n","INFO:tensorflow:examples/sec: 5.89677\n","INFO:tensorflow:global_step/sec: 1.57086\n","INFO:tensorflow:examples/sec: 6.28346\n","INFO:tensorflow:global_step/sec: 1.45789\n","INFO:tensorflow:examples/sec: 5.83156\n","INFO:tensorflow:global_step/sec: 1.51407\n","INFO:tensorflow:examples/sec: 6.05629\n","INFO:tensorflow:global_step/sec: 1.53094\n","INFO:tensorflow:examples/sec: 6.12376\n","INFO:tensorflow:Saving checkpoints for 10000 into /content/trained_output/model.ckpt.\n","INFO:tensorflow:global_step/sec: 1.49296\n","INFO:tensorflow:examples/sec: 5.97183\n","INFO:tensorflow:global_step/sec: 1.56431\n","INFO:tensorflow:examples/sec: 6.25723\n","INFO:tensorflow:global_step/sec: 1.51456\n","INFO:tensorflow:examples/sec: 6.05825\n","INFO:tensorflow:global_step/sec: 1.52954\n","INFO:tensorflow:examples/sec: 6.11815\n","INFO:tensorflow:global_step/sec: 1.56389\n","INFO:tensorflow:examples/sec: 6.25558\n","INFO:tensorflow:global_step/sec: 1.45985\n","INFO:tensorflow:examples/sec: 5.83939\n","INFO:tensorflow:global_step/sec: 1.56572\n","INFO:tensorflow:examples/sec: 6.26289\n","INFO:tensorflow:global_step/sec: 1.5118\n","INFO:tensorflow:examples/sec: 6.04721\n","INFO:tensorflow:global_step/sec: 1.49832\n","INFO:tensorflow:examples/sec: 5.99327\n","INFO:tensorflow:global_step/sec: 1.56733\n","INFO:tensorflow:examples/sec: 6.26931\n","INFO:tensorflow:Saving checkpoints for 11000 into /content/trained_output/model.ckpt.\n","INFO:tensorflow:global_step/sec: 1.4454\n","INFO:tensorflow:examples/sec: 5.78161\n","INFO:tensorflow:global_step/sec: 1.56343\n","INFO:tensorflow:examples/sec: 6.25371\n","INFO:tensorflow:global_step/sec: 1.50493\n","INFO:tensorflow:examples/sec: 6.01971\n","INFO:tensorflow:global_step/sec: 1.51888\n","INFO:tensorflow:examples/sec: 6.07554\n","INFO:tensorflow:global_step/sec: 1.54205\n","INFO:tensorflow:examples/sec: 6.1682\n","INFO:tensorflow:global_step/sec: 1.49087\n","INFO:tensorflow:examples/sec: 5.96348\n","INFO:tensorflow:global_step/sec: 1.53036\n","INFO:tensorflow:examples/sec: 6.12142\n","INFO:tensorflow:global_step/sec: 1.37747\n","INFO:tensorflow:examples/sec: 5.50989\n","INFO:tensorflow:global_step/sec: 1.52752\n","INFO:tensorflow:examples/sec: 6.11008\n","INFO:tensorflow:global_step/sec: 1.46804\n","INFO:tensorflow:examples/sec: 5.87216\n","INFO:tensorflow:Saving checkpoints for 12000 into /content/trained_output/model.ckpt.\n","INFO:tensorflow:global_step/sec: 1.54165\n","INFO:tensorflow:examples/sec: 6.16659\n","INFO:tensorflow:global_step/sec: 1.46608\n","INFO:tensorflow:examples/sec: 5.86433\n","INFO:tensorflow:global_step/sec: 1.51604\n","INFO:tensorflow:examples/sec: 6.06416\n","INFO:tensorflow:global_step/sec: 1.5551\n","INFO:tensorflow:examples/sec: 6.2204\n","INFO:tensorflow:global_step/sec: 1.49563\n","INFO:tensorflow:examples/sec: 5.98252\n","INFO:tensorflow:global_step/sec: 1.56085\n","INFO:tensorflow:examples/sec: 6.24341\n","INFO:tensorflow:global_step/sec: 1.50722\n","INFO:tensorflow:examples/sec: 6.02889\n","INFO:tensorflow:global_step/sec: 1.54535\n","INFO:tensorflow:examples/sec: 6.1814\n","INFO:tensorflow:global_step/sec: 1.60555\n","INFO:tensorflow:examples/sec: 6.42221\n","INFO:tensorflow:global_step/sec: 1.5233\n","INFO:tensorflow:examples/sec: 6.09322\n","INFO:tensorflow:Saving checkpoints for 13000 into /content/trained_output/model.ckpt.\n","INFO:tensorflow:global_step/sec: 1.50114\n","INFO:tensorflow:examples/sec: 6.00457\n","INFO:tensorflow:global_step/sec: 1.52795\n","INFO:tensorflow:examples/sec: 6.11179\n","INFO:tensorflow:global_step/sec: 1.50431\n","INFO:tensorflow:examples/sec: 6.01723\n","INFO:tensorflow:global_step/sec: 1.55696\n","INFO:tensorflow:examples/sec: 6.22785\n","INFO:tensorflow:global_step/sec: 1.46771\n","INFO:tensorflow:examples/sec: 5.87083\n","INFO:tensorflow:global_step/sec: 1.54716\n","INFO:tensorflow:examples/sec: 6.18864\n","INFO:tensorflow:global_step/sec: 1.53661\n","INFO:tensorflow:examples/sec: 6.14643\n","INFO:tensorflow:global_step/sec: 1.51545\n","INFO:tensorflow:examples/sec: 6.06179\n","INFO:tensorflow:global_step/sec: 1.54997\n","INFO:tensorflow:examples/sec: 6.1999\n","INFO:tensorflow:global_step/sec: 1.49136\n","INFO:tensorflow:examples/sec: 5.96546\n","INFO:tensorflow:Saving checkpoints for 14000 into /content/trained_output/model.ckpt.\n","INFO:tensorflow:global_step/sec: 1.52806\n","INFO:tensorflow:examples/sec: 6.11224\n","INFO:tensorflow:global_step/sec: 1.53358\n","INFO:tensorflow:examples/sec: 6.13434\n","INFO:tensorflow:global_step/sec: 1.47162\n","INFO:tensorflow:examples/sec: 5.88649\n","INFO:tensorflow:global_step/sec: 1.4741\n","INFO:tensorflow:examples/sec: 5.89641\n","INFO:tensorflow:global_step/sec: 1.45767\n","INFO:tensorflow:examples/sec: 5.83066\n","INFO:tensorflow:global_step/sec: 1.4918\n","INFO:tensorflow:examples/sec: 5.96719\n","INFO:tensorflow:global_step/sec: 1.52516\n","INFO:tensorflow:examples/sec: 6.10064\n","INFO:tensorflow:global_step/sec: 1.56886\n","INFO:tensorflow:examples/sec: 6.27546\n","INFO:tensorflow:global_step/sec: 1.52165\n","INFO:tensorflow:examples/sec: 6.08662\n","INFO:tensorflow:global_step/sec: 1.51992\n","INFO:tensorflow:examples/sec: 6.07969\n","INFO:tensorflow:Saving checkpoints for 15000 into /content/trained_output/model.ckpt.\n","INFO:tensorflow:global_step/sec: 1.55466\n","INFO:tensorflow:examples/sec: 6.21865\n","INFO:tensorflow:global_step/sec: 1.4878\n","INFO:tensorflow:examples/sec: 5.95121\n","INFO:tensorflow:global_step/sec: 1.51767\n","INFO:tensorflow:examples/sec: 6.07069\n","INFO:tensorflow:global_step/sec: 1.52574\n","INFO:tensorflow:examples/sec: 6.10296\n","INFO:tensorflow:global_step/sec: 1.52587\n","INFO:tensorflow:examples/sec: 6.10347\n","INFO:tensorflow:global_step/sec: 1.58653\n","INFO:tensorflow:examples/sec: 6.34611\n","INFO:tensorflow:global_step/sec: 1.48103\n","INFO:tensorflow:examples/sec: 5.92412\n","INFO:tensorflow:global_step/sec: 1.54639\n","INFO:tensorflow:examples/sec: 6.18556\n","INFO:tensorflow:global_step/sec: 1.52315\n","INFO:tensorflow:examples/sec: 6.09259\n","INFO:tensorflow:global_step/sec: 1.48718\n","INFO:tensorflow:examples/sec: 5.94872\n","INFO:tensorflow:Saving checkpoints for 16000 into /content/trained_output/model.ckpt.\n","INFO:tensorflow:global_step/sec: 1.47657\n","INFO:tensorflow:examples/sec: 5.90628\n","INFO:tensorflow:global_step/sec: 1.45688\n","INFO:tensorflow:examples/sec: 5.82752\n","INFO:tensorflow:global_step/sec: 1.47646\n","INFO:tensorflow:examples/sec: 5.90584\n","INFO:tensorflow:global_step/sec: 1.47493\n","INFO:tensorflow:examples/sec: 5.8997\n","INFO:tensorflow:global_step/sec: 1.50989\n","INFO:tensorflow:examples/sec: 6.03958\n","INFO:tensorflow:global_step/sec: 1.47054\n","INFO:tensorflow:examples/sec: 5.88215\n","INFO:tensorflow:global_step/sec: 1.53351\n","INFO:tensorflow:examples/sec: 6.13403\n","INFO:tensorflow:global_step/sec: 1.42072\n","INFO:tensorflow:examples/sec: 5.68287\n","INFO:tensorflow:global_step/sec: 1.53407\n","INFO:tensorflow:examples/sec: 6.13628\n","INFO:tensorflow:global_step/sec: 1.43607\n","INFO:tensorflow:examples/sec: 5.74427\n","INFO:tensorflow:Saving checkpoints for 17000 into /content/trained_output/model.ckpt.\n","INFO:tensorflow:global_step/sec: 1.45892\n","INFO:tensorflow:examples/sec: 5.83568\n","INFO:tensorflow:global_step/sec: 1.431\n","INFO:tensorflow:examples/sec: 5.72402\n","INFO:tensorflow:global_step/sec: 1.52798\n","INFO:tensorflow:examples/sec: 6.11191\n","INFO:tensorflow:global_step/sec: 1.43961\n","INFO:tensorflow:examples/sec: 5.75846\n","INFO:tensorflow:global_step/sec: 1.52318\n","INFO:tensorflow:examples/sec: 6.09271\n","INFO:tensorflow:global_step/sec: 1.36024\n","INFO:tensorflow:examples/sec: 5.44098\n","INFO:tensorflow:global_step/sec: 1.48449\n","INFO:tensorflow:examples/sec: 5.93797\n","INFO:tensorflow:global_step/sec: 1.45335\n","INFO:tensorflow:examples/sec: 5.81339\n","INFO:tensorflow:global_step/sec: 1.52189\n","INFO:tensorflow:examples/sec: 6.08757\n","INFO:tensorflow:global_step/sec: 1.41752\n","INFO:tensorflow:examples/sec: 5.67007\n","INFO:tensorflow:Saving checkpoints for 18000 into /content/trained_output/model.ckpt.\n","INFO:tensorflow:global_step/sec: 1.49925\n","INFO:tensorflow:examples/sec: 5.99701\n","INFO:tensorflow:global_step/sec: 1.47239\n","INFO:tensorflow:examples/sec: 5.88957\n","INFO:tensorflow:global_step/sec: 1.4952\n","INFO:tensorflow:examples/sec: 5.98079\n","INFO:tensorflow:global_step/sec: 1.42627\n","INFO:tensorflow:examples/sec: 5.70509\n","INFO:tensorflow:global_step/sec: 1.42917\n","INFO:tensorflow:examples/sec: 5.71667\n","INFO:tensorflow:global_step/sec: 1.41307\n","INFO:tensorflow:examples/sec: 5.65228\n","INFO:tensorflow:global_step/sec: 1.47239\n","INFO:tensorflow:examples/sec: 5.88956\n","INFO:tensorflow:global_step/sec: 1.42796\n","INFO:tensorflow:examples/sec: 5.71184\n","INFO:tensorflow:global_step/sec: 1.50683\n","INFO:tensorflow:examples/sec: 6.02733\n","INFO:tensorflow:global_step/sec: 1.46645\n","INFO:tensorflow:examples/sec: 5.8658\n","INFO:tensorflow:Saving checkpoints for 19000 into /content/trained_output/model.ckpt.\n","INFO:tensorflow:global_step/sec: 1.50659\n","INFO:tensorflow:examples/sec: 6.02637\n","INFO:tensorflow:global_step/sec: 1.45469\n","INFO:tensorflow:examples/sec: 5.81875\n","INFO:tensorflow:global_step/sec: 1.53122\n","INFO:tensorflow:examples/sec: 6.12486\n","INFO:tensorflow:global_step/sec: 1.4661\n","INFO:tensorflow:examples/sec: 5.86438\n","INFO:tensorflow:global_step/sec: 1.48325\n","INFO:tensorflow:examples/sec: 5.933\n","INFO:tensorflow:global_step/sec: 1.47646\n","INFO:tensorflow:examples/sec: 5.90585\n","INFO:tensorflow:global_step/sec: 1.479\n","INFO:tensorflow:examples/sec: 5.91598\n","INFO:tensorflow:global_step/sec: 1.42416\n","INFO:tensorflow:examples/sec: 5.69664\n","INFO:tensorflow:global_step/sec: 1.50929\n","INFO:tensorflow:examples/sec: 6.03718\n","INFO:tensorflow:global_step/sec: 1.48064\n","INFO:tensorflow:examples/sec: 5.92258\n","INFO:tensorflow:Saving checkpoints for 20000 into /content/trained_output/model.ckpt.\n","INFO:tensorflow:global_step/sec: 1.44351\n","INFO:tensorflow:examples/sec: 5.77404\n","INFO:tensorflow:global_step/sec: 1.42423\n","INFO:tensorflow:examples/sec: 5.69692\n","INFO:tensorflow:global_step/sec: 1.48438\n","INFO:tensorflow:examples/sec: 5.93752\n","INFO:tensorflow:global_step/sec: 1.50026\n","INFO:tensorflow:examples/sec: 6.00104\n","INFO:tensorflow:global_step/sec: 1.46531\n","INFO:tensorflow:examples/sec: 5.86126\n","INFO:tensorflow:global_step/sec: 1.48324\n","INFO:tensorflow:examples/sec: 5.93294\n","INFO:tensorflow:global_step/sec: 1.4659\n","INFO:tensorflow:examples/sec: 5.86362\n","INFO:tensorflow:global_step/sec: 1.52554\n","INFO:tensorflow:examples/sec: 6.10217\n","INFO:tensorflow:global_step/sec: 1.44954\n","INFO:tensorflow:examples/sec: 5.79816\n","INFO:tensorflow:global_step/sec: 1.52754\n","INFO:tensorflow:examples/sec: 6.11016\n","INFO:tensorflow:Saving checkpoints for 21000 into /content/trained_output/model.ckpt.\n","INFO:tensorflow:global_step/sec: 1.43231\n","INFO:tensorflow:examples/sec: 5.72923\n","INFO:tensorflow:global_step/sec: 1.51783\n","INFO:tensorflow:examples/sec: 6.07133\n","INFO:tensorflow:global_step/sec: 1.3823\n","INFO:tensorflow:examples/sec: 5.52921\n","INFO:tensorflow:global_step/sec: 1.53002\n","INFO:tensorflow:examples/sec: 6.12006\n","INFO:tensorflow:global_step/sec: 1.41071\n","INFO:tensorflow:examples/sec: 5.64284\n","INFO:tensorflow:global_step/sec: 1.52858\n","INFO:tensorflow:examples/sec: 6.11431\n","INFO:tensorflow:global_step/sec: 1.45456\n","INFO:tensorflow:examples/sec: 5.81822\n","INFO:tensorflow:global_step/sec: 1.4652\n","INFO:tensorflow:examples/sec: 5.86082\n","INFO:tensorflow:global_step/sec: 1.51102\n","INFO:tensorflow:examples/sec: 6.04409\n","INFO:tensorflow:global_step/sec: 1.47289\n","INFO:tensorflow:examples/sec: 5.89155\n","INFO:tensorflow:Saving checkpoints for 22000 into /content/trained_output/model.ckpt.\n","INFO:tensorflow:global_step/sec: 1.45162\n","INFO:tensorflow:examples/sec: 5.80646\n","INFO:tensorflow:global_step/sec: 1.49685\n","INFO:tensorflow:examples/sec: 5.98739\n","INFO:tensorflow:global_step/sec: 1.53373\n","INFO:tensorflow:examples/sec: 6.13492\n","INFO:tensorflow:global_step/sec: 1.44019\n","INFO:tensorflow:examples/sec: 5.76077\n","INFO:tensorflow:global_step/sec: 1.51864\n","INFO:tensorflow:examples/sec: 6.07458\n","INFO:tensorflow:global_step/sec: 1.41494\n","INFO:tensorflow:examples/sec: 5.65977\n","INFO:tensorflow:global_step/sec: 1.5373\n","INFO:tensorflow:examples/sec: 6.14921\n","INFO:tensorflow:global_step/sec: 1.42209\n","INFO:tensorflow:examples/sec: 5.68837\n","INFO:tensorflow:global_step/sec: 1.49465\n","INFO:tensorflow:examples/sec: 5.9786\n","INFO:tensorflow:global_step/sec: 1.43456\n","INFO:tensorflow:examples/sec: 5.73824\n","INFO:tensorflow:Saving checkpoints for 23000 into /content/trained_output/model.ckpt.\n","INFO:tensorflow:global_step/sec: 1.48982\n","INFO:tensorflow:examples/sec: 5.95928\n","INFO:tensorflow:global_step/sec: 1.42521\n","INFO:tensorflow:examples/sec: 5.70085\n","INFO:tensorflow:global_step/sec: 1.4935\n","INFO:tensorflow:examples/sec: 5.97399\n","INFO:tensorflow:global_step/sec: 1.43957\n","INFO:tensorflow:examples/sec: 5.75826\n","INFO:tensorflow:global_step/sec: 1.5154\n","INFO:tensorflow:examples/sec: 6.0616\n","INFO:tensorflow:global_step/sec: 1.50223\n","INFO:tensorflow:examples/sec: 6.00893\n","INFO:tensorflow:global_step/sec: 1.52415\n","INFO:tensorflow:examples/sec: 6.0966\n","INFO:tensorflow:global_step/sec: 1.4455\n","INFO:tensorflow:examples/sec: 5.78199\n","INFO:tensorflow:global_step/sec: 1.50112\n","INFO:tensorflow:examples/sec: 6.00449\n","INFO:tensorflow:global_step/sec: 1.42449\n","INFO:tensorflow:examples/sec: 5.69797\n","INFO:tensorflow:Saving checkpoints for 24000 into /content/trained_output/model.ckpt.\n","INFO:tensorflow:global_step/sec: 1.45041\n","INFO:tensorflow:examples/sec: 5.80166\n","INFO:tensorflow:global_step/sec: 1.36675\n","INFO:tensorflow:examples/sec: 5.467\n","INFO:tensorflow:global_step/sec: 1.47107\n","INFO:tensorflow:examples/sec: 5.88428\n","INFO:tensorflow:global_step/sec: 1.4597\n","INFO:tensorflow:examples/sec: 5.8388\n","INFO:tensorflow:global_step/sec: 1.44931\n","INFO:tensorflow:examples/sec: 5.79723\n","INFO:tensorflow:global_step/sec: 1.41968\n","INFO:tensorflow:examples/sec: 5.67871\n","INFO:tensorflow:global_step/sec: 1.44324\n","INFO:tensorflow:examples/sec: 5.77296\n","INFO:tensorflow:global_step/sec: 1.49203\n","INFO:tensorflow:examples/sec: 5.9681\n","INFO:tensorflow:global_step/sec: 1.45591\n","INFO:tensorflow:examples/sec: 5.82362\n","INFO:tensorflow:global_step/sec: 1.44978\n","INFO:tensorflow:examples/sec: 5.79914\n","INFO:tensorflow:Saving checkpoints for 25000 into /content/trained_output/model.ckpt.\n","INFO:tensorflow:global_step/sec: 1.40362\n","INFO:tensorflow:examples/sec: 5.61447\n","INFO:tensorflow:global_step/sec: 1.48297\n","INFO:tensorflow:examples/sec: 5.93187\n","INFO:tensorflow:global_step/sec: 1.38345\n","INFO:tensorflow:examples/sec: 5.53379\n","INFO:tensorflow:global_step/sec: 1.50371\n","INFO:tensorflow:examples/sec: 6.01485\n","INFO:tensorflow:global_step/sec: 1.43132\n","INFO:tensorflow:examples/sec: 5.72527\n","INFO:tensorflow:global_step/sec: 1.51399\n","INFO:tensorflow:examples/sec: 6.05594\n","INFO:tensorflow:global_step/sec: 1.42241\n","INFO:tensorflow:examples/sec: 5.68963\n","INFO:tensorflow:global_step/sec: 1.49354\n","INFO:tensorflow:examples/sec: 5.97416\n","INFO:tensorflow:global_step/sec: 1.4028\n","INFO:tensorflow:examples/sec: 5.6112\n","INFO:tensorflow:global_step/sec: 1.43792\n","INFO:tensorflow:examples/sec: 5.7517\n","INFO:tensorflow:Saving checkpoints for 26000 into /content/trained_output/model.ckpt.\n","INFO:tensorflow:global_step/sec: 1.42089\n","INFO:tensorflow:examples/sec: 5.68354\n","INFO:tensorflow:global_step/sec: 1.40777\n","INFO:tensorflow:examples/sec: 5.63107\n","INFO:tensorflow:global_step/sec: 1.43497\n","INFO:tensorflow:examples/sec: 5.73987\n","INFO:tensorflow:global_step/sec: 1.49401\n","INFO:tensorflow:examples/sec: 5.97603\n","INFO:tensorflow:global_step/sec: 1.41922\n","INFO:tensorflow:examples/sec: 5.6769\n","INFO:tensorflow:global_step/sec: 1.40056\n","INFO:tensorflow:examples/sec: 5.60223\n","INFO:tensorflow:global_step/sec: 1.44415\n","INFO:tensorflow:examples/sec: 5.7766\n","INFO:tensorflow:global_step/sec: 1.39074\n","INFO:tensorflow:examples/sec: 5.56297\n","INFO:tensorflow:global_step/sec: 1.49732\n","INFO:tensorflow:examples/sec: 5.98928\n","INFO:tensorflow:global_step/sec: 1.42056\n","INFO:tensorflow:examples/sec: 5.68222\n","INFO:tensorflow:Saving checkpoints for 27000 into /content/trained_output/model.ckpt.\n","INFO:tensorflow:global_step/sec: 1.46688\n","INFO:tensorflow:examples/sec: 5.86753\n","INFO:tensorflow:global_step/sec: 1.44704\n","INFO:tensorflow:examples/sec: 5.78815\n","INFO:tensorflow:global_step/sec: 1.53312\n","INFO:tensorflow:examples/sec: 6.13248\n","INFO:tensorflow:global_step/sec: 1.46231\n","INFO:tensorflow:examples/sec: 5.84924\n","INFO:tensorflow:global_step/sec: 1.52569\n","INFO:tensorflow:examples/sec: 6.10278\n","INFO:tensorflow:global_step/sec: 1.44006\n","INFO:tensorflow:examples/sec: 5.76026\n","INFO:tensorflow:global_step/sec: 1.50016\n","INFO:tensorflow:examples/sec: 6.00063\n","INFO:tensorflow:global_step/sec: 1.46087\n","INFO:tensorflow:examples/sec: 5.84349\n","INFO:tensorflow:global_step/sec: 1.52883\n","INFO:tensorflow:examples/sec: 6.11531\n","INFO:tensorflow:global_step/sec: 1.42485\n","INFO:tensorflow:examples/sec: 5.69941\n","INFO:tensorflow:Saving checkpoints for 28000 into /content/trained_output/model.ckpt.\n","INFO:tensorflow:global_step/sec: 1.46237\n","INFO:tensorflow:examples/sec: 5.84948\n","INFO:tensorflow:global_step/sec: 1.44338\n","INFO:tensorflow:examples/sec: 5.77352\n","INFO:tensorflow:global_step/sec: 1.53153\n","INFO:tensorflow:examples/sec: 6.12611\n","INFO:tensorflow:global_step/sec: 1.48625\n","INFO:tensorflow:examples/sec: 5.94499\n","INFO:tensorflow:global_step/sec: 1.52579\n","INFO:tensorflow:examples/sec: 6.10315\n","INFO:tensorflow:global_step/sec: 1.52729\n","INFO:tensorflow:examples/sec: 6.10916\n","INFO:tensorflow:global_step/sec: 1.49025\n","INFO:tensorflow:examples/sec: 5.96102\n","INFO:tensorflow:global_step/sec: 1.50796\n","INFO:tensorflow:examples/sec: 6.03185\n","INFO:tensorflow:global_step/sec: 1.48834\n","INFO:tensorflow:examples/sec: 5.95335\n","INFO:tensorflow:global_step/sec: 1.51608\n","INFO:tensorflow:examples/sec: 6.06431\n","INFO:tensorflow:Saving checkpoints for 29000 into /content/trained_output/model.ckpt.\n","INFO:tensorflow:global_step/sec: 1.42065\n","INFO:tensorflow:examples/sec: 5.6826\n","INFO:tensorflow:global_step/sec: 1.49299\n","INFO:tensorflow:examples/sec: 5.97197\n","INFO:tensorflow:global_step/sec: 1.44008\n","INFO:tensorflow:examples/sec: 5.76032\n","INFO:tensorflow:global_step/sec: 1.5071\n","INFO:tensorflow:examples/sec: 6.02841\n","INFO:tensorflow:global_step/sec: 1.48685\n","INFO:tensorflow:examples/sec: 5.94739\n","INFO:tensorflow:global_step/sec: 1.4636\n","INFO:tensorflow:examples/sec: 5.8544\n","INFO:tensorflow:global_step/sec: 1.53641\n","INFO:tensorflow:examples/sec: 6.14564\n","INFO:tensorflow:global_step/sec: 1.4821\n","INFO:tensorflow:examples/sec: 5.92838\n","INFO:tensorflow:global_step/sec: 1.47899\n","INFO:tensorflow:examples/sec: 5.91597\n","INFO:tensorflow:global_step/sec: 1.55026\n","INFO:tensorflow:examples/sec: 6.20103\n","INFO:tensorflow:Saving checkpoints for 30000 into /content/trained_output/model.ckpt.\n","INFO:tensorflow:global_step/sec: 1.46593\n","INFO:tensorflow:examples/sec: 5.86371\n","INFO:tensorflow:global_step/sec: 1.51954\n","INFO:tensorflow:examples/sec: 6.07814\n","INFO:tensorflow:global_step/sec: 1.49432\n","INFO:tensorflow:examples/sec: 5.97729\n","INFO:tensorflow:global_step/sec: 1.57312\n","INFO:tensorflow:examples/sec: 6.29249\n","INFO:tensorflow:global_step/sec: 1.50671\n","INFO:tensorflow:examples/sec: 6.02683\n","INFO:tensorflow:global_step/sec: 1.53142\n","INFO:tensorflow:examples/sec: 6.12568\n","INFO:tensorflow:global_step/sec: 1.51542\n","INFO:tensorflow:examples/sec: 6.06169\n","INFO:tensorflow:global_step/sec: 1.50502\n","INFO:tensorflow:examples/sec: 6.02006\n","INFO:tensorflow:global_step/sec: 1.53555\n","INFO:tensorflow:examples/sec: 6.1422\n","INFO:tensorflow:global_step/sec: 1.51617\n","INFO:tensorflow:examples/sec: 6.06467\n","INFO:tensorflow:Saving checkpoints for 31000 into /content/trained_output/model.ckpt.\n","INFO:tensorflow:global_step/sec: 1.55707\n","INFO:tensorflow:examples/sec: 6.22826\n","INFO:tensorflow:global_step/sec: 1.49405\n","INFO:tensorflow:examples/sec: 5.97619\n","INFO:tensorflow:global_step/sec: 1.51512\n","INFO:tensorflow:examples/sec: 6.06048\n","INFO:tensorflow:global_step/sec: 1.52205\n","INFO:tensorflow:examples/sec: 6.08818\n","INFO:tensorflow:global_step/sec: 1.49427\n","INFO:tensorflow:examples/sec: 5.97709\n","INFO:tensorflow:global_step/sec: 1.52063\n","INFO:tensorflow:examples/sec: 6.08252\n","INFO:tensorflow:global_step/sec: 1.50496\n","INFO:tensorflow:examples/sec: 6.01985\n","INFO:tensorflow:global_step/sec: 1.58206\n","INFO:tensorflow:examples/sec: 6.32823\n","INFO:tensorflow:global_step/sec: 1.51598\n","INFO:tensorflow:examples/sec: 6.06393\n","INFO:tensorflow:global_step/sec: 1.55658\n","INFO:tensorflow:examples/sec: 6.2263\n","INFO:tensorflow:Saving checkpoints for 32000 into /content/trained_output/model.ckpt.\n","INFO:tensorflow:global_step/sec: 1.46884\n","INFO:tensorflow:examples/sec: 5.87537\n","INFO:tensorflow:global_step/sec: 1.56298\n","INFO:tensorflow:examples/sec: 6.25194\n","INFO:tensorflow:global_step/sec: 1.48729\n","INFO:tensorflow:examples/sec: 5.94914\n","INFO:tensorflow:global_step/sec: 1.46898\n","INFO:tensorflow:examples/sec: 5.87593\n","INFO:tensorflow:global_step/sec: 1.59025\n","INFO:tensorflow:examples/sec: 6.36102\n","INFO:tensorflow:global_step/sec: 1.52149\n","INFO:tensorflow:examples/sec: 6.08597\n","INFO:tensorflow:training_loop marked as finished\n","Traceback (most recent call last):\n","  File \"run_classifier.py\", line 1330, in <module>\n","    tf.app.run()\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py\", line 125, in run\n","    _sys.exit(main(argv))\n","  File \"run_classifier.py\", line 1229, in main\n","    estimator.train(input_fn=train_input_fn, max_steps=num_train_steps)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/contrib/tpu/python/tpu/tpu_estimator.py\", line 2452, in train\n","    saving_listeners=saving_listeners)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 358, in train\n","    loss = self._train_model(input_fn, hooks, saving_listeners)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1124, in _train_model\n","    return self._train_model_default(input_fn, hooks, saving_listeners)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1158, in _train_model_default\n","    saving_listeners)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1407, in _train_with_estimator_spec\n","    _, loss = mon_sess.run([estimator_spec.train_op, estimator_spec.loss])\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/monitored_session.py\", line 676, in run\n","    run_metadata=run_metadata)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/monitored_session.py\", line 1171, in run\n","    run_metadata=run_metadata)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/monitored_session.py\", line 1255, in run\n","    return self._sess.run(*args, **kwargs)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/monitored_session.py\", line 1327, in run\n","    run_metadata=run_metadata)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/monitored_session.py\", line 1091, in run\n","    return self._sess.run(*args, **kwargs)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\", line 929, in run\n","    run_metadata_ptr)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\", line 1152, in _run\n","    feed_dict_tensor, options, run_metadata)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\", line 1328, in _do_run\n","    run_metadata)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\", line 1334, in _do_call\n","    return fn(*args)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\", line 1319, in _run_fn\n","    options, feed_dict, fetch_list, target_list, run_metadata)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\", line 1407, in _call_tf_sessionrun\n","    run_metadata)\n","KeyboardInterrupt\n","^C\n"]}],"source":["%cd /content/drive/MyDrive/Code_pretrain\n","%pwd\n","%env BERT_BASE_DIR=uncased_L-4_H-256_A-4\n","%env GLUE_DIR=data\n","!rm -rf /content/trained_output\n","\n","!python3 run_classifier.py \\\n","  --task_name=MNLI-MM \\\n","  --do_train=true \\\n","  --do_eval=true \\\n","  --data_dir=$GLUE_DIR/MNLI \\\n","  --vocab_file=$BERT_BASE_DIR/vocab.txt \\\n","  --bert_config_file=$BERT_BASE_DIR/bert_config.json \\\n","  --init_checkpoint=$BERT_BASE_DIR/bert_model.ckpt \\\n","  --max_seq_length=128 \\\n","  --train_batch_size=4 \\\n","  --learning_rate=2e-5 \\\n","  --num_train_epochs=1.0 \\\n","  --output_dir=/content/trained_output\n","\n","# result metric.\n","# INFO:tensorflow:  eval_accuracy = 0.6647681\n","# INFO:tensorflow:  eval_loss = 0.7852047\n","# INFO:tensorflow:  global_step = 98175\n","# INFO:tensorflow:  loss = 0.7852047\n","\n","# INFO:tensorflow:  eval_accuracy = 0.5509561\n","# INFO:tensorflow:  eval_loss = 0.94312745\n","# INFO:tensorflow:  global_step = 98175\n","# INFO:tensorflow:  loss = 0.94312745"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"PwzPIHAp-h6C","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1684740153440,"user_tz":-480,"elapsed":60582,"user":{"displayName":"Brian Shen","userId":"08246478872294528508"}},"outputId":"33663a6b-be48-42e6-fd51-437342204fd1"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Code_pretrain\n","env: BERT_BASE_DIR=uncased_L-4_H-256_A-4\n","env: GLUE_DIR=data\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n","\n","WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n","For more information, please see:\n","  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n","  * https://github.com/tensorflow/addons\n","If you depend on functionality not listed there, please file an issue.\n","\n","WARNING:tensorflow:Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f2b21ddbae8>) includes params argument, but params are not passed to Estimator.\n","INFO:tensorflow:Using config: {'_model_dir': '/content/trained_output', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 1000, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n","graph_options {\n","  rewrite_options {\n","    meta_optimizer_iterations: ONE\n","  }\n","}\n",", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f2b22411c18>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=1000, num_shards=8, num_cores_per_replica=None, per_host_input_for_training=3, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None), '_cluster': None}\n","INFO:tensorflow:_TPUContext: eval_on_tpu True\n","WARNING:tensorflow:eval_on_tpu ignored because use_tpu is False.\n","INFO:tensorflow:Writing example 0 of 5749\n","INFO:tensorflow:*** Example ***\n","INFO:tensorflow:guid: train-0\n","INFO:tensorflow:tokens: [CLS] a plane is taking off . [SEP] an air plane is taking off . [SEP]\n","INFO:tensorflow:input_ids: 101 1037 4946 2003 2635 2125 1012 102 2019 2250 4946 2003 2635 2125 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:label: 5 (id = 5)\n","INFO:tensorflow:*** Example ***\n","INFO:tensorflow:guid: train-1\n","INFO:tensorflow:tokens: [CLS] a man is playing a large flute . [SEP] a man is playing a flute . [SEP]\n","INFO:tensorflow:input_ids: 101 1037 2158 2003 2652 1037 2312 8928 1012 102 1037 2158 2003 2652 1037 8928 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:label: 3 (id = 3)\n","INFO:tensorflow:*** Example ***\n","INFO:tensorflow:guid: train-2\n","INFO:tensorflow:tokens: [CLS] a man is spreading sh ##red ##ed cheese on a pizza . [SEP] a man is spreading shredded cheese on an un ##co ##oked pizza . [SEP]\n","INFO:tensorflow:input_ids: 101 1037 2158 2003 9359 14021 5596 2098 8808 2006 1037 10733 1012 102 1037 2158 2003 9359 29022 8808 2006 2019 4895 3597 23461 10733 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:label: 3 (id = 3)\n","INFO:tensorflow:*** Example ***\n","INFO:tensorflow:guid: train-3\n","INFO:tensorflow:tokens: [CLS] three men are playing chess . [SEP] two men are playing chess . [SEP]\n","INFO:tensorflow:input_ids: 101 2093 2273 2024 2652 7433 1012 102 2048 2273 2024 2652 7433 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:label: 2 (id = 2)\n","INFO:tensorflow:*** Example ***\n","INFO:tensorflow:guid: train-4\n","INFO:tensorflow:tokens: [CLS] a man is playing the cello . [SEP] a man seated is playing the cello . [SEP]\n","INFO:tensorflow:input_ids: 101 1037 2158 2003 2652 1996 10145 1012 102 1037 2158 8901 2003 2652 1996 10145 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:label: 4 (id = 4)\n","INFO:tensorflow:***** Running training *****\n","INFO:tensorflow:  Num examples = 5749\n","INFO:tensorflow:  Batch size = 4\n","INFO:tensorflow:  Num steps = 1437\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Colocations handled automatically by placer.\n","WARNING:tensorflow:From run_classifier.py:890: map_and_batch (from tensorflow.contrib.data.python.ops.batching) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.experimental.map_and_batch(...)`.\n","WARNING:tensorflow:From run_classifier.py:870: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.cast instead.\n","INFO:tensorflow:Calling model_fn.\n","INFO:tensorflow:Running train on CPU\n","INFO:tensorflow:*** Features ***\n","INFO:tensorflow:  name = input_ids, shape = (4, 128)\n","INFO:tensorflow:  name = input_mask, shape = (4, 128)\n","INFO:tensorflow:  name = is_real_example, shape = (4,)\n","INFO:tensorflow:  name = label_ids, shape = (4,)\n","INFO:tensorflow:  name = segment_ids, shape = (4, 128)\n","WARNING:tensorflow:From /content/drive/MyDrive/Code_pretrain/modeling.py:358: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n","WARNING:tensorflow:From /content/drive/MyDrive/Code_pretrain/modeling.py:671: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use keras.layers.dense instead.\n","INFO:tensorflow:**** Trainable Variables ****\n","INFO:tensorflow:  name = bert/embeddings/word_embeddings:0, shape = (30522, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/embeddings/token_type_embeddings:0, shape = (2, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/embeddings/position_embeddings:0, shape = (512, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/embeddings/LayerNorm/beta:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/embeddings/LayerNorm/gamma:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/query/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/query/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/key/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/key/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/value/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/value/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/dense/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/dense/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/LayerNorm/beta:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/LayerNorm/gamma:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/intermediate/dense/kernel:0, shape = (256, 1024), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/intermediate/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/output/dense/kernel:0, shape = (1024, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/output/dense/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/output/LayerNorm/beta:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/output/LayerNorm/gamma:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/query/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/query/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/key/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/key/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/value/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/value/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/dense/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/dense/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/LayerNorm/beta:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/LayerNorm/gamma:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/intermediate/dense/kernel:0, shape = (256, 1024), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/intermediate/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/output/dense/kernel:0, shape = (1024, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/output/dense/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/output/LayerNorm/beta:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/output/LayerNorm/gamma:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/query/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/query/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/key/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/key/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/value/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/value/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/dense/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/dense/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/LayerNorm/beta:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/LayerNorm/gamma:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/intermediate/dense/kernel:0, shape = (256, 1024), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/intermediate/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/output/dense/kernel:0, shape = (1024, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/output/dense/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/output/LayerNorm/beta:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/output/LayerNorm/gamma:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/query/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/query/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/key/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/key/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/value/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/value/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/dense/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/dense/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/LayerNorm/beta:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/LayerNorm/gamma:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/intermediate/dense/kernel:0, shape = (256, 1024), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/intermediate/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/output/dense/kernel:0, shape = (1024, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/output/dense/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/output/LayerNorm/beta:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/output/LayerNorm/gamma:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/pooler/dense/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/pooler/dense/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = output_weights:0, shape = (6, 256)\n","INFO:tensorflow:  name = output_bias:0, shape = (6,)\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/learning_rate_decay_v2.py:321: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Deprecated in favor of operator or tf.math.divide.\n","INFO:tensorflow:Done calling model_fn.\n","INFO:tensorflow:Create CheckpointSaverHook.\n","INFO:tensorflow:Graph was finalized.\n","2023-05-22 07:21:47.206809: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA\n","2023-05-22 07:21:47.398788: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2023-05-22 07:21:47.403044: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x7dff100 executing computations on platform CUDA. Devices:\n","2023-05-22 07:21:47.403082: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n","2023-05-22 07:21:47.437670: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2000185000 Hz\n","2023-05-22 07:21:47.437866: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x35b3e20 executing computations on platform Host. Devices:\n","2023-05-22 07:21:47.437893: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>\n","2023-05-22 07:21:47.438078: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 0 with properties: \n","name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n","pciBusID: 0000:00:04.0\n","totalMemory: 14.75GiB freeMemory: 14.65GiB\n","2023-05-22 07:21:47.438109: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0\n","2023-05-22 07:21:47.439165: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2023-05-22 07:21:47.439200: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0 \n","2023-05-22 07:21:47.439216: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N \n","2023-05-22 07:21:47.439285: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","2023-05-22 07:21:47.439395: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14248 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n","INFO:tensorflow:Running local_init_op.\n","INFO:tensorflow:Done running local_init_op.\n","INFO:tensorflow:Saving checkpoints for 0 into /content/trained_output/model.ckpt.\n","2023-05-22 07:21:55.312879: I tensorflow/stream_executor/dso_loader.cc:152] successfully opened CUDA library libcublas.so.10.0 locally\n","INFO:tensorflow:global_step/sec: 32.1403\n","INFO:tensorflow:examples/sec: 128.561\n","INFO:tensorflow:global_step/sec: 49.8543\n","INFO:tensorflow:examples/sec: 199.417\n","INFO:tensorflow:global_step/sec: 48.9249\n","INFO:tensorflow:examples/sec: 195.699\n","INFO:tensorflow:global_step/sec: 49.9973\n","INFO:tensorflow:examples/sec: 199.989\n","INFO:tensorflow:global_step/sec: 52.7809\n","INFO:tensorflow:examples/sec: 211.124\n","INFO:tensorflow:global_step/sec: 52.4906\n","INFO:tensorflow:examples/sec: 209.962\n","INFO:tensorflow:global_step/sec: 52.1949\n","INFO:tensorflow:examples/sec: 208.78\n","INFO:tensorflow:global_step/sec: 52.3198\n","INFO:tensorflow:examples/sec: 209.279\n","INFO:tensorflow:global_step/sec: 52.4067\n","INFO:tensorflow:examples/sec: 209.627\n","INFO:tensorflow:Saving checkpoints for 1000 into /content/trained_output/model.ckpt.\n","INFO:tensorflow:global_step/sec: 35.7794\n","INFO:tensorflow:examples/sec: 143.117\n","INFO:tensorflow:global_step/sec: 49.1081\n","INFO:tensorflow:examples/sec: 196.433\n","INFO:tensorflow:global_step/sec: 48.443\n","INFO:tensorflow:examples/sec: 193.772\n","INFO:tensorflow:global_step/sec: 50.0071\n","INFO:tensorflow:examples/sec: 200.028\n","INFO:tensorflow:global_step/sec: 52.1666\n","INFO:tensorflow:examples/sec: 208.666\n","INFO:tensorflow:Saving checkpoints for 1437 into /content/trained_output/model.ckpt.\n","INFO:tensorflow:Loss for final step: 1.2230304.\n","INFO:tensorflow:training_loop marked as finished\n","INFO:tensorflow:Writing example 0 of 1500\n","INFO:tensorflow:*** Example ***\n","INFO:tensorflow:guid: dev-0\n","INFO:tensorflow:tokens: [CLS] a man with a hard hat is dancing . [SEP] a man wearing a hard hat is dancing . [SEP]\n","INFO:tensorflow:input_ids: 101 1037 2158 2007 1037 2524 6045 2003 5613 1012 102 1037 2158 4147 1037 2524 6045 2003 5613 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:label: 5 (id = 5)\n","INFO:tensorflow:*** Example ***\n","INFO:tensorflow:guid: dev-1\n","INFO:tensorflow:tokens: [CLS] a young child is riding a horse . [SEP] a child is riding a horse . [SEP]\n","INFO:tensorflow:input_ids: 101 1037 2402 2775 2003 5559 1037 3586 1012 102 1037 2775 2003 5559 1037 3586 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:label: 4 (id = 4)\n","INFO:tensorflow:*** Example ***\n","INFO:tensorflow:guid: dev-2\n","INFO:tensorflow:tokens: [CLS] a man is feeding a mouse to a snake . [SEP] the man is feeding a mouse to the snake . [SEP]\n","INFO:tensorflow:input_ids: 101 1037 2158 2003 8521 1037 8000 2000 1037 7488 1012 102 1996 2158 2003 8521 1037 8000 2000 1996 7488 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:label: 5 (id = 5)\n","INFO:tensorflow:*** Example ***\n","INFO:tensorflow:guid: dev-3\n","INFO:tensorflow:tokens: [CLS] a woman is playing the guitar . [SEP] a man is playing guitar . [SEP]\n","INFO:tensorflow:input_ids: 101 1037 2450 2003 2652 1996 2858 1012 102 1037 2158 2003 2652 2858 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:label: 2 (id = 2)\n","INFO:tensorflow:*** Example ***\n","INFO:tensorflow:guid: dev-4\n","INFO:tensorflow:tokens: [CLS] a woman is playing the flute . [SEP] a man is playing a flute . [SEP]\n","INFO:tensorflow:input_ids: 101 1037 2450 2003 2652 1996 8928 1012 102 1037 2158 2003 2652 1037 8928 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:label: 2 (id = 2)\n","INFO:tensorflow:***** Running evaluation *****\n","INFO:tensorflow:  Num examples = 1500 (1500 actual, 0 padding)\n","INFO:tensorflow:  Batch size = 8\n","INFO:tensorflow:Calling model_fn.\n","INFO:tensorflow:Running eval on CPU\n","INFO:tensorflow:*** Features ***\n","INFO:tensorflow:  name = input_ids, shape = (?, 128)\n","INFO:tensorflow:  name = input_mask, shape = (?, 128)\n","INFO:tensorflow:  name = is_real_example, shape = (?,)\n","INFO:tensorflow:  name = label_ids, shape = (?,)\n","INFO:tensorflow:  name = segment_ids, shape = (?, 128)\n","INFO:tensorflow:**** Trainable Variables ****\n","INFO:tensorflow:  name = bert/embeddings/word_embeddings:0, shape = (30522, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/embeddings/token_type_embeddings:0, shape = (2, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/embeddings/position_embeddings:0, shape = (512, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/embeddings/LayerNorm/beta:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/embeddings/LayerNorm/gamma:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/query/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/query/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/key/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/key/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/value/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/value/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/dense/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/dense/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/LayerNorm/beta:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/LayerNorm/gamma:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/intermediate/dense/kernel:0, shape = (256, 1024), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/intermediate/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/output/dense/kernel:0, shape = (1024, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/output/dense/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/output/LayerNorm/beta:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/output/LayerNorm/gamma:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/query/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/query/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/key/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/key/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/value/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/value/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/dense/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/dense/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/LayerNorm/beta:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/LayerNorm/gamma:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/intermediate/dense/kernel:0, shape = (256, 1024), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/intermediate/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/output/dense/kernel:0, shape = (1024, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/output/dense/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/output/LayerNorm/beta:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/output/LayerNorm/gamma:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/query/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/query/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/key/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/key/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/value/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/value/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/dense/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/dense/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/LayerNorm/beta:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/LayerNorm/gamma:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/intermediate/dense/kernel:0, shape = (256, 1024), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/intermediate/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/output/dense/kernel:0, shape = (1024, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/output/dense/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/output/LayerNorm/beta:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/output/LayerNorm/gamma:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/query/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/query/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/key/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/key/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/value/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/value/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/dense/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/dense/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/LayerNorm/beta:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/LayerNorm/gamma:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/intermediate/dense/kernel:0, shape = (256, 1024), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/intermediate/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/output/dense/kernel:0, shape = (1024, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/output/dense/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/output/LayerNorm/beta:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/output/LayerNorm/gamma:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/pooler/dense/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/pooler/dense/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = output_weights:0, shape = (6, 256)\n","INFO:tensorflow:  name = output_bias:0, shape = (6,)\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/metrics_impl.py:455: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.cast instead.\n","INFO:tensorflow:Done calling model_fn.\n","INFO:tensorflow:Starting evaluation at 2023-05-22T07:22:29Z\n","INFO:tensorflow:Graph was finalized.\n","2023-05-22 07:22:29.864884: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0\n","2023-05-22 07:22:29.864949: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2023-05-22 07:22:29.864966: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0 \n","2023-05-22 07:22:29.864976: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N \n","2023-05-22 07:22:29.865077: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14248 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use standard file APIs to check for files with this prefix.\n","INFO:tensorflow:Restoring parameters from /content/trained_output/model.ckpt-1437\n","INFO:tensorflow:Running local_init_op.\n","INFO:tensorflow:Done running local_init_op.\n","INFO:tensorflow:Finished evaluation at 2023-05-22-07:22:31\n","INFO:tensorflow:Saving dict for global step 1437: eval_accuracy = 0.45266667, eval_loss = 1.2799171, global_step = 1437, loss = 1.2798506\n","INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1437: /content/trained_output/model.ckpt-1437\n","INFO:tensorflow:evaluation_loop marked as finished\n","INFO:tensorflow:***** Eval results *****\n","INFO:tensorflow:  eval_accuracy = 0.45266667\n","INFO:tensorflow:  eval_loss = 1.2799171\n","INFO:tensorflow:  global_step = 1437\n","INFO:tensorflow:  loss = 1.2798506\n"]}],"source":["%cd /content/drive/MyDrive/Code_pretrain\n","%pwd\n","%env BERT_BASE_DIR=uncased_L-4_H-256_A-4\n","%env GLUE_DIR=data\n","!rm -rf /content/trained_output\n","\n","!python3 run_classifier.py \\\n","  --task_name=STS-B \\\n","  --do_train=true \\\n","  --do_eval=true \\\n","  --data_dir=$GLUE_DIR/STS-B \\\n","  --vocab_file=$BERT_BASE_DIR/vocab.txt \\\n","  --bert_config_file=$BERT_BASE_DIR/bert_config.json \\\n","  --init_checkpoint=$BERT_BASE_DIR/bert_model.ckpt \\\n","  --max_seq_length=128 \\\n","  --train_batch_size=4 \\\n","  --learning_rate=2e-5 \\\n","  --num_train_epochs=1.0 \\\n","  --output_dir=/content/trained_output\n","\n","# result metric.\n","# INFO:tensorflow:  eval_accuracy = 0.42733333\n","# INFO:tensorflow:  eval_loss = 1.4847277\n","# INFO:tensorflow:  global_step = 1437\n","# INFO:tensorflow:  loss = 1.485607\n","\n","# INFO:tensorflow:  eval_accuracy = 0.45266667\n","# INFO:tensorflow:  eval_loss = 1.2799171\n","# INFO:tensorflow:  global_step = 1437\n","# INFO:tensorflow:  loss = 1.2798506"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iq4MP-LV_D72","outputId":"a3e157ab-73ee-469b-ba80-42f69ac1c067"},"outputs":[{"output_type":"stream","name":"stderr","text":["ERROR:root:Internal Python error in the inspect module.\n","Below is the traceback from this internal error.\n","\n","ERROR:root:Internal Python error in the inspect module.\n","Below is the traceback from this internal error.\n","\n","ERROR:root:Internal Python error in the inspect module.\n","Below is the traceback from this internal error.\n","\n"]},{"output_type":"stream","name":"stdout","text":["Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n","    exec(code_obj, self.user_global_ns, self.user_ns)\n","  File \"<ipython-input-6-23640fa6337e>\", line 1, in <cell line: 1>\n","    get_ipython().run_line_magic('cd', '/content/drive/MyDrive/Code_pretrain')\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2418, in run_line_magic\n","    result = fn(*args, **kwargs)\n","  File \"<decorator-gen-85>\", line 2, in cd\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/magic.py\", line 187, in <lambda>\n","    call = lambda f, *a, **k: f(*a, **k)\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/magics/osm.py\", line 342, in cd\n","    oldcwd = os.getcwd()\n","OSError: [Errno 107] Transport endpoint is not connected\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n","    stb = value._render_traceback_()\n","AttributeError: 'OSError' object has no attribute '_render_traceback_'\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1101, in get_records\n","    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 248, in wrapped\n","    return f(*args, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n","    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n","  File \"/usr/lib/python3.10/inspect.py\", line 1662, in getinnerframes\n","    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n","  File \"/usr/lib/python3.10/inspect.py\", line 1620, in getframeinfo\n","    filename = getsourcefile(frame) or getfile(frame)\n","  File \"/usr/lib/python3.10/inspect.py\", line 829, in getsourcefile\n","    module = getmodule(object, filename)\n","  File \"/usr/lib/python3.10/inspect.py\", line 861, in getmodule\n","    file = getabsfile(object, _filename)\n","  File \"/usr/lib/python3.10/inspect.py\", line 845, in getabsfile\n","    return os.path.normcase(os.path.abspath(_filename))\n","  File \"/usr/lib/python3.10/posixpath.py\", line 384, in abspath\n","    cwd = os.getcwd()\n","OSError: [Errno 107] Transport endpoint is not connected\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n","    exec(code_obj, self.user_global_ns, self.user_ns)\n","  File \"<ipython-input-6-23640fa6337e>\", line 1, in <cell line: 1>\n","    get_ipython().run_line_magic('cd', '/content/drive/MyDrive/Code_pretrain')\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2418, in run_line_magic\n","    result = fn(*args, **kwargs)\n","  File \"<decorator-gen-85>\", line 2, in cd\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/magic.py\", line 187, in <lambda>\n","    call = lambda f, *a, **k: f(*a, **k)\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/magics/osm.py\", line 342, in cd\n","    oldcwd = os.getcwd()\n","OSError: [Errno 107] Transport endpoint is not connected\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n","    stb = value._render_traceback_()\n","AttributeError: 'OSError' object has no attribute '_render_traceback_'\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n","    if (await self.run_code(code, result,  async_=asy)):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3575, in run_code\n","    self.showtraceback(running_compiled_code=True)\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2101, in showtraceback\n","    stb = self.InteractiveTB.structured_traceback(etype,\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1367, in structured_traceback\n","    return FormattedTB.structured_traceback(\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1267, in structured_traceback\n","    return VerboseTB.structured_traceback(\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1124, in structured_traceback\n","    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1082, in format_exception_as_a_whole\n","    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 382, in find_recursion\n","    return len(records), 0\n","TypeError: object of type 'NoneType' has no len()\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n","    stb = value._render_traceback_()\n","AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1101, in get_records\n","    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 248, in wrapped\n","    return f(*args, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n","    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n","  File \"/usr/lib/python3.10/inspect.py\", line 1662, in getinnerframes\n","    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n","  File \"/usr/lib/python3.10/inspect.py\", line 1620, in getframeinfo\n","    filename = getsourcefile(frame) or getfile(frame)\n","  File \"/usr/lib/python3.10/inspect.py\", line 829, in getsourcefile\n","    module = getmodule(object, filename)\n","  File \"/usr/lib/python3.10/inspect.py\", line 861, in getmodule\n","    file = getabsfile(object, _filename)\n","  File \"/usr/lib/python3.10/inspect.py\", line 845, in getabsfile\n","    return os.path.normcase(os.path.abspath(_filename))\n","  File \"/usr/lib/python3.10/posixpath.py\", line 384, in abspath\n","    cwd = os.getcwd()\n","OSError: [Errno 107] Transport endpoint is not connected\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n","    exec(code_obj, self.user_global_ns, self.user_ns)\n","  File \"<ipython-input-6-23640fa6337e>\", line 1, in <cell line: 1>\n","    get_ipython().run_line_magic('cd', '/content/drive/MyDrive/Code_pretrain')\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2418, in run_line_magic\n","    result = fn(*args, **kwargs)\n","  File \"<decorator-gen-85>\", line 2, in cd\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/magic.py\", line 187, in <lambda>\n","    call = lambda f, *a, **k: f(*a, **k)\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/magics/osm.py\", line 342, in cd\n","    oldcwd = os.getcwd()\n","OSError: [Errno 107] Transport endpoint is not connected\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n","    stb = value._render_traceback_()\n","AttributeError: 'OSError' object has no attribute '_render_traceback_'\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n","    if (await self.run_code(code, result,  async_=asy)):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3575, in run_code\n","    self.showtraceback(running_compiled_code=True)\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2101, in showtraceback\n","    stb = self.InteractiveTB.structured_traceback(etype,\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1367, in structured_traceback\n","    return FormattedTB.structured_traceback(\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1267, in structured_traceback\n","    return VerboseTB.structured_traceback(\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1124, in structured_traceback\n","    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1082, in format_exception_as_a_whole\n","    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 382, in find_recursion\n","    return len(records), 0\n","TypeError: object of type 'NoneType' has no len()\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n","    stb = value._render_traceback_()\n","AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n","    return runner(coro)\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n","    coro.send(None)\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\n","    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3492, in run_ast_nodes\n","    self.showtraceback()\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2101, in showtraceback\n","    stb = self.InteractiveTB.structured_traceback(etype,\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1367, in structured_traceback\n","    return FormattedTB.structured_traceback(\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1267, in structured_traceback\n","    return VerboseTB.structured_traceback(\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1142, in structured_traceback\n","    formatted_exceptions += self.format_exception_as_a_whole(etype, evalue, etb, lines_of_context,\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1082, in format_exception_as_a_whole\n","    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 382, in find_recursion\n","    return len(records), 0\n","TypeError: object of type 'NoneType' has no len()\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n","    stb = value._render_traceback_()\n","AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1101, in get_records\n","    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 248, in wrapped\n","    return f(*args, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n","    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n","  File \"/usr/lib/python3.10/inspect.py\", line 1662, in getinnerframes\n","    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n","  File \"/usr/lib/python3.10/inspect.py\", line 1620, in getframeinfo\n","    filename = getsourcefile(frame) or getfile(frame)\n","  File \"/usr/lib/python3.10/inspect.py\", line 829, in getsourcefile\n","    module = getmodule(object, filename)\n","  File \"/usr/lib/python3.10/inspect.py\", line 861, in getmodule\n","    file = getabsfile(object, _filename)\n","  File \"/usr/lib/python3.10/inspect.py\", line 845, in getabsfile\n","    return os.path.normcase(os.path.abspath(_filename))\n","  File \"/usr/lib/python3.10/posixpath.py\", line 384, in abspath\n","    cwd = os.getcwd()\n","OSError: [Errno 107] Transport endpoint is not connected\n"]}],"source":["%cd /content/drive/MyDrive/Code_pretrain\n","%pwd\n","%env BERT_BASE_DIR=uncased_L-4_H-256_A-4\n","%env GLUE_DIR=data\n","!rm -rf /content/trained_output\n","\n","!python3 run_classifier.py \\\n","  --task_name=QQP \\\n","  --do_train=true \\\n","  --do_eval=true \\\n","  --data_dir=$GLUE_DIR/QQP \\\n","  --vocab_file=$BERT_BASE_DIR/vocab.txt \\\n","  --bert_config_file=$BERT_BASE_DIR/bert_config.json \\\n","  --init_checkpoint=$BERT_BASE_DIR/bert_model.ckpt \\\n","  --max_seq_length=128 \\\n","  --train_batch_size=4 \\\n","  --learning_rate=2e-5 \\\n","  --num_train_epochs=1.0 \\\n","  --output_dir=/content/trained_output\n","\n","# result metric.\n","# INFO:tensorflow:  eval_accuracy = 0.79809546\n","# INFO:tensorflow:  eval_loss = 0.48185706\n","# INFO:tensorflow:  global_step = 90961\n","# INFO:tensorflow:  loss = 0.48184583\n","\n","# INFO:tensorflow:  eval_accuracy = 0.76094484\n","# INFO:tensorflow:  eval_loss = 0.5269344\n","# INFO:tensorflow:  global_step = 90961\n","# INFO:tensorflow:  loss = 0.52696335"]},{"cell_type":"code","execution_count":19,"metadata":{"id":"NeWrQI6p_Mfl","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1684740811987,"user_tz":-480,"elapsed":658554,"user":{"displayName":"Brian Shen","userId":"08246478872294528508"}},"outputId":"297d2a5e-8a5a-4c26-f852-54f2defdc88c"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Code_pretrain\n","env: BERT_BASE_DIR=uncased_L-4_H-256_A-4\n","env: GLUE_DIR=data\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n","\n","WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n","For more information, please see:\n","  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n","  * https://github.com/tensorflow/addons\n","If you depend on functionality not listed there, please file an issue.\n","\n","WARNING:tensorflow:Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7fc795194730>) includes params argument, but params are not passed to Estimator.\n","INFO:tensorflow:Using config: {'_model_dir': '/content/trained_output', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 1000, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n","graph_options {\n","  rewrite_options {\n","    meta_optimizer_iterations: ONE\n","  }\n","}\n",", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fc798c76c50>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=1000, num_shards=8, num_cores_per_replica=None, per_host_input_for_training=3, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None), '_cluster': None}\n","INFO:tensorflow:_TPUContext: eval_on_tpu True\n","WARNING:tensorflow:eval_on_tpu ignored because use_tpu is False.\n","INFO:tensorflow:Writing example 0 of 104743\n","INFO:tensorflow:*** Example ***\n","INFO:tensorflow:guid: train-0\n","INFO:tensorflow:tokens: [CLS] when did the third dig ##imo ##n series begin ? [SEP] unlike the two seasons before it and most of the seasons that followed , dig ##imo ##n tame ##rs takes a darker and more realistic approach to its story featuring dig ##imo ##n who do not rein ##car ##nate after their deaths and more complex character development in the original japanese . [SEP]\n","INFO:tensorflow:input_ids: 101 2043 2106 1996 2353 10667 16339 2078 2186 4088 1029 102 4406 1996 2048 3692 2077 2009 1998 2087 1997 1996 3692 2008 2628 1010 10667 16339 2078 24763 2869 3138 1037 9904 1998 2062 12689 3921 2000 2049 2466 3794 10667 16339 2078 2040 2079 2025 27788 10010 12556 2044 2037 6677 1998 2062 3375 2839 2458 1999 1996 2434 2887 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:label: not_entailment (id = 1)\n","INFO:tensorflow:*** Example ***\n","INFO:tensorflow:guid: train-1\n","INFO:tensorflow:tokens: [CLS] which missile batteries often have individual launcher ##s several kilometres from one another ? [SEP] when man ##pad ##s is operated by specialists , batteries may have several dozen teams deploy ##ing separately in small sections ; self - propelled air defence guns may deploy in pairs . [SEP]\n","INFO:tensorflow:input_ids: 101 2029 7421 10274 2411 2031 3265 22742 2015 2195 3717 2013 2028 2178 1029 102 2043 2158 15455 2015 2003 3498 2011 15744 1010 10274 2089 2031 2195 6474 2780 21296 2075 10329 1999 2235 5433 1025 2969 1011 15801 2250 4721 4409 2089 21296 1999 7689 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:label: not_entailment (id = 1)\n","INFO:tensorflow:*** Example ***\n","INFO:tensorflow:guid: train-2\n","INFO:tensorflow:tokens: [CLS] what two things does pop ##per argue tar ##ski ' s theory involves in an evaluation of truth ? [SEP] he bases this interpretation on the fact that examples such as the one described above refer to two things : assertion ##s and the facts to which they refer . [SEP]\n","INFO:tensorflow:input_ids: 101 2054 2048 2477 2515 3769 4842 7475 16985 5488 1005 1055 3399 7336 1999 2019 9312 1997 3606 1029 102 2002 7888 2023 7613 2006 1996 2755 2008 4973 2107 2004 1996 2028 2649 2682 6523 2000 2048 2477 1024 23617 2015 1998 1996 8866 2000 2029 2027 6523 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:label: entailment (id = 0)\n","INFO:tensorflow:*** Example ***\n","INFO:tensorflow:guid: train-3\n","INFO:tensorflow:tokens: [CLS] what is the name of the village 9 miles north of cal ##af ##at where the ottoman forces attacked the russians ? [SEP] on 31 december 1853 , the ottoman forces at cal ##af ##at moved against the russian force at chet ##ate ##a or ce ##tate , a small village nine miles north of cal ##af ##at , and engaged them on 6 january 1854 . [SEP]\n","INFO:tensorflow:input_ids: 101 2054 2003 1996 2171 1997 1996 2352 1023 2661 2167 1997 10250 10354 4017 2073 1996 6188 2749 4457 1996 12513 1029 102 2006 2861 2285 8933 1010 1996 6188 2749 2012 10250 10354 4017 2333 2114 1996 2845 2486 2012 25157 3686 2050 2030 8292 12259 1010 1037 2235 2352 3157 2661 2167 1997 10250 10354 4017 1010 1998 5117 2068 2006 1020 2254 8421 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:label: entailment (id = 0)\n","INFO:tensorflow:*** Example ***\n","INFO:tensorflow:guid: train-4\n","INFO:tensorflow:tokens: [CLS] what famous palace is located in london ? [SEP] london contains four world heritage sites : the tower of london ; ke ##w gardens ; the site comprising the palace of westminster , westminster abbey , and st margaret ' s church ; and the historic settlement of greenwich ( in which the royal observatory , greenwich marks the prime meridian , 0 ##° longitude , and gm ##t ) . [SEP]\n","INFO:tensorflow:input_ids: 101 2054 3297 4186 2003 2284 1999 2414 1029 102 2414 3397 2176 2088 4348 4573 1024 1996 3578 1997 2414 1025 17710 2860 5822 1025 1996 2609 9605 1996 4186 1997 9434 1010 9434 6103 1010 1998 2358 5545 1005 1055 2277 1025 1998 1996 3181 4093 1997 13861 1006 1999 2029 1996 2548 9970 1010 13861 6017 1996 3539 17984 1010 1014 7737 20413 1010 1998 13938 2102 1007 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:label: not_entailment (id = 1)\n","INFO:tensorflow:Writing example 10000 of 104743\n","INFO:tensorflow:Writing example 20000 of 104743\n","INFO:tensorflow:Writing example 30000 of 104743\n","INFO:tensorflow:Writing example 40000 of 104743\n","INFO:tensorflow:Writing example 50000 of 104743\n","INFO:tensorflow:Writing example 60000 of 104743\n","INFO:tensorflow:Writing example 70000 of 104743\n","INFO:tensorflow:Writing example 80000 of 104743\n","INFO:tensorflow:Writing example 90000 of 104743\n","INFO:tensorflow:Writing example 100000 of 104743\n","INFO:tensorflow:***** Running training *****\n","INFO:tensorflow:  Num examples = 104743\n","INFO:tensorflow:  Batch size = 4\n","INFO:tensorflow:  Num steps = 26185\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Colocations handled automatically by placer.\n","WARNING:tensorflow:From run_classifier.py:890: map_and_batch (from tensorflow.contrib.data.python.ops.batching) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.experimental.map_and_batch(...)`.\n","WARNING:tensorflow:From run_classifier.py:870: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.cast instead.\n","INFO:tensorflow:Calling model_fn.\n","INFO:tensorflow:Running train on CPU\n","INFO:tensorflow:*** Features ***\n","INFO:tensorflow:  name = input_ids, shape = (4, 128)\n","INFO:tensorflow:  name = input_mask, shape = (4, 128)\n","INFO:tensorflow:  name = is_real_example, shape = (4,)\n","INFO:tensorflow:  name = label_ids, shape = (4,)\n","INFO:tensorflow:  name = segment_ids, shape = (4, 128)\n","WARNING:tensorflow:From /content/drive/MyDrive/Code_pretrain/modeling.py:358: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n","WARNING:tensorflow:From /content/drive/MyDrive/Code_pretrain/modeling.py:671: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use keras.layers.dense instead.\n","INFO:tensorflow:**** Trainable Variables ****\n","INFO:tensorflow:  name = bert/embeddings/word_embeddings:0, shape = (30522, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/embeddings/token_type_embeddings:0, shape = (2, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/embeddings/position_embeddings:0, shape = (512, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/embeddings/LayerNorm/beta:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/embeddings/LayerNorm/gamma:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/query/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/query/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/key/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/key/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/value/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/value/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/dense/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/dense/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/LayerNorm/beta:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/LayerNorm/gamma:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/intermediate/dense/kernel:0, shape = (256, 1024), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/intermediate/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/output/dense/kernel:0, shape = (1024, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/output/dense/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/output/LayerNorm/beta:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/output/LayerNorm/gamma:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/query/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/query/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/key/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/key/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/value/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/value/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/dense/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/dense/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/LayerNorm/beta:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/LayerNorm/gamma:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/intermediate/dense/kernel:0, shape = (256, 1024), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/intermediate/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/output/dense/kernel:0, shape = (1024, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/output/dense/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/output/LayerNorm/beta:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/output/LayerNorm/gamma:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/query/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/query/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/key/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/key/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/value/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/value/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/dense/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/dense/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/LayerNorm/beta:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/LayerNorm/gamma:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/intermediate/dense/kernel:0, shape = (256, 1024), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/intermediate/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/output/dense/kernel:0, shape = (1024, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/output/dense/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/output/LayerNorm/beta:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/output/LayerNorm/gamma:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/query/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/query/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/key/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/key/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/value/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/value/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/dense/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/dense/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/LayerNorm/beta:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/LayerNorm/gamma:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/intermediate/dense/kernel:0, shape = (256, 1024), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/intermediate/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/output/dense/kernel:0, shape = (1024, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/output/dense/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/output/LayerNorm/beta:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/output/LayerNorm/gamma:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/pooler/dense/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/pooler/dense/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = output_weights:0, shape = (2, 256)\n","INFO:tensorflow:  name = output_bias:0, shape = (2,)\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/learning_rate_decay_v2.py:321: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Deprecated in favor of operator or tf.math.divide.\n","INFO:tensorflow:Done calling model_fn.\n","INFO:tensorflow:Create CheckpointSaverHook.\n","INFO:tensorflow:Graph was finalized.\n","2023-05-22 07:24:16.516147: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA\n","2023-05-22 07:24:16.621682: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2023-05-22 07:24:16.622009: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x24130e0 executing computations on platform CUDA. Devices:\n","2023-05-22 07:24:16.622041: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n","2023-05-22 07:24:16.624062: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2000185000 Hz\n","2023-05-22 07:24:16.624230: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x23354e0 executing computations on platform Host. Devices:\n","2023-05-22 07:24:16.624260: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>\n","2023-05-22 07:24:16.624390: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 0 with properties: \n","name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n","pciBusID: 0000:00:04.0\n","totalMemory: 14.75GiB freeMemory: 14.65GiB\n","2023-05-22 07:24:16.624414: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0\n","2023-05-22 07:24:16.624725: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2023-05-22 07:24:16.624746: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0 \n","2023-05-22 07:24:16.624755: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N \n","2023-05-22 07:24:16.624808: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","2023-05-22 07:24:16.624847: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14248 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n","INFO:tensorflow:Running local_init_op.\n","INFO:tensorflow:Done running local_init_op.\n","INFO:tensorflow:Saving checkpoints for 0 into /content/trained_output/model.ckpt.\n","2023-05-22 07:24:24.310932: I tensorflow/stream_executor/dso_loader.cc:152] successfully opened CUDA library libcublas.so.10.0 locally\n","INFO:tensorflow:global_step/sec: 27.8569\n","INFO:tensorflow:examples/sec: 111.428\n","INFO:tensorflow:global_step/sec: 53.0249\n","INFO:tensorflow:examples/sec: 212.1\n","INFO:tensorflow:global_step/sec: 53.0933\n","INFO:tensorflow:examples/sec: 212.373\n","INFO:tensorflow:global_step/sec: 53.0395\n","INFO:tensorflow:examples/sec: 212.158\n","INFO:tensorflow:global_step/sec: 53.0897\n","INFO:tensorflow:examples/sec: 212.359\n","INFO:tensorflow:global_step/sec: 51.1243\n","INFO:tensorflow:examples/sec: 204.497\n","INFO:tensorflow:global_step/sec: 49.3095\n","INFO:tensorflow:examples/sec: 197.238\n","INFO:tensorflow:global_step/sec: 48.7641\n","INFO:tensorflow:examples/sec: 195.056\n","INFO:tensorflow:global_step/sec: 49.3204\n","INFO:tensorflow:examples/sec: 197.282\n","INFO:tensorflow:Saving checkpoints for 1000 into /content/trained_output/model.ckpt.\n","INFO:tensorflow:global_step/sec: 41.5639\n","INFO:tensorflow:examples/sec: 166.256\n","INFO:tensorflow:global_step/sec: 52.2478\n","INFO:tensorflow:examples/sec: 208.991\n","INFO:tensorflow:global_step/sec: 52.295\n","INFO:tensorflow:examples/sec: 209.18\n","INFO:tensorflow:global_step/sec: 51.9551\n","INFO:tensorflow:examples/sec: 207.82\n","INFO:tensorflow:global_step/sec: 52.1573\n","INFO:tensorflow:examples/sec: 208.629\n","INFO:tensorflow:global_step/sec: 49.4626\n","INFO:tensorflow:examples/sec: 197.85\n","INFO:tensorflow:global_step/sec: 48.8992\n","INFO:tensorflow:examples/sec: 195.597\n","INFO:tensorflow:global_step/sec: 49.405\n","INFO:tensorflow:examples/sec: 197.62\n","INFO:tensorflow:global_step/sec: 49.083\n","INFO:tensorflow:examples/sec: 196.332\n","INFO:tensorflow:global_step/sec: 51.9228\n","INFO:tensorflow:examples/sec: 207.691\n","INFO:tensorflow:Saving checkpoints for 2000 into /content/trained_output/model.ckpt.\n","INFO:tensorflow:global_step/sec: 41.9946\n","INFO:tensorflow:examples/sec: 167.978\n","INFO:tensorflow:global_step/sec: 52.012\n","INFO:tensorflow:examples/sec: 208.048\n","INFO:tensorflow:global_step/sec: 51.8772\n","INFO:tensorflow:examples/sec: 207.509\n","INFO:tensorflow:global_step/sec: 50.428\n","INFO:tensorflow:examples/sec: 201.712\n","INFO:tensorflow:global_step/sec: 48.8043\n","INFO:tensorflow:examples/sec: 195.217\n","INFO:tensorflow:global_step/sec: 48.6571\n","INFO:tensorflow:examples/sec: 194.628\n","INFO:tensorflow:global_step/sec: 48.404\n","INFO:tensorflow:examples/sec: 193.616\n","INFO:tensorflow:global_step/sec: 49.6687\n","INFO:tensorflow:examples/sec: 198.675\n","INFO:tensorflow:global_step/sec: 51.7795\n","INFO:tensorflow:examples/sec: 207.118\n","INFO:tensorflow:global_step/sec: 51.8965\n","INFO:tensorflow:examples/sec: 207.586\n","INFO:tensorflow:Saving checkpoints for 3000 into /content/trained_output/model.ckpt.\n","INFO:tensorflow:global_step/sec: 41.2137\n","INFO:tensorflow:examples/sec: 164.855\n","INFO:tensorflow:global_step/sec: 51.8038\n","INFO:tensorflow:examples/sec: 207.215\n","INFO:tensorflow:global_step/sec: 50.7862\n","INFO:tensorflow:examples/sec: 203.145\n","INFO:tensorflow:global_step/sec: 48.4896\n","INFO:tensorflow:examples/sec: 193.958\n","INFO:tensorflow:global_step/sec: 48.7689\n","INFO:tensorflow:examples/sec: 195.076\n","INFO:tensorflow:global_step/sec: 48.9565\n","INFO:tensorflow:examples/sec: 195.826\n","INFO:tensorflow:global_step/sec: 50.9015\n","INFO:tensorflow:examples/sec: 203.606\n","INFO:tensorflow:global_step/sec: 52.226\n","INFO:tensorflow:examples/sec: 208.904\n","INFO:tensorflow:global_step/sec: 52.0131\n","INFO:tensorflow:examples/sec: 208.052\n","INFO:tensorflow:global_step/sec: 52.1408\n","INFO:tensorflow:examples/sec: 208.563\n","INFO:tensorflow:Saving checkpoints for 4000 into /content/trained_output/model.ckpt.\n","INFO:tensorflow:global_step/sec: 41.838\n","INFO:tensorflow:examples/sec: 167.352\n","INFO:tensorflow:global_step/sec: 50.0995\n","INFO:tensorflow:examples/sec: 200.398\n","INFO:tensorflow:global_step/sec: 48.5541\n","INFO:tensorflow:examples/sec: 194.216\n","INFO:tensorflow:global_step/sec: 48.9336\n","INFO:tensorflow:examples/sec: 195.734\n","INFO:tensorflow:global_step/sec: 49.2244\n","INFO:tensorflow:examples/sec: 196.898\n","INFO:tensorflow:global_step/sec: 52.162\n","INFO:tensorflow:examples/sec: 208.648\n","INFO:tensorflow:global_step/sec: 52.1963\n","INFO:tensorflow:examples/sec: 208.785\n","INFO:tensorflow:global_step/sec: 52.3954\n","INFO:tensorflow:examples/sec: 209.582\n","INFO:tensorflow:global_step/sec: 52.2917\n","INFO:tensorflow:examples/sec: 209.167\n","INFO:tensorflow:global_step/sec: 52.4226\n","INFO:tensorflow:examples/sec: 209.691\n","INFO:tensorflow:Saving checkpoints for 5000 into /content/trained_output/model.ckpt.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:966: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use standard file APIs to delete files with this prefix.\n","INFO:tensorflow:global_step/sec: 36.0239\n","INFO:tensorflow:examples/sec: 144.095\n","INFO:tensorflow:global_step/sec: 48.4529\n","INFO:tensorflow:examples/sec: 193.812\n","INFO:tensorflow:global_step/sec: 48.4927\n","INFO:tensorflow:examples/sec: 193.971\n","INFO:tensorflow:global_step/sec: 49.3079\n","INFO:tensorflow:examples/sec: 197.232\n","INFO:tensorflow:global_step/sec: 52.1684\n","INFO:tensorflow:examples/sec: 208.674\n","INFO:tensorflow:global_step/sec: 52.3167\n","INFO:tensorflow:examples/sec: 209.267\n","INFO:tensorflow:global_step/sec: 52.0138\n","INFO:tensorflow:examples/sec: 208.055\n","INFO:tensorflow:global_step/sec: 52.1192\n","INFO:tensorflow:examples/sec: 208.477\n","INFO:tensorflow:global_step/sec: 51.8441\n","INFO:tensorflow:examples/sec: 207.377\n","INFO:tensorflow:global_step/sec: 49.389\n","INFO:tensorflow:examples/sec: 197.556\n","INFO:tensorflow:Saving checkpoints for 6000 into /content/trained_output/model.ckpt.\n","INFO:tensorflow:global_step/sec: 35.9646\n","INFO:tensorflow:examples/sec: 143.858\n","INFO:tensorflow:global_step/sec: 48.5965\n","INFO:tensorflow:examples/sec: 194.386\n","INFO:tensorflow:global_step/sec: 51.05\n","INFO:tensorflow:examples/sec: 204.2\n","INFO:tensorflow:global_step/sec: 51.3505\n","INFO:tensorflow:examples/sec: 205.402\n","INFO:tensorflow:global_step/sec: 51.9654\n","INFO:tensorflow:examples/sec: 207.862\n","INFO:tensorflow:global_step/sec: 52.1445\n","INFO:tensorflow:examples/sec: 208.578\n","INFO:tensorflow:global_step/sec: 52.2125\n","INFO:tensorflow:examples/sec: 208.85\n","INFO:tensorflow:global_step/sec: 50.003\n","INFO:tensorflow:examples/sec: 200.012\n","INFO:tensorflow:global_step/sec: 48.6353\n","INFO:tensorflow:examples/sec: 194.541\n","INFO:tensorflow:global_step/sec: 48.2056\n","INFO:tensorflow:examples/sec: 192.823\n","INFO:tensorflow:Saving checkpoints for 7000 into /content/trained_output/model.ckpt.\n","INFO:tensorflow:global_step/sec: 36.5199\n","INFO:tensorflow:examples/sec: 146.08\n","INFO:tensorflow:global_step/sec: 52.0225\n","INFO:tensorflow:examples/sec: 208.09\n","INFO:tensorflow:global_step/sec: 52.0761\n","INFO:tensorflow:examples/sec: 208.304\n","INFO:tensorflow:global_step/sec: 52.1888\n","INFO:tensorflow:examples/sec: 208.755\n","INFO:tensorflow:global_step/sec: 52.1494\n","INFO:tensorflow:examples/sec: 208.598\n","INFO:tensorflow:global_step/sec: 52.3242\n","INFO:tensorflow:examples/sec: 209.297\n","INFO:tensorflow:global_step/sec: 49.6562\n","INFO:tensorflow:examples/sec: 198.625\n","INFO:tensorflow:global_step/sec: 49.5128\n","INFO:tensorflow:examples/sec: 198.051\n","INFO:tensorflow:global_step/sec: 48.3027\n","INFO:tensorflow:examples/sec: 193.211\n","INFO:tensorflow:global_step/sec: 48.7523\n","INFO:tensorflow:examples/sec: 195.009\n","INFO:tensorflow:Saving checkpoints for 8000 into /content/trained_output/model.ckpt.\n","INFO:tensorflow:global_step/sec: 41.252\n","INFO:tensorflow:examples/sec: 165.008\n","INFO:tensorflow:global_step/sec: 52.4442\n","INFO:tensorflow:examples/sec: 209.777\n","INFO:tensorflow:global_step/sec: 52.1999\n","INFO:tensorflow:examples/sec: 208.8\n","INFO:tensorflow:global_step/sec: 52.1141\n","INFO:tensorflow:examples/sec: 208.456\n","INFO:tensorflow:global_step/sec: 51.9954\n","INFO:tensorflow:examples/sec: 207.982\n","INFO:tensorflow:global_step/sec: 48.8165\n","INFO:tensorflow:examples/sec: 195.266\n","INFO:tensorflow:global_step/sec: 48.4937\n","INFO:tensorflow:examples/sec: 193.975\n","INFO:tensorflow:global_step/sec: 48.9097\n","INFO:tensorflow:examples/sec: 195.639\n","INFO:tensorflow:global_step/sec: 49.8587\n","INFO:tensorflow:examples/sec: 199.435\n","INFO:tensorflow:global_step/sec: 52.1661\n","INFO:tensorflow:examples/sec: 208.664\n","INFO:tensorflow:Saving checkpoints for 9000 into /content/trained_output/model.ckpt.\n","INFO:tensorflow:global_step/sec: 41.6494\n","INFO:tensorflow:examples/sec: 166.598\n","INFO:tensorflow:global_step/sec: 52.277\n","INFO:tensorflow:examples/sec: 209.108\n","INFO:tensorflow:global_step/sec: 52.2278\n","INFO:tensorflow:examples/sec: 208.911\n","INFO:tensorflow:global_step/sec: 50.8058\n","INFO:tensorflow:examples/sec: 203.223\n","INFO:tensorflow:global_step/sec: 47.9629\n","INFO:tensorflow:examples/sec: 191.852\n","INFO:tensorflow:global_step/sec: 48.7935\n","INFO:tensorflow:examples/sec: 195.174\n","INFO:tensorflow:global_step/sec: 48.8246\n","INFO:tensorflow:examples/sec: 195.298\n","INFO:tensorflow:global_step/sec: 50.8399\n","INFO:tensorflow:examples/sec: 203.36\n","INFO:tensorflow:global_step/sec: 51.976\n","INFO:tensorflow:examples/sec: 207.904\n","INFO:tensorflow:global_step/sec: 52.1674\n","INFO:tensorflow:examples/sec: 208.669\n","INFO:tensorflow:Saving checkpoints for 10000 into /content/trained_output/model.ckpt.\n","INFO:tensorflow:global_step/sec: 41.5916\n","INFO:tensorflow:examples/sec: 166.366\n","INFO:tensorflow:global_step/sec: 52.2394\n","INFO:tensorflow:examples/sec: 208.957\n","INFO:tensorflow:global_step/sec: 49.6678\n","INFO:tensorflow:examples/sec: 198.671\n","INFO:tensorflow:global_step/sec: 48.4454\n","INFO:tensorflow:examples/sec: 193.782\n","INFO:tensorflow:global_step/sec: 48.8803\n","INFO:tensorflow:examples/sec: 195.521\n","INFO:tensorflow:global_step/sec: 48.657\n","INFO:tensorflow:examples/sec: 194.628\n","INFO:tensorflow:global_step/sec: 51.7327\n","INFO:tensorflow:examples/sec: 206.931\n","INFO:tensorflow:global_step/sec: 52.1254\n","INFO:tensorflow:examples/sec: 208.501\n","INFO:tensorflow:global_step/sec: 52.2961\n","INFO:tensorflow:examples/sec: 209.184\n","INFO:tensorflow:global_step/sec: 52.3423\n","INFO:tensorflow:examples/sec: 209.369\n","INFO:tensorflow:Saving checkpoints for 11000 into /content/trained_output/model.ckpt.\n","INFO:tensorflow:global_step/sec: 41.4897\n","INFO:tensorflow:examples/sec: 165.959\n","INFO:tensorflow:global_step/sec: 48.9401\n","INFO:tensorflow:examples/sec: 195.76\n","INFO:tensorflow:global_step/sec: 47.7914\n","INFO:tensorflow:examples/sec: 191.166\n","INFO:tensorflow:global_step/sec: 47.7224\n","INFO:tensorflow:examples/sec: 190.89\n","INFO:tensorflow:global_step/sec: 49.6654\n","INFO:tensorflow:examples/sec: 198.662\n","INFO:tensorflow:global_step/sec: 52.0664\n","INFO:tensorflow:examples/sec: 208.266\n","INFO:tensorflow:global_step/sec: 52.2184\n","INFO:tensorflow:examples/sec: 208.874\n","INFO:tensorflow:global_step/sec: 52.1858\n","INFO:tensorflow:examples/sec: 208.743\n","INFO:tensorflow:global_step/sec: 52.1018\n","INFO:tensorflow:examples/sec: 208.407\n","INFO:tensorflow:global_step/sec: 51.9141\n","INFO:tensorflow:examples/sec: 207.656\n","INFO:tensorflow:Saving checkpoints for 12000 into /content/trained_output/model.ckpt.\n","INFO:tensorflow:global_step/sec: 35.5463\n","INFO:tensorflow:examples/sec: 142.185\n","INFO:tensorflow:global_step/sec: 48.8701\n","INFO:tensorflow:examples/sec: 195.48\n","INFO:tensorflow:global_step/sec: 48.6272\n","INFO:tensorflow:examples/sec: 194.509\n","INFO:tensorflow:global_step/sec: 50.3668\n","INFO:tensorflow:examples/sec: 201.467\n","INFO:tensorflow:global_step/sec: 52.2105\n","INFO:tensorflow:examples/sec: 208.842\n","INFO:tensorflow:global_step/sec: 52.344\n","INFO:tensorflow:examples/sec: 209.376\n","INFO:tensorflow:global_step/sec: 52.3738\n","INFO:tensorflow:examples/sec: 209.495\n","INFO:tensorflow:global_step/sec: 52.4503\n","INFO:tensorflow:examples/sec: 209.801\n","INFO:tensorflow:global_step/sec: 50.422\n","INFO:tensorflow:examples/sec: 201.688\n","INFO:tensorflow:global_step/sec: 48.9866\n","INFO:tensorflow:examples/sec: 195.947\n","INFO:tensorflow:Saving checkpoints for 13000 into /content/trained_output/model.ckpt.\n","INFO:tensorflow:global_step/sec: 35.8751\n","INFO:tensorflow:examples/sec: 143.5\n","INFO:tensorflow:global_step/sec: 48.6724\n","INFO:tensorflow:examples/sec: 194.69\n","INFO:tensorflow:global_step/sec: 51.7784\n","INFO:tensorflow:examples/sec: 207.114\n","INFO:tensorflow:global_step/sec: 52.2242\n","INFO:tensorflow:examples/sec: 208.897\n","INFO:tensorflow:global_step/sec: 52.2582\n","INFO:tensorflow:examples/sec: 209.033\n","INFO:tensorflow:global_step/sec: 52.1082\n","INFO:tensorflow:examples/sec: 208.433\n","INFO:tensorflow:global_step/sec: 52.2682\n","INFO:tensorflow:examples/sec: 209.073\n","INFO:tensorflow:global_step/sec: 50.0699\n","INFO:tensorflow:examples/sec: 200.28\n","INFO:tensorflow:global_step/sec: 48.4678\n","INFO:tensorflow:examples/sec: 193.871\n","INFO:tensorflow:global_step/sec: 48.3689\n","INFO:tensorflow:examples/sec: 193.476\n","INFO:tensorflow:Saving checkpoints for 14000 into /content/trained_output/model.ckpt.\n","INFO:tensorflow:global_step/sec: 38.9673\n","INFO:tensorflow:examples/sec: 155.869\n","INFO:tensorflow:global_step/sec: 52.2384\n","INFO:tensorflow:examples/sec: 208.954\n","INFO:tensorflow:global_step/sec: 52.1138\n","INFO:tensorflow:examples/sec: 208.455\n","INFO:tensorflow:global_step/sec: 52.0099\n","INFO:tensorflow:examples/sec: 208.04\n","INFO:tensorflow:global_step/sec: 52.1688\n","INFO:tensorflow:examples/sec: 208.675\n","INFO:tensorflow:global_step/sec: 51.9978\n","INFO:tensorflow:examples/sec: 207.991\n","INFO:tensorflow:global_step/sec: 46.8363\n","INFO:tensorflow:examples/sec: 187.345\n","INFO:tensorflow:global_step/sec: 48.4009\n","INFO:tensorflow:examples/sec: 193.604\n","INFO:tensorflow:global_step/sec: 48.4742\n","INFO:tensorflow:examples/sec: 193.897\n","INFO:tensorflow:global_step/sec: 49.5981\n","INFO:tensorflow:examples/sec: 198.392\n","INFO:tensorflow:Saving checkpoints for 15000 into /content/trained_output/model.ckpt.\n","INFO:tensorflow:global_step/sec: 41.8344\n","INFO:tensorflow:examples/sec: 167.338\n","INFO:tensorflow:global_step/sec: 52.0423\n","INFO:tensorflow:examples/sec: 208.169\n","INFO:tensorflow:global_step/sec: 52.1427\n","INFO:tensorflow:examples/sec: 208.571\n","INFO:tensorflow:global_step/sec: 51.9828\n","INFO:tensorflow:examples/sec: 207.931\n","INFO:tensorflow:global_step/sec: 51.3505\n","INFO:tensorflow:examples/sec: 205.402\n","INFO:tensorflow:global_step/sec: 50.1543\n","INFO:tensorflow:examples/sec: 200.617\n","INFO:tensorflow:global_step/sec: 49.3362\n","INFO:tensorflow:examples/sec: 197.345\n","INFO:tensorflow:global_step/sec: 49.1538\n","INFO:tensorflow:examples/sec: 196.615\n","INFO:tensorflow:global_step/sec: 49.7948\n","INFO:tensorflow:examples/sec: 199.179\n","INFO:tensorflow:global_step/sec: 52.2227\n","INFO:tensorflow:examples/sec: 208.891\n","INFO:tensorflow:Saving checkpoints for 16000 into /content/trained_output/model.ckpt.\n","INFO:tensorflow:global_step/sec: 41.2418\n","INFO:tensorflow:examples/sec: 164.967\n","INFO:tensorflow:global_step/sec: 51.8242\n","INFO:tensorflow:examples/sec: 207.297\n","INFO:tensorflow:global_step/sec: 52.0023\n","INFO:tensorflow:examples/sec: 208.009\n","INFO:tensorflow:global_step/sec: 49.9115\n","INFO:tensorflow:examples/sec: 199.646\n","INFO:tensorflow:global_step/sec: 49.4874\n","INFO:tensorflow:examples/sec: 197.95\n","INFO:tensorflow:global_step/sec: 48.9849\n","INFO:tensorflow:examples/sec: 195.94\n","INFO:tensorflow:global_step/sec: 49.3858\n","INFO:tensorflow:examples/sec: 197.543\n","INFO:tensorflow:global_step/sec: 51.3233\n","INFO:tensorflow:examples/sec: 205.293\n","INFO:tensorflow:global_step/sec: 52.2074\n","INFO:tensorflow:examples/sec: 208.83\n","INFO:tensorflow:global_step/sec: 52.4219\n","INFO:tensorflow:examples/sec: 209.688\n","INFO:tensorflow:Saving checkpoints for 17000 into /content/trained_output/model.ckpt.\n","INFO:tensorflow:global_step/sec: 41.446\n","INFO:tensorflow:examples/sec: 165.784\n","INFO:tensorflow:global_step/sec: 52.2349\n","INFO:tensorflow:examples/sec: 208.94\n","INFO:tensorflow:global_step/sec: 49.7485\n","INFO:tensorflow:examples/sec: 198.994\n","INFO:tensorflow:global_step/sec: 48.3059\n","INFO:tensorflow:examples/sec: 193.224\n","INFO:tensorflow:global_step/sec: 49.0201\n","INFO:tensorflow:examples/sec: 196.08\n","INFO:tensorflow:global_step/sec: 49.2788\n","INFO:tensorflow:examples/sec: 197.115\n","INFO:tensorflow:global_step/sec: 52.1031\n","INFO:tensorflow:examples/sec: 208.413\n","INFO:tensorflow:global_step/sec: 52.2591\n","INFO:tensorflow:examples/sec: 209.036\n","INFO:tensorflow:global_step/sec: 52.2936\n","INFO:tensorflow:examples/sec: 209.174\n","INFO:tensorflow:global_step/sec: 52.355\n","INFO:tensorflow:examples/sec: 209.42\n","INFO:tensorflow:Saving checkpoints for 18000 into /content/trained_output/model.ckpt.\n","INFO:tensorflow:global_step/sec: 39.1997\n","INFO:tensorflow:examples/sec: 156.799\n","INFO:tensorflow:global_step/sec: 48.932\n","INFO:tensorflow:examples/sec: 195.728\n","INFO:tensorflow:global_step/sec: 48.7483\n","INFO:tensorflow:examples/sec: 194.993\n","INFO:tensorflow:global_step/sec: 49.1002\n","INFO:tensorflow:examples/sec: 196.401\n","INFO:tensorflow:global_step/sec: 50.8161\n","INFO:tensorflow:examples/sec: 203.264\n","INFO:tensorflow:global_step/sec: 52.3793\n","INFO:tensorflow:examples/sec: 209.517\n","INFO:tensorflow:global_step/sec: 52.2332\n","INFO:tensorflow:examples/sec: 208.933\n","INFO:tensorflow:global_step/sec: 52.1331\n","INFO:tensorflow:examples/sec: 208.532\n","INFO:tensorflow:global_step/sec: 52.0012\n","INFO:tensorflow:examples/sec: 208.005\n","INFO:tensorflow:global_step/sec: 51.4333\n","INFO:tensorflow:examples/sec: 205.733\n","INFO:tensorflow:Saving checkpoints for 19000 into /content/trained_output/model.ckpt.\n","INFO:tensorflow:global_step/sec: 36.0782\n","INFO:tensorflow:examples/sec: 144.313\n","INFO:tensorflow:global_step/sec: 48.72\n","INFO:tensorflow:examples/sec: 194.88\n","INFO:tensorflow:global_step/sec: 49.3121\n","INFO:tensorflow:examples/sec: 197.249\n","INFO:tensorflow:global_step/sec: 51.5351\n","INFO:tensorflow:examples/sec: 206.141\n","INFO:tensorflow:global_step/sec: 52.1567\n","INFO:tensorflow:examples/sec: 208.627\n","INFO:tensorflow:global_step/sec: 52.2018\n","INFO:tensorflow:examples/sec: 208.807\n","INFO:tensorflow:global_step/sec: 52.2732\n","INFO:tensorflow:examples/sec: 209.093\n","INFO:tensorflow:global_step/sec: 52.0766\n","INFO:tensorflow:examples/sec: 208.306\n","INFO:tensorflow:global_step/sec: 50.2575\n","INFO:tensorflow:examples/sec: 201.03\n","INFO:tensorflow:global_step/sec: 48.9946\n","INFO:tensorflow:examples/sec: 195.978\n","INFO:tensorflow:Saving checkpoints for 20000 into /content/trained_output/model.ckpt.\n","INFO:tensorflow:global_step/sec: 35.1726\n","INFO:tensorflow:examples/sec: 140.69\n","INFO:tensorflow:global_step/sec: 49.1505\n","INFO:tensorflow:examples/sec: 196.602\n","INFO:tensorflow:global_step/sec: 52.2058\n","INFO:tensorflow:examples/sec: 208.823\n","INFO:tensorflow:global_step/sec: 52.003\n","INFO:tensorflow:examples/sec: 208.012\n","INFO:tensorflow:global_step/sec: 52.2409\n","INFO:tensorflow:examples/sec: 208.964\n","INFO:tensorflow:global_step/sec: 52.2729\n","INFO:tensorflow:examples/sec: 209.092\n","INFO:tensorflow:global_step/sec: 52.1986\n","INFO:tensorflow:examples/sec: 208.795\n","INFO:tensorflow:global_step/sec: 48.8857\n","INFO:tensorflow:examples/sec: 195.543\n","INFO:tensorflow:global_step/sec: 48.6708\n","INFO:tensorflow:examples/sec: 194.683\n","INFO:tensorflow:global_step/sec: 49.1173\n","INFO:tensorflow:examples/sec: 196.469\n","INFO:tensorflow:Saving checkpoints for 21000 into /content/trained_output/model.ckpt.\n","INFO:tensorflow:global_step/sec: 40.1353\n","INFO:tensorflow:examples/sec: 160.541\n","INFO:tensorflow:global_step/sec: 51.9244\n","INFO:tensorflow:examples/sec: 207.698\n","INFO:tensorflow:global_step/sec: 52.3621\n","INFO:tensorflow:examples/sec: 209.448\n","INFO:tensorflow:global_step/sec: 52.1699\n","INFO:tensorflow:examples/sec: 208.68\n","INFO:tensorflow:global_step/sec: 52.3828\n","INFO:tensorflow:examples/sec: 209.531\n","INFO:tensorflow:global_step/sec: 51.145\n","INFO:tensorflow:examples/sec: 204.58\n","INFO:tensorflow:global_step/sec: 49.346\n","INFO:tensorflow:examples/sec: 197.384\n","INFO:tensorflow:global_step/sec: 49.5214\n","INFO:tensorflow:examples/sec: 198.085\n","INFO:tensorflow:global_step/sec: 48.7301\n","INFO:tensorflow:examples/sec: 194.92\n","INFO:tensorflow:global_step/sec: 50.6896\n","INFO:tensorflow:examples/sec: 202.758\n","INFO:tensorflow:Saving checkpoints for 22000 into /content/trained_output/model.ckpt.\n","INFO:tensorflow:global_step/sec: 41.578\n","INFO:tensorflow:examples/sec: 166.312\n","INFO:tensorflow:global_step/sec: 52.4394\n","INFO:tensorflow:examples/sec: 209.758\n","INFO:tensorflow:global_step/sec: 52.2993\n","INFO:tensorflow:examples/sec: 209.197\n","INFO:tensorflow:global_step/sec: 51.957\n","INFO:tensorflow:examples/sec: 207.828\n","INFO:tensorflow:global_step/sec: 50.3364\n","INFO:tensorflow:examples/sec: 201.345\n","INFO:tensorflow:global_step/sec: 49.2228\n","INFO:tensorflow:examples/sec: 196.891\n","INFO:tensorflow:global_step/sec: 49.2466\n","INFO:tensorflow:examples/sec: 196.987\n","INFO:tensorflow:global_step/sec: 49.3658\n","INFO:tensorflow:examples/sec: 197.463\n","INFO:tensorflow:global_step/sec: 51.893\n","INFO:tensorflow:examples/sec: 207.572\n","INFO:tensorflow:global_step/sec: 52.4215\n","INFO:tensorflow:examples/sec: 209.686\n","INFO:tensorflow:Saving checkpoints for 23000 into /content/trained_output/model.ckpt.\n","INFO:tensorflow:global_step/sec: 41.8477\n","INFO:tensorflow:examples/sec: 167.391\n","INFO:tensorflow:global_step/sec: 52.1921\n","INFO:tensorflow:examples/sec: 208.768\n","INFO:tensorflow:global_step/sec: 52.3688\n","INFO:tensorflow:examples/sec: 209.475\n","INFO:tensorflow:global_step/sec: 48.9401\n","INFO:tensorflow:examples/sec: 195.761\n","INFO:tensorflow:global_step/sec: 49.5319\n","INFO:tensorflow:examples/sec: 198.127\n","INFO:tensorflow:global_step/sec: 48.6807\n","INFO:tensorflow:examples/sec: 194.723\n","INFO:tensorflow:global_step/sec: 49.2811\n","INFO:tensorflow:examples/sec: 197.124\n","INFO:tensorflow:global_step/sec: 52.1937\n","INFO:tensorflow:examples/sec: 208.775\n","INFO:tensorflow:global_step/sec: 52.1608\n","INFO:tensorflow:examples/sec: 208.643\n","INFO:tensorflow:global_step/sec: 52.3679\n","INFO:tensorflow:examples/sec: 209.472\n","INFO:tensorflow:Saving checkpoints for 24000 into /content/trained_output/model.ckpt.\n","INFO:tensorflow:global_step/sec: 41.4828\n","INFO:tensorflow:examples/sec: 165.931\n","INFO:tensorflow:global_step/sec: 51.1277\n","INFO:tensorflow:examples/sec: 204.511\n","INFO:tensorflow:global_step/sec: 48.7677\n","INFO:tensorflow:examples/sec: 195.071\n","INFO:tensorflow:global_step/sec: 49.351\n","INFO:tensorflow:examples/sec: 197.404\n","INFO:tensorflow:global_step/sec: 49.2675\n","INFO:tensorflow:examples/sec: 197.07\n","INFO:tensorflow:global_step/sec: 50.7015\n","INFO:tensorflow:examples/sec: 202.806\n","INFO:tensorflow:global_step/sec: 52.1911\n","INFO:tensorflow:examples/sec: 208.764\n","INFO:tensorflow:global_step/sec: 52.3955\n","INFO:tensorflow:examples/sec: 209.582\n","INFO:tensorflow:global_step/sec: 52.2447\n","INFO:tensorflow:examples/sec: 208.979\n","INFO:tensorflow:global_step/sec: 52.3801\n","INFO:tensorflow:examples/sec: 209.52\n","INFO:tensorflow:Saving checkpoints for 25000 into /content/trained_output/model.ckpt.\n","INFO:tensorflow:global_step/sec: 36.5604\n","INFO:tensorflow:examples/sec: 146.242\n","INFO:tensorflow:global_step/sec: 49.3609\n","INFO:tensorflow:examples/sec: 197.444\n","INFO:tensorflow:global_step/sec: 49.2185\n","INFO:tensorflow:examples/sec: 196.874\n","INFO:tensorflow:global_step/sec: 49.1078\n","INFO:tensorflow:examples/sec: 196.431\n","INFO:tensorflow:global_step/sec: 51.6277\n","INFO:tensorflow:examples/sec: 206.511\n","INFO:tensorflow:global_step/sec: 52.1876\n","INFO:tensorflow:examples/sec: 208.751\n","INFO:tensorflow:global_step/sec: 52.4564\n","INFO:tensorflow:examples/sec: 209.826\n","INFO:tensorflow:global_step/sec: 52.283\n","INFO:tensorflow:examples/sec: 209.132\n","INFO:tensorflow:global_step/sec: 52.1271\n","INFO:tensorflow:examples/sec: 208.508\n","INFO:tensorflow:global_step/sec: 50.4553\n","INFO:tensorflow:examples/sec: 201.821\n","INFO:tensorflow:Saving checkpoints for 26000 into /content/trained_output/model.ckpt.\n","INFO:tensorflow:global_step/sec: 35.9855\n","INFO:tensorflow:examples/sec: 143.942\n","INFO:tensorflow:global_step/sec: 48.873\n","INFO:tensorflow:examples/sec: 195.492\n","INFO:tensorflow:Saving checkpoints for 26185 into /content/trained_output/model.ckpt.\n","INFO:tensorflow:Loss for final step: 0.33621117.\n","INFO:tensorflow:training_loop marked as finished\n","INFO:tensorflow:Writing example 0 of 5463\n","INFO:tensorflow:*** Example ***\n","INFO:tensorflow:guid: dev_matched-0\n","INFO:tensorflow:tokens: [CLS] what came into force after the new constitution was herald ? [SEP] as of that day , the new constitution herald ##ing the second republic came into force . [SEP]\n","INFO:tensorflow:input_ids: 101 2054 2234 2046 2486 2044 1996 2047 4552 2001 9536 1029 102 2004 1997 2008 2154 1010 1996 2047 4552 9536 2075 1996 2117 3072 2234 2046 2486 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:label: entailment (id = 0)\n","INFO:tensorflow:*** Example ***\n","INFO:tensorflow:guid: dev_matched-1\n","INFO:tensorflow:tokens: [CLS] what is the first major city in the stream of the rhine ? [SEP] the most important tributaries in this area are the ill below of strasbourg , the neck ##ar in mannheim and the main across from mainz . [SEP]\n","INFO:tensorflow:input_ids: 101 2054 2003 1996 2034 2350 2103 1999 1996 5460 1997 1996 10950 1029 102 1996 2087 2590 15777 1999 2023 2181 2024 1996 5665 2917 1997 18104 1010 1996 3300 2906 1999 25116 1998 1996 2364 2408 2013 19876 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:label: not_entailment (id = 1)\n","INFO:tensorflow:*** Example ***\n","INFO:tensorflow:guid: dev_matched-2\n","INFO:tensorflow:tokens: [CLS] what is the minimum required if you want to teach in canada ? [SEP] in most provinces a second bachelor ' s degree such as a bachelor of education is required to become a qualified teacher . [SEP]\n","INFO:tensorflow:input_ids: 101 2054 2003 1996 6263 3223 2065 2017 2215 2000 6570 1999 2710 1029 102 1999 2087 6941 1037 2117 5065 1005 1055 3014 2107 2004 1037 5065 1997 2495 2003 3223 2000 2468 1037 4591 3836 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:label: not_entailment (id = 1)\n","INFO:tensorflow:*** Example ***\n","INFO:tensorflow:guid: dev_matched-3\n","INFO:tensorflow:tokens: [CLS] how was te ##mu ##jin kept imprisoned by the tay ##ichi ' ud ? [SEP] the tay ##ichi ' ud enslaved te ##mu ##jin ( reportedly with a can ##gue , a sort of portable stocks ) , but with the help of a sympathetic guard , the father of chi ##lau ##n ( who later became a general of gen ##ghi ##s khan ) , he was able to escape from the ge ##r ( yu ##rt ) in the middle of the night by hiding in a river cr ##evic ##e . [ citation needed ] [SEP]\n","INFO:tensorflow:input_ids: 101 2129 2001 8915 12274 14642 2921 8580 2011 1996 28117 11319 1005 20904 1029 102 1996 28117 11319 1005 20904 22216 8915 12274 14642 1006 7283 2007 1037 2064 9077 1010 1037 4066 1997 12109 15768 1007 1010 2021 2007 1996 2393 1997 1037 13026 3457 1010 1996 2269 1997 9610 17298 2078 1006 2040 2101 2150 1037 2236 1997 8991 28891 2015 4967 1007 1010 2002 2001 2583 2000 4019 2013 1996 16216 2099 1006 9805 5339 1007 1999 1996 2690 1997 1996 2305 2011 6318 1999 1037 2314 13675 17726 2063 1012 1031 11091 2734 1033 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:label: entailment (id = 0)\n","INFO:tensorflow:*** Example ***\n","INFO:tensorflow:guid: dev_matched-4\n","INFO:tensorflow:tokens: [CLS] what did herr got ##t , di ##ch lobe ##n wi ##r become known as ? [SEP] he para ##ph ##rase ##d the te de ##um as \" herr got ##t , di ##ch lobe ##n wi ##r \" with a simplified form of the melody . [SEP]\n","INFO:tensorflow:input_ids: 101 2054 2106 23506 2288 2102 1010 4487 2818 21833 2078 15536 2099 2468 2124 2004 1029 102 2002 11498 8458 23797 2094 1996 8915 2139 2819 2004 1000 23506 2288 2102 1010 4487 2818 21833 2078 15536 2099 1000 2007 1037 11038 2433 1997 1996 8531 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:label: not_entailment (id = 1)\n","INFO:tensorflow:***** Running evaluation *****\n","INFO:tensorflow:  Num examples = 5463 (5463 actual, 0 padding)\n","INFO:tensorflow:  Batch size = 8\n","INFO:tensorflow:Calling model_fn.\n","INFO:tensorflow:Running eval on CPU\n","INFO:tensorflow:*** Features ***\n","INFO:tensorflow:  name = input_ids, shape = (?, 128)\n","INFO:tensorflow:  name = input_mask, shape = (?, 128)\n","INFO:tensorflow:  name = is_real_example, shape = (?,)\n","INFO:tensorflow:  name = label_ids, shape = (?,)\n","INFO:tensorflow:  name = segment_ids, shape = (?, 128)\n","INFO:tensorflow:**** Trainable Variables ****\n","INFO:tensorflow:  name = bert/embeddings/word_embeddings:0, shape = (30522, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/embeddings/token_type_embeddings:0, shape = (2, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/embeddings/position_embeddings:0, shape = (512, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/embeddings/LayerNorm/beta:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/embeddings/LayerNorm/gamma:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/query/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/query/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/key/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/key/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/value/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/value/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/dense/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/dense/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/LayerNorm/beta:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/LayerNorm/gamma:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/intermediate/dense/kernel:0, shape = (256, 1024), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/intermediate/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/output/dense/kernel:0, shape = (1024, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/output/dense/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/output/LayerNorm/beta:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/output/LayerNorm/gamma:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/query/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/query/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/key/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/key/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/value/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/value/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/dense/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/dense/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/LayerNorm/beta:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/LayerNorm/gamma:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/intermediate/dense/kernel:0, shape = (256, 1024), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/intermediate/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/output/dense/kernel:0, shape = (1024, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/output/dense/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/output/LayerNorm/beta:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/output/LayerNorm/gamma:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/query/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/query/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/key/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/key/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/value/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/value/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/dense/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/dense/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/LayerNorm/beta:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/LayerNorm/gamma:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/intermediate/dense/kernel:0, shape = (256, 1024), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/intermediate/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/output/dense/kernel:0, shape = (1024, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/output/dense/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/output/LayerNorm/beta:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/output/LayerNorm/gamma:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/query/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/query/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/key/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/key/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/value/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/value/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/dense/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/dense/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/LayerNorm/beta:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/LayerNorm/gamma:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/intermediate/dense/kernel:0, shape = (256, 1024), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/intermediate/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/output/dense/kernel:0, shape = (1024, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/output/dense/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/output/LayerNorm/beta:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/output/LayerNorm/gamma:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/pooler/dense/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/pooler/dense/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = output_weights:0, shape = (2, 256)\n","INFO:tensorflow:  name = output_bias:0, shape = (2,)\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/metrics_impl.py:455: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.cast instead.\n","INFO:tensorflow:Done calling model_fn.\n","INFO:tensorflow:Starting evaluation at 2023-05-22T07:33:23Z\n","INFO:tensorflow:Graph was finalized.\n","2023-05-22 07:33:24.193814: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0\n","2023-05-22 07:33:24.193876: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2023-05-22 07:33:24.193895: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0 \n","2023-05-22 07:33:24.193905: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N \n","2023-05-22 07:33:24.194007: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14248 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use standard file APIs to check for files with this prefix.\n","INFO:tensorflow:Restoring parameters from /content/trained_output/model.ckpt-26185\n","INFO:tensorflow:Running local_init_op.\n","INFO:tensorflow:Done running local_init_op.\n","INFO:tensorflow:Finished evaluation at 2023-05-22-07:33:29\n","INFO:tensorflow:Saving dict for global step 26185: eval_accuracy = 0.8321435, eval_loss = 0.4846125, global_step = 26185, loss = 0.48469925\n","INFO:tensorflow:Saving 'checkpoint_path' summary for global step 26185: /content/trained_output/model.ckpt-26185\n","INFO:tensorflow:evaluation_loop marked as finished\n","INFO:tensorflow:***** Eval results *****\n","INFO:tensorflow:  eval_accuracy = 0.8321435\n","INFO:tensorflow:  eval_loss = 0.4846125\n","INFO:tensorflow:  global_step = 26185\n","INFO:tensorflow:  loss = 0.48469925\n"]}],"source":["%cd /content/drive/MyDrive/Code_pretrain\n","%pwd\n","%env BERT_BASE_DIR=uncased_L-4_H-256_A-4\n","%env GLUE_DIR=data\n","!rm -rf /content/trained_output\n","\n","!python3 run_classifier.py \\\n","  --task_name=QNLI \\\n","  --do_train=true \\\n","  --do_eval=true \\\n","  --data_dir=$GLUE_DIR/QNLI \\\n","  --vocab_file=$BERT_BASE_DIR/vocab.txt \\\n","  --bert_config_file=$BERT_BASE_DIR/bert_config.json \\\n","  --init_checkpoint=$BERT_BASE_DIR/bert_model.ckpt \\\n","  --max_seq_length=128 \\\n","  --train_batch_size=4 \\\n","  --learning_rate=2e-5 \\\n","  --num_train_epochs=1.0 \\\n","  --output_dir=/content/trained_output\n","\n","# result metric.\n","# INFO:tensorflow:  eval_accuracy = 0.77631336\n","# INFO:tensorflow:  eval_loss = 0.54709363\n","# INFO:tensorflow:  global_step = 26185\n","# INFO:tensorflow:  loss = 0.5471753\n","\n","# INFO:tensorflow:  eval_accuracy = 0.8321435\n","# INFO:tensorflow:  eval_loss = 0.4846125\n","# INFO:tensorflow:  global_step = 26185\n","# INFO:tensorflow:  loss = 0.48469925"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"m20Aj7Pf_Ruf","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1684741221147,"user_tz":-480,"elapsed":166131,"user":{"displayName":"Brian Shen","userId":"08246478872294528508"}},"outputId":"031e59ba-796a-4b3c-a2c4-186c655100a2"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Code_pretrain\n","env: BERT_BASE_DIR=uncased_L-4_H-256_A-4\n","env: GLUE_DIR=data\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n","\n","WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n","For more information, please see:\n","  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n","  * https://github.com/tensorflow/addons\n","If you depend on functionality not listed there, please file an issue.\n","\n","WARNING:tensorflow:Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f28226c50d0>) includes params argument, but params are not passed to Estimator.\n","INFO:tensorflow:Using config: {'_model_dir': '/content/trained_output', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 1000, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n","graph_options {\n","  rewrite_options {\n","    meta_optimizer_iterations: ONE\n","  }\n","}\n",", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f2822eed6d8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=1000, num_shards=8, num_cores_per_replica=None, per_host_input_for_training=3, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None), '_cluster': None}\n","INFO:tensorflow:_TPUContext: eval_on_tpu True\n","WARNING:tensorflow:eval_on_tpu ignored because use_tpu is False.\n","INFO:tensorflow:Writing example 0 of 635\n","INFO:tensorflow:*** Example ***\n","INFO:tensorflow:guid: train-0\n","INFO:tensorflow:tokens: [CLS] i stuck a pin through a carrot . when i pulled the pin out , it had a hole . [SEP] the carrot had a hole . [SEP]\n","INFO:tensorflow:input_ids: 101 1045 5881 1037 9231 2083 1037 25659 1012 2043 1045 2766 1996 9231 2041 1010 2009 2018 1037 4920 1012 102 1996 25659 2018 1037 4920 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:label: 1 (id = 1)\n","INFO:tensorflow:*** Example ***\n","INFO:tensorflow:guid: train-1\n","INFO:tensorflow:tokens: [CLS] john couldn ' t see the stage with billy in front of him because he is so short . [SEP] john is so short . [SEP]\n","INFO:tensorflow:input_ids: 101 2198 2481 1005 1056 2156 1996 2754 2007 5006 1999 2392 1997 2032 2138 2002 2003 2061 2460 1012 102 2198 2003 2061 2460 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:label: 1 (id = 1)\n","INFO:tensorflow:*** Example ***\n","INFO:tensorflow:guid: train-2\n","INFO:tensorflow:tokens: [CLS] the police arrested all of the gang members . they were trying to stop the drug trade in the neighborhood . [SEP] the police were trying to stop the drug trade in the neighborhood . [SEP]\n","INFO:tensorflow:input_ids: 101 1996 2610 4727 2035 1997 1996 6080 2372 1012 2027 2020 2667 2000 2644 1996 4319 3119 1999 1996 5101 1012 102 1996 2610 2020 2667 2000 2644 1996 4319 3119 1999 1996 5101 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:label: 1 (id = 1)\n","INFO:tensorflow:*** Example ***\n","INFO:tensorflow:guid: train-3\n","INFO:tensorflow:tokens: [CLS] steve follows fred ' s example in everything . he influences him hugely . [SEP] steve influences him hugely . [SEP]\n","INFO:tensorflow:input_ids: 101 3889 4076 5965 1005 1055 2742 1999 2673 1012 2002 8092 2032 27564 1012 102 3889 8092 2032 27564 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:label: 0 (id = 0)\n","INFO:tensorflow:*** Example ***\n","INFO:tensorflow:guid: train-4\n","INFO:tensorflow:tokens: [CLS] when ta ##tya ##na reached the cabin , her mother was sleeping . she was careful not to disturb her , und ##ress ##ing and climbing back into her berth . [SEP] mother was careful not to disturb her , und ##ress ##ing and climbing back into her berth . [SEP]\n","INFO:tensorflow:input_ids: 101 2043 11937 21426 2532 2584 1996 6644 1010 2014 2388 2001 5777 1012 2016 2001 6176 2025 2000 22995 2014 1010 6151 8303 2075 1998 8218 2067 2046 2014 17064 1012 102 2388 2001 6176 2025 2000 22995 2014 1010 6151 8303 2075 1998 8218 2067 2046 2014 17064 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:label: 0 (id = 0)\n","INFO:tensorflow:***** Running training *****\n","INFO:tensorflow:  Num examples = 635\n","INFO:tensorflow:  Batch size = 4\n","INFO:tensorflow:  Num steps = 158\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Colocations handled automatically by placer.\n","WARNING:tensorflow:From run_classifier.py:890: map_and_batch (from tensorflow.contrib.data.python.ops.batching) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.experimental.map_and_batch(...)`.\n","WARNING:tensorflow:From run_classifier.py:870: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.cast instead.\n","INFO:tensorflow:Calling model_fn.\n","INFO:tensorflow:Running train on CPU\n","INFO:tensorflow:*** Features ***\n","INFO:tensorflow:  name = input_ids, shape = (4, 128)\n","INFO:tensorflow:  name = input_mask, shape = (4, 128)\n","INFO:tensorflow:  name = is_real_example, shape = (4,)\n","INFO:tensorflow:  name = label_ids, shape = (4,)\n","INFO:tensorflow:  name = segment_ids, shape = (4, 128)\n","WARNING:tensorflow:From /content/drive/MyDrive/Code_pretrain/modeling.py:358: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n","WARNING:tensorflow:From /content/drive/MyDrive/Code_pretrain/modeling.py:671: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use keras.layers.dense instead.\n","INFO:tensorflow:**** Trainable Variables ****\n","INFO:tensorflow:  name = bert/embeddings/word_embeddings:0, shape = (30522, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/embeddings/token_type_embeddings:0, shape = (2, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/embeddings/position_embeddings:0, shape = (512, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/embeddings/LayerNorm/beta:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/embeddings/LayerNorm/gamma:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/query/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/query/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/key/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/key/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/value/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/value/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/dense/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/dense/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/LayerNorm/beta:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/LayerNorm/gamma:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/intermediate/dense/kernel:0, shape = (256, 1024), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/intermediate/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/output/dense/kernel:0, shape = (1024, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/output/dense/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/output/LayerNorm/beta:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/output/LayerNorm/gamma:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/query/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/query/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/key/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/key/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/value/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/value/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/dense/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/dense/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/LayerNorm/beta:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/LayerNorm/gamma:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/intermediate/dense/kernel:0, shape = (256, 1024), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/intermediate/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/output/dense/kernel:0, shape = (1024, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/output/dense/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/output/LayerNorm/beta:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/output/LayerNorm/gamma:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/query/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/query/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/key/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/key/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/value/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/value/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/dense/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/dense/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/LayerNorm/beta:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/LayerNorm/gamma:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/intermediate/dense/kernel:0, shape = (256, 1024), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/intermediate/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/output/dense/kernel:0, shape = (1024, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/output/dense/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/output/LayerNorm/beta:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/output/LayerNorm/gamma:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/query/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/query/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/key/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/key/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/value/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/value/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/dense/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/dense/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/LayerNorm/beta:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/LayerNorm/gamma:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/intermediate/dense/kernel:0, shape = (256, 1024), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/intermediate/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/output/dense/kernel:0, shape = (1024, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/output/dense/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/output/LayerNorm/beta:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/output/LayerNorm/gamma:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/pooler/dense/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/pooler/dense/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = output_weights:0, shape = (2, 256)\n","INFO:tensorflow:  name = output_bias:0, shape = (2,)\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/learning_rate_decay_v2.py:321: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Deprecated in favor of operator or tf.math.divide.\n","INFO:tensorflow:Done calling model_fn.\n","INFO:tensorflow:Create CheckpointSaverHook.\n","INFO:tensorflow:Graph was finalized.\n","2023-05-22 07:37:49.357661: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n","2023-05-22 07:37:49.362156: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2200155000 Hz\n","2023-05-22 07:37:49.362383: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x5a6f660 executing computations on platform Host. Devices:\n","2023-05-22 07:37:49.362415: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>\n","INFO:tensorflow:Running local_init_op.\n","INFO:tensorflow:Done running local_init_op.\n","INFO:tensorflow:Saving checkpoints for 0 into /content/trained_output/model.ckpt.\n","INFO:tensorflow:global_step/sec: 1.21425\n","INFO:tensorflow:examples/sec: 4.85702\n","INFO:tensorflow:Saving checkpoints for 158 into /content/trained_output/model.ckpt.\n","INFO:tensorflow:Loss for final step: 0.73438656.\n","INFO:tensorflow:training_loop marked as finished\n","INFO:tensorflow:Writing example 0 of 71\n","INFO:tensorflow:*** Example ***\n","INFO:tensorflow:guid: dev-0\n","INFO:tensorflow:tokens: [CLS] the drain is cl ##og ##ged with hair . it has to be cleaned . [SEP] the hair has to be cleaned . [SEP]\n","INFO:tensorflow:input_ids: 101 1996 12475 2003 18856 8649 5999 2007 2606 1012 2009 2038 2000 2022 12176 1012 102 1996 2606 2038 2000 2022 12176 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:label: 0 (id = 0)\n","INFO:tensorflow:*** Example ***\n","INFO:tensorflow:guid: dev-1\n","INFO:tensorflow:tokens: [CLS] jane knocked on susan ' s door but she did not answer . [SEP] susan did not answer . [SEP]\n","INFO:tensorflow:input_ids: 101 4869 6573 2006 6294 1005 1055 2341 2021 2016 2106 2025 3437 1012 102 6294 2106 2025 3437 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:label: 1 (id = 1)\n","INFO:tensorflow:*** Example ***\n","INFO:tensorflow:guid: dev-2\n","INFO:tensorflow:tokens: [CLS] beth didn ' t get angry with sally , who had cut her off , because she stopped and counted to ten . [SEP] sally stopped and counted to ten . [SEP]\n","INFO:tensorflow:input_ids: 101 7014 2134 1005 1056 2131 4854 2007 8836 1010 2040 2018 3013 2014 2125 1010 2138 2016 3030 1998 8897 2000 2702 1012 102 8836 3030 1998 8897 2000 2702 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:label: 0 (id = 0)\n","INFO:tensorflow:*** Example ***\n","INFO:tensorflow:guid: dev-3\n","INFO:tensorflow:tokens: [CLS] no one joins facebook to be sad and lonely . but a new study from the university of wisconsin psychologist george lincoln argues that that ' s exactly how it makes us feel . [SEP] that ' s exactly how facebook makes us feel . [SEP]\n","INFO:tensorflow:input_ids: 101 2053 2028 9794 9130 2000 2022 6517 1998 9479 1012 2021 1037 2047 2817 2013 1996 2118 1997 5273 15034 2577 5367 9251 2008 2008 1005 1055 3599 2129 2009 3084 2149 2514 1012 102 2008 1005 1055 3599 2129 9130 3084 2149 2514 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:label: 1 (id = 1)\n","INFO:tensorflow:*** Example ***\n","INFO:tensorflow:guid: dev-4\n","INFO:tensorflow:tokens: [CLS] the man couldn ' t lift his son because he was so heavy . [SEP] the son was so heavy . [SEP]\n","INFO:tensorflow:input_ids: 101 1996 2158 2481 1005 1056 6336 2010 2365 2138 2002 2001 2061 3082 1012 102 1996 2365 2001 2061 3082 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:label: 1 (id = 1)\n","INFO:tensorflow:***** Running evaluation *****\n","INFO:tensorflow:  Num examples = 71 (71 actual, 0 padding)\n","INFO:tensorflow:  Batch size = 8\n","INFO:tensorflow:Calling model_fn.\n","INFO:tensorflow:Running eval on CPU\n","INFO:tensorflow:*** Features ***\n","INFO:tensorflow:  name = input_ids, shape = (?, 128)\n","INFO:tensorflow:  name = input_mask, shape = (?, 128)\n","INFO:tensorflow:  name = is_real_example, shape = (?,)\n","INFO:tensorflow:  name = label_ids, shape = (?,)\n","INFO:tensorflow:  name = segment_ids, shape = (?, 128)\n","INFO:tensorflow:**** Trainable Variables ****\n","INFO:tensorflow:  name = bert/embeddings/word_embeddings:0, shape = (30522, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/embeddings/token_type_embeddings:0, shape = (2, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/embeddings/position_embeddings:0, shape = (512, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/embeddings/LayerNorm/beta:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/embeddings/LayerNorm/gamma:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/query/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/query/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/key/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/key/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/value/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/value/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/dense/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/dense/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/LayerNorm/beta:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/LayerNorm/gamma:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/intermediate/dense/kernel:0, shape = (256, 1024), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/intermediate/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/output/dense/kernel:0, shape = (1024, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/output/dense/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/output/LayerNorm/beta:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/output/LayerNorm/gamma:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/query/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/query/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/key/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/key/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/value/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/value/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/dense/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/dense/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/LayerNorm/beta:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/LayerNorm/gamma:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/intermediate/dense/kernel:0, shape = (256, 1024), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/intermediate/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/output/dense/kernel:0, shape = (1024, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/output/dense/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/output/LayerNorm/beta:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/output/LayerNorm/gamma:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/query/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/query/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/key/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/key/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/value/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/value/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/dense/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/dense/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/LayerNorm/beta:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/LayerNorm/gamma:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/intermediate/dense/kernel:0, shape = (256, 1024), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/intermediate/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/output/dense/kernel:0, shape = (1024, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/output/dense/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/output/LayerNorm/beta:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/output/LayerNorm/gamma:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/query/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/query/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/key/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/key/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/value/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/value/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/dense/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/dense/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/LayerNorm/beta:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/LayerNorm/gamma:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/intermediate/dense/kernel:0, shape = (256, 1024), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/intermediate/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/output/dense/kernel:0, shape = (1024, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/output/dense/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/output/LayerNorm/beta:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/output/LayerNorm/gamma:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/pooler/dense/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/pooler/dense/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = output_weights:0, shape = (2, 256)\n","INFO:tensorflow:  name = output_bias:0, shape = (2,)\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/metrics_impl.py:455: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.cast instead.\n","INFO:tensorflow:Done calling model_fn.\n","INFO:tensorflow:Starting evaluation at 2023-05-22T07:40:13Z\n","INFO:tensorflow:Graph was finalized.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use standard file APIs to check for files with this prefix.\n","INFO:tensorflow:Restoring parameters from /content/trained_output/model.ckpt-158\n","INFO:tensorflow:Running local_init_op.\n","INFO:tensorflow:Done running local_init_op.\n","INFO:tensorflow:Finished evaluation at 2023-05-22-07:40:20\n","INFO:tensorflow:Saving dict for global step 158: eval_accuracy = 0.4084507, eval_loss = 0.7177324, global_step = 158, loss = 0.7176453\n","INFO:tensorflow:Saving 'checkpoint_path' summary for global step 158: /content/trained_output/model.ckpt-158\n","INFO:tensorflow:evaluation_loop marked as finished\n","INFO:tensorflow:***** Eval results *****\n","INFO:tensorflow:  eval_accuracy = 0.4084507\n","INFO:tensorflow:  eval_loss = 0.7177324\n","INFO:tensorflow:  global_step = 158\n","INFO:tensorflow:  loss = 0.7176453\n"]}],"source":["%cd /content/drive/MyDrive/Code_pretrain\n","%pwd\n","%env BERT_BASE_DIR=uncased_L-4_H-256_A-4\n","%env GLUE_DIR=data\n","!rm -rf /content/trained_output\n","\n","!python3 run_classifier.py \\\n","  --task_name=WNLI \\\n","  --do_train=true \\\n","  --do_eval=true \\\n","  --data_dir=$GLUE_DIR/WNLI \\\n","  --vocab_file=$BERT_BASE_DIR/vocab.txt \\\n","  --bert_config_file=$BERT_BASE_DIR/bert_config.json \\\n","  --init_checkpoint=$BERT_BASE_DIR/bert_model.ckpt \\\n","  --max_seq_length=128 \\\n","  --train_batch_size=4 \\\n","  --learning_rate=2e-5 \\\n","  --num_train_epochs=1.0 \\\n","  --output_dir=/content/trained_output\n","\n","# result metric.\n","# INFO:tensorflow:  eval_accuracy = 0.4225352\n","# INFO:tensorflow:  eval_loss = 0.70586663\n","# INFO:tensorflow:  global_step = 158\n","# INFO:tensorflow:  loss = 0.70596206\n","\n","# INFO:tensorflow:  eval_accuracy = 0.4084507\n","# INFO:tensorflow:  eval_loss = 0.7177324\n","# INFO:tensorflow:  global_step = 158\n","# INFO:tensorflow:  loss = 0.7176453"]},{"cell_type":"code","execution_count":21,"metadata":{"id":"gsSPfldS_ZB-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1684740870670,"user_tz":-480,"elapsed":34714,"user":{"displayName":"Brian Shen","userId":"08246478872294528508"}},"outputId":"daa6ae6d-05b8-43ab-cadf-63dc321274c9"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Code_pretrain\n","env: BERT_BASE_DIR=uncased_L-4_H-256_A-4\n","env: GLUE_DIR=data\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n","\n","WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n","For more information, please see:\n","  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n","  * https://github.com/tensorflow/addons\n","If you depend on functionality not listed there, please file an issue.\n","\n","WARNING:tensorflow:Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7fc60caabd08>) includes params argument, but params are not passed to Estimator.\n","INFO:tensorflow:Using config: {'_model_dir': '/content/trained_output', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 1000, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n","graph_options {\n","  rewrite_options {\n","    meta_optimizer_iterations: ONE\n","  }\n","}\n",", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fc60ca5ac50>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=1000, num_shards=8, num_cores_per_replica=None, per_host_input_for_training=3, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None), '_cluster': None}\n","INFO:tensorflow:_TPUContext: eval_on_tpu True\n","WARNING:tensorflow:eval_on_tpu ignored because use_tpu is False.\n","INFO:tensorflow:Writing example 0 of 2490\n","INFO:tensorflow:*** Example ***\n","INFO:tensorflow:guid: train-0\n","INFO:tensorflow:tokens: [CLS] no weapons of mass destruction found in iraq yet . [SEP] weapons of mass destruction found in iraq . [SEP]\n","INFO:tensorflow:input_ids: 101 2053 4255 1997 3742 6215 2179 1999 5712 2664 1012 102 4255 1997 3742 6215 2179 1999 5712 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:label: not_entailment (id = 1)\n","INFO:tensorflow:*** Example ***\n","INFO:tensorflow:guid: train-1\n","INFO:tensorflow:tokens: [CLS] a place of sorrow , after pope john paul ii died , became a place of celebration , as roman catholic faithful gathered in downtown chicago to mark the installation of new pope benedict xvi . [SEP] pope benedict xvi is the new leader of the roman catholic church . [SEP]\n","INFO:tensorflow:input_ids: 101 1037 2173 1997 14038 1010 2044 4831 2198 2703 2462 2351 1010 2150 1037 2173 1997 7401 1010 2004 3142 3234 11633 5935 1999 5116 3190 2000 2928 1996 8272 1997 2047 4831 12122 16855 1012 102 4831 12122 16855 2003 1996 2047 3003 1997 1996 3142 3234 2277 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:label: entailment (id = 0)\n","INFO:tensorflow:*** Example ***\n","INFO:tensorflow:guid: train-2\n","INFO:tensorflow:tokens: [CLS] her ##ce ##pt ##in was already approved to treat the sick ##est breast cancer patients , and the company said , monday , it will discuss with federal regulators the possibility of pre ##sc ##ri ##bing the drug for more breast cancer patients . [SEP] her ##ce ##pt ##in can be used to treat breast cancer . [SEP]\n","INFO:tensorflow:input_ids: 101 2014 3401 13876 2378 2001 2525 4844 2000 7438 1996 5305 4355 7388 4456 5022 1010 1998 1996 2194 2056 1010 6928 1010 2009 2097 6848 2007 2976 25644 1996 6061 1997 3653 11020 3089 10472 1996 4319 2005 2062 7388 4456 5022 1012 102 2014 3401 13876 2378 2064 2022 2109 2000 7438 7388 4456 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:label: entailment (id = 0)\n","INFO:tensorflow:*** Example ***\n","INFO:tensorflow:guid: train-3\n","INFO:tensorflow:tokens: [CLS] ju ##die vivian , chief executive at prom ##ed ##ica , a medical service company that helps sustain the 2 - year - old vietnam heart institute in ho chi minh city ( formerly saigon ) , said that so far about 1 , 500 children have received treatment . [SEP] the previous name of ho chi minh city was saigon . [SEP]\n","INFO:tensorflow:input_ids: 101 18414 10265 13801 1010 2708 3237 2012 20877 2098 5555 1010 1037 2966 2326 2194 2008 7126 15770 1996 1016 1011 2095 1011 2214 5148 2540 2820 1999 7570 9610 19538 2103 1006 3839 24001 1007 1010 2056 2008 2061 2521 2055 1015 1010 3156 2336 2031 2363 3949 1012 102 1996 3025 2171 1997 7570 9610 19538 2103 2001 24001 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:label: entailment (id = 0)\n","INFO:tensorflow:*** Example ***\n","INFO:tensorflow:guid: train-4\n","INFO:tensorflow:tokens: [CLS] a man is due in court later charged with the murder 26 years ago of a teenager whose case was the first to be featured on bbc one ' s crime ##watch . cole ##tte ara ##m , 16 , was walking to her boyfriend ' s house in key ##worth , nottinghamshire , on 30 october 1983 when she disappeared . her body was later found in a field close to her home . paul stewart hutchinson , 50 , has been charged with murder and is due before nottingham magistrates later . [SEP] paul stewart hutchinson is accused of having stabbed a girl . [SEP]\n","INFO:tensorflow:input_ids: 101 1037 2158 2003 2349 1999 2457 2101 5338 2007 1996 4028 2656 2086 3283 1997 1037 10563 3005 2553 2001 1996 2034 2000 2022 2956 2006 4035 2028 1005 1055 4126 18866 1012 5624 4674 19027 2213 1010 2385 1010 2001 3788 2000 2014 6898 1005 1055 2160 1999 3145 5172 1010 20126 1010 2006 2382 2255 3172 2043 2016 5419 1012 2014 2303 2001 2101 2179 1999 1037 2492 2485 2000 2014 2188 1012 2703 5954 17165 1010 2753 1010 2038 2042 5338 2007 4028 1998 2003 2349 2077 11331 23007 2101 1012 102 2703 5954 17165 2003 5496 1997 2383 13263 1037 2611 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:label: not_entailment (id = 1)\n","INFO:tensorflow:***** Running training *****\n","INFO:tensorflow:  Num examples = 2490\n","INFO:tensorflow:  Batch size = 4\n","INFO:tensorflow:  Num steps = 622\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Colocations handled automatically by placer.\n","WARNING:tensorflow:From run_classifier.py:890: map_and_batch (from tensorflow.contrib.data.python.ops.batching) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.experimental.map_and_batch(...)`.\n","WARNING:tensorflow:From run_classifier.py:870: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.cast instead.\n","INFO:tensorflow:Calling model_fn.\n","INFO:tensorflow:Running train on CPU\n","INFO:tensorflow:*** Features ***\n","INFO:tensorflow:  name = input_ids, shape = (4, 128)\n","INFO:tensorflow:  name = input_mask, shape = (4, 128)\n","INFO:tensorflow:  name = is_real_example, shape = (4,)\n","INFO:tensorflow:  name = label_ids, shape = (4,)\n","INFO:tensorflow:  name = segment_ids, shape = (4, 128)\n","WARNING:tensorflow:From /content/drive/MyDrive/Code_pretrain/modeling.py:358: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n","WARNING:tensorflow:From /content/drive/MyDrive/Code_pretrain/modeling.py:671: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use keras.layers.dense instead.\n","INFO:tensorflow:**** Trainable Variables ****\n","INFO:tensorflow:  name = bert/embeddings/word_embeddings:0, shape = (30522, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/embeddings/token_type_embeddings:0, shape = (2, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/embeddings/position_embeddings:0, shape = (512, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/embeddings/LayerNorm/beta:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/embeddings/LayerNorm/gamma:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/query/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/query/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/key/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/key/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/value/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/value/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/dense/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/dense/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/LayerNorm/beta:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/LayerNorm/gamma:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/intermediate/dense/kernel:0, shape = (256, 1024), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/intermediate/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/output/dense/kernel:0, shape = (1024, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/output/dense/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/output/LayerNorm/beta:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/output/LayerNorm/gamma:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/query/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/query/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/key/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/key/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/value/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/value/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/dense/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/dense/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/LayerNorm/beta:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/LayerNorm/gamma:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/intermediate/dense/kernel:0, shape = (256, 1024), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/intermediate/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/output/dense/kernel:0, shape = (1024, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/output/dense/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/output/LayerNorm/beta:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/output/LayerNorm/gamma:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/query/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/query/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/key/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/key/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/value/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/value/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/dense/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/dense/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/LayerNorm/beta:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/LayerNorm/gamma:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/intermediate/dense/kernel:0, shape = (256, 1024), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/intermediate/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/output/dense/kernel:0, shape = (1024, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/output/dense/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/output/LayerNorm/beta:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/output/LayerNorm/gamma:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/query/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/query/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/key/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/key/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/value/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/value/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/dense/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/dense/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/LayerNorm/beta:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/LayerNorm/gamma:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/intermediate/dense/kernel:0, shape = (256, 1024), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/intermediate/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/output/dense/kernel:0, shape = (1024, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/output/dense/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/output/LayerNorm/beta:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/output/LayerNorm/gamma:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/pooler/dense/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/pooler/dense/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = output_weights:0, shape = (2, 256)\n","INFO:tensorflow:  name = output_bias:0, shape = (2,)\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/learning_rate_decay_v2.py:321: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Deprecated in favor of operator or tf.math.divide.\n","INFO:tensorflow:Done calling model_fn.\n","INFO:tensorflow:Create CheckpointSaverHook.\n","INFO:tensorflow:Graph was finalized.\n","2023-05-22 07:34:04.022129: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA\n","2023-05-22 07:34:04.156045: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2023-05-22 07:34:04.156384: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x320cfe0 executing computations on platform CUDA. Devices:\n","2023-05-22 07:34:04.156415: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n","2023-05-22 07:34:04.159145: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2000185000 Hz\n","2023-05-22 07:34:04.159296: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x312f4e0 executing computations on platform Host. Devices:\n","2023-05-22 07:34:04.159312: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>\n","2023-05-22 07:34:04.159430: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 0 with properties: \n","name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n","pciBusID: 0000:00:04.0\n","totalMemory: 14.75GiB freeMemory: 14.65GiB\n","2023-05-22 07:34:04.159458: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0\n","2023-05-22 07:34:04.159871: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2023-05-22 07:34:04.159890: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0 \n","2023-05-22 07:34:04.159899: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N \n","2023-05-22 07:34:04.159950: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","2023-05-22 07:34:04.159991: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14248 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n","INFO:tensorflow:Running local_init_op.\n","INFO:tensorflow:Done running local_init_op.\n","INFO:tensorflow:Saving checkpoints for 0 into /content/trained_output/model.ckpt.\n","2023-05-22 07:34:11.697015: I tensorflow/stream_executor/dso_loader.cc:152] successfully opened CUDA library libcublas.so.10.0 locally\n","INFO:tensorflow:global_step/sec: 33.4699\n","INFO:tensorflow:examples/sec: 133.88\n","INFO:tensorflow:global_step/sec: 52.6052\n","INFO:tensorflow:examples/sec: 210.421\n","INFO:tensorflow:global_step/sec: 52.2549\n","INFO:tensorflow:examples/sec: 209.019\n","INFO:tensorflow:global_step/sec: 51.177\n","INFO:tensorflow:examples/sec: 204.708\n","INFO:tensorflow:global_step/sec: 49.0997\n","INFO:tensorflow:examples/sec: 196.399\n","INFO:tensorflow:global_step/sec: 49.0845\n","INFO:tensorflow:examples/sec: 196.338\n","INFO:tensorflow:Saving checkpoints for 622 into /content/trained_output/model.ckpt.\n","INFO:tensorflow:Loss for final step: 0.5562406.\n","INFO:tensorflow:training_loop marked as finished\n","INFO:tensorflow:Writing example 0 of 277\n","INFO:tensorflow:*** Example ***\n","INFO:tensorflow:guid: dev-0\n","INFO:tensorflow:tokens: [CLS] dana reeve , the widow of the actor christopher reeve , has died of lung cancer at age 44 , according to the christopher reeve foundation . [SEP] christopher reeve had an accident . [SEP]\n","INFO:tensorflow:input_ids: 101 11271 20726 1010 1996 7794 1997 1996 3364 5696 20726 1010 2038 2351 1997 11192 4456 2012 2287 4008 1010 2429 2000 1996 5696 20726 3192 1012 102 5696 20726 2018 2019 4926 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:label: not_entailment (id = 1)\n","INFO:tensorflow:*** Example ***\n","INFO:tensorflow:guid: dev-1\n","INFO:tensorflow:tokens: [CLS] yet , we now are discovering that antibiotics are losing their effectiveness against illness . disease - causing bacteria are mu ##tat ##ing faster than we can come up with new antibiotics to fight the new variations . [SEP] bacteria is winning the war against antibiotics . [SEP]\n","INFO:tensorflow:input_ids: 101 2664 1010 2057 2085 2024 13648 2008 24479 2024 3974 2037 12353 2114 7355 1012 4295 1011 4786 10327 2024 14163 29336 2075 5514 2084 2057 2064 2272 2039 2007 2047 24479 2000 2954 1996 2047 8358 1012 102 10327 2003 3045 1996 2162 2114 24479 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:label: entailment (id = 0)\n","INFO:tensorflow:*** Example ***\n","INFO:tensorflow:guid: dev-2\n","INFO:tensorflow:tokens: [CLS] cairo is now home to some 15 million people - a bu ##rgeon ##ing population that produces approximately 10 , 000 tonnes of rubbish per day , putting an enormous strain on public services . in the past 10 years , the government has tried hard to encourage private investment in the refuse sector , but some estimate 4 , 000 tonnes of waste is left behind every day , fest ##ering in the heat as it waits for someone to clear it up . it is often the people in the poor ##est neighbourhoods that are worst affected . but in some areas they are fighting back . in shu ##bra , one [SEP] 15 million tonnes of rubbish are produced daily in cairo . [SEP]\n","INFO:tensorflow:input_ids: 101 11096 2003 2085 2188 2000 2070 2321 2454 2111 1011 1037 20934 28242 2075 2313 2008 7137 3155 2184 1010 2199 11000 1997 29132 2566 2154 1010 5128 2019 8216 10178 2006 2270 2578 1012 1999 1996 2627 2184 2086 1010 1996 2231 2038 2699 2524 2000 8627 2797 5211 1999 1996 10214 4753 1010 2021 2070 10197 1018 1010 2199 11000 1997 5949 2003 2187 2369 2296 2154 1010 17037 7999 1999 1996 3684 2004 2009 18074 2005 2619 2000 3154 2009 2039 1012 2009 2003 2411 1996 2111 1999 1996 3532 4355 27535 2008 2024 5409 5360 1012 2021 1999 2070 2752 2027 2024 3554 2067 1012 1999 18454 10024 1010 2028 102 2321 2454 11000 1997 29132 2024 2550 3679 1999 11096 1012 102\n","INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1\n","INFO:tensorflow:label: not_entailment (id = 1)\n","INFO:tensorflow:*** Example ***\n","INFO:tensorflow:guid: dev-3\n","INFO:tensorflow:tokens: [CLS] the ami ##sh community in pennsylvania , which numbers about 55 , 000 , lives an agrarian lifestyle , shu ##nni ##ng technological advances like electricity and automobiles . and many say their ins ##ular lifestyle gives them a sense that they are protected from the violence of american society . but as residents gathered near the school , some wearing traditional ga ##rb and arriving in horse - drawn bug ##gies , they said that sense of safety had been shattered . \" if someone snaps and wants to do something stupid , there ' s no distance that ' s going to stop them , \" said jake king , [SEP] pennsylvania has the biggest ami ##sh community in the u . s . [SEP]\n","INFO:tensorflow:input_ids: 101 1996 26445 4095 2451 1999 3552 1010 2029 3616 2055 4583 1010 2199 1010 3268 2019 23226 9580 1010 18454 23500 3070 10660 9849 2066 6451 1998 19207 1012 1998 2116 2360 2037 16021 7934 9580 3957 2068 1037 3168 2008 2027 2024 5123 2013 1996 4808 1997 2137 2554 1012 2021 2004 3901 5935 2379 1996 2082 1010 2070 4147 3151 11721 15185 1998 7194 1999 3586 1011 4567 11829 17252 1010 2027 2056 2008 3168 1997 3808 2018 2042 10909 1012 1000 2065 2619 20057 1998 4122 2000 2079 2242 5236 1010 2045 1005 1055 2053 3292 2008 1005 1055 2183 2000 2644 2068 1010 1000 2056 5180 2332 1010 102 3552 2038 1996 5221 26445 4095 2451 1999 1996 1057 1012 1055 1012 102\n","INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","INFO:tensorflow:label: not_entailment (id = 1)\n","INFO:tensorflow:*** Example ***\n","INFO:tensorflow:guid: dev-4\n","INFO:tensorflow:tokens: [CLS] security forces were on high alert after an election campaign in which more than 1 , 000 people , including seven election candidates , have been killed . [SEP] security forces were on high alert after a campaign marred by violence . [SEP]\n","INFO:tensorflow:input_ids: 101 3036 2749 2020 2006 2152 9499 2044 2019 2602 3049 1999 2029 2062 2084 1015 1010 2199 2111 1010 2164 2698 2602 5347 1010 2031 2042 2730 1012 102 3036 2749 2020 2006 2152 9499 2044 1037 3049 24563 2011 4808 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","INFO:tensorflow:label: entailment (id = 0)\n","INFO:tensorflow:***** Running evaluation *****\n","INFO:tensorflow:  Num examples = 277 (277 actual, 0 padding)\n","INFO:tensorflow:  Batch size = 8\n","INFO:tensorflow:Calling model_fn.\n","INFO:tensorflow:Running eval on CPU\n","INFO:tensorflow:*** Features ***\n","INFO:tensorflow:  name = input_ids, shape = (?, 128)\n","INFO:tensorflow:  name = input_mask, shape = (?, 128)\n","INFO:tensorflow:  name = is_real_example, shape = (?,)\n","INFO:tensorflow:  name = label_ids, shape = (?,)\n","INFO:tensorflow:  name = segment_ids, shape = (?, 128)\n","INFO:tensorflow:**** Trainable Variables ****\n","INFO:tensorflow:  name = bert/embeddings/word_embeddings:0, shape = (30522, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/embeddings/token_type_embeddings:0, shape = (2, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/embeddings/position_embeddings:0, shape = (512, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/embeddings/LayerNorm/beta:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/embeddings/LayerNorm/gamma:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/query/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/query/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/key/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/key/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/value/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/value/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/dense/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/dense/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/LayerNorm/beta:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/LayerNorm/gamma:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/intermediate/dense/kernel:0, shape = (256, 1024), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/intermediate/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/output/dense/kernel:0, shape = (1024, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/output/dense/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/output/LayerNorm/beta:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_0/output/LayerNorm/gamma:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/query/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/query/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/key/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/key/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/value/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/value/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/dense/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/dense/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/LayerNorm/beta:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/LayerNorm/gamma:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/intermediate/dense/kernel:0, shape = (256, 1024), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/intermediate/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/output/dense/kernel:0, shape = (1024, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/output/dense/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/output/LayerNorm/beta:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_1/output/LayerNorm/gamma:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/query/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/query/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/key/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/key/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/value/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/value/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/dense/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/dense/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/LayerNorm/beta:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/LayerNorm/gamma:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/intermediate/dense/kernel:0, shape = (256, 1024), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/intermediate/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/output/dense/kernel:0, shape = (1024, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/output/dense/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/output/LayerNorm/beta:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_2/output/LayerNorm/gamma:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/query/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/query/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/key/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/key/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/value/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/value/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/dense/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/dense/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/LayerNorm/beta:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/LayerNorm/gamma:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/intermediate/dense/kernel:0, shape = (256, 1024), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/intermediate/dense/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/output/dense/kernel:0, shape = (1024, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/output/dense/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/output/LayerNorm/beta:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/encoder/layer_3/output/LayerNorm/gamma:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/pooler/dense/kernel:0, shape = (256, 256), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = bert/pooler/dense/bias:0, shape = (256,), *INIT_FROM_CKPT*\n","INFO:tensorflow:  name = output_weights:0, shape = (2, 256)\n","INFO:tensorflow:  name = output_bias:0, shape = (2,)\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/metrics_impl.py:455: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.cast instead.\n","INFO:tensorflow:Done calling model_fn.\n","INFO:tensorflow:Starting evaluation at 2023-05-22T07:34:28Z\n","INFO:tensorflow:Graph was finalized.\n","2023-05-22 07:34:28.963130: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0\n","2023-05-22 07:34:28.963188: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2023-05-22 07:34:28.963204: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0 \n","2023-05-22 07:34:28.963214: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N \n","2023-05-22 07:34:28.963307: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14248 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use standard file APIs to check for files with this prefix.\n","INFO:tensorflow:Restoring parameters from /content/trained_output/model.ckpt-622\n","INFO:tensorflow:Running local_init_op.\n","INFO:tensorflow:Done running local_init_op.\n","INFO:tensorflow:Finished evaluation at 2023-05-22-07:34:29\n","INFO:tensorflow:Saving dict for global step 622: eval_accuracy = 0.6101083, eval_loss = 0.6598809, global_step = 622, loss = 0.65960556\n","INFO:tensorflow:Saving 'checkpoint_path' summary for global step 622: /content/trained_output/model.ckpt-622\n","INFO:tensorflow:evaluation_loop marked as finished\n","INFO:tensorflow:***** Eval results *****\n","INFO:tensorflow:  eval_accuracy = 0.6101083\n","INFO:tensorflow:  eval_loss = 0.6598809\n","INFO:tensorflow:  global_step = 622\n","INFO:tensorflow:  loss = 0.65960556\n"]}],"source":["%cd /content/drive/MyDrive/Code_pretrain\n","%pwd\n","%env BERT_BASE_DIR=uncased_L-4_H-256_A-4\n","%env GLUE_DIR=data\n","!rm -rf /content/trained_output\n","\n","!python3 run_classifier.py \\\n","  --task_name=RTE \\\n","  --do_train=true \\\n","  --do_eval=true \\\n","  --data_dir=$GLUE_DIR/RTE \\\n","  --vocab_file=$BERT_BASE_DIR/vocab.txt \\\n","  --bert_config_file=$BERT_BASE_DIR/bert_config.json \\\n","  --init_checkpoint=$BERT_BASE_DIR/bert_model.ckpt \\\n","  --max_seq_length=128 \\\n","  --train_batch_size=4 \\\n","  --learning_rate=2e-5 \\\n","  --num_train_epochs=1.0 \\\n","  --output_dir=/content/trained_output\n","\n","# result metric.\n","# INFO:tensorflow:  eval_accuracy = 0.59205776\n","# INFO:tensorflow:  eval_loss = 0.6777811\n","# INFO:tensorflow:  global_step = 622\n","# INFO:tensorflow:  loss = 0.6773494\n","\n","# INFO:tensorflow:  eval_accuracy = 0.6101083\n","# INFO:tensorflow:  eval_loss = 0.6598809\n","# INFO:tensorflow:  global_step = 622\n","# INFO:tensorflow:  loss = 0.65960556"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}