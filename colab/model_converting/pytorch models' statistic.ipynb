{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1AsAqT3zLO2tocu_Zi7J8J0RvupaElq1h","authorship_tag":"ABX9TyNmM5XqCCHtJ2xhrcpAd7T7"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["#BERT development praparation\n","BERT needs python3.6, tensorflow1.13.1, pytorch1.10.0, pytorch-transformers1.2.0 to run properly."],"metadata":{"id":"U3-jXGJtzL4A"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"KRadyDGiy7Vh","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1684718592832,"user_tz":-480,"elapsed":118320,"user":{"displayName":"Brian Shen","userId":"08246478872294528508"}},"outputId":"65e88976-60c3-43cc-e0ce-4a19443fed67"},"outputs":[{"output_type":"stream","name":"stdout","text":["Python 3.10.11\n","Reading package lists... Done\n","Building dependency tree       \n","Reading state information... Done\n","The following additional packages will be installed:\n","  libpython3.6-minimal libpython3.6-stdlib python3.6-minimal\n","Suggested packages:\n","  python3.6-venv binfmt-support\n","The following NEW packages will be installed:\n","  libpython3.6-minimal libpython3.6-stdlib python3.6 python3.6-minimal\n","0 upgraded, 4 newly installed, 0 to remove and 24 not upgraded.\n","Need to get 4,294 kB of archives.\n","After this operation, 22.1 MB of additional disk space will be used.\n","Get:1 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu focal/main amd64 libpython3.6-minimal amd64 3.6.15-1+focal3 [569 kB]\n","Get:2 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu focal/main amd64 python3.6-minimal amd64 3.6.15-1+focal3 [1,718 kB]\n","Get:3 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu focal/main amd64 libpython3.6-stdlib amd64 3.6.15-1+focal3 [1,758 kB]\n","Get:4 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu focal/main amd64 python3.6 amd64 3.6.15-1+focal3 [248 kB]\n","Fetched 4,294 kB in 0s (11.8 MB/s)\n","debconf: unable to initialize frontend: Dialog\n","debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 4.)\n","debconf: falling back to frontend: Readline\n","debconf: unable to initialize frontend: Readline\n","debconf: (This frontend requires a controlling tty.)\n","debconf: falling back to frontend: Teletype\n","dpkg-preconfigure: unable to re-open stdin: \n","Selecting previously unselected package libpython3.6-minimal:amd64.\n","(Reading database ... 122531 files and directories currently installed.)\n","Preparing to unpack .../libpython3.6-minimal_3.6.15-1+focal3_amd64.deb ...\n","Unpacking libpython3.6-minimal:amd64 (3.6.15-1+focal3) ...\n","Selecting previously unselected package python3.6-minimal.\n","Preparing to unpack .../python3.6-minimal_3.6.15-1+focal3_amd64.deb ...\n","Unpacking python3.6-minimal (3.6.15-1+focal3) ...\n","Selecting previously unselected package libpython3.6-stdlib:amd64.\n","Preparing to unpack .../libpython3.6-stdlib_3.6.15-1+focal3_amd64.deb ...\n","Unpacking libpython3.6-stdlib:amd64 (3.6.15-1+focal3) ...\n","Selecting previously unselected package python3.6.\n","Preparing to unpack .../python3.6_3.6.15-1+focal3_amd64.deb ...\n","Unpacking python3.6 (3.6.15-1+focal3) ...\n","Setting up libpython3.6-minimal:amd64 (3.6.15-1+focal3) ...\n","Setting up python3.6-minimal (3.6.15-1+focal3) ...\n","Setting up libpython3.6-stdlib:amd64 (3.6.15-1+focal3) ...\n","Setting up python3.6 (3.6.15-1+focal3) ...\n","Processing triggers for man-db (2.9.1-1) ...\n","Processing triggers for mime-support (3.64ubuntu1) ...\n","update-alternatives: using /usr/bin/python3.6 to provide /usr/bin/python3 (python3) in auto mode\n","Reading package lists... Done\n","Building dependency tree       \n","Reading state information... Done\n","The following additional packages will be installed:\n","  python3.6-lib2to3\n","The following NEW packages will be installed:\n","  python3.6-distutils python3.6-lib2to3\n","0 upgraded, 2 newly installed, 0 to remove and 24 not upgraded.\n","Need to get 308 kB of archives.\n","After this operation, 1,232 kB of additional disk space will be used.\n","Get:1 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu focal/main amd64 python3.6-lib2to3 all 3.6.15-1+focal3 [122 kB]\n","Get:2 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu focal/main amd64 python3.6-distutils all 3.6.15-1+focal3 [187 kB]\n","Fetched 308 kB in 0s (2,582 kB/s)\n","debconf: unable to initialize frontend: Dialog\n","debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 2.)\n","debconf: falling back to frontend: Readline\n","debconf: unable to initialize frontend: Readline\n","debconf: (This frontend requires a controlling tty.)\n","debconf: falling back to frontend: Teletype\n","dpkg-preconfigure: unable to re-open stdin: \n","Selecting previously unselected package python3.6-lib2to3.\n","(Reading database ... 123142 files and directories currently installed.)\n","Preparing to unpack .../python3.6-lib2to3_3.6.15-1+focal3_all.deb ...\n","Unpacking python3.6-lib2to3 (3.6.15-1+focal3) ...\n","Selecting previously unselected package python3.6-distutils.\n","Preparing to unpack .../python3.6-distutils_3.6.15-1+focal3_all.deb ...\n","Unpacking python3.6-distutils (3.6.15-1+focal3) ...\n","Setting up python3.6-lib2to3 (3.6.15-1+focal3) ...\n","Setting up python3.6-distutils (3.6.15-1+focal3) ...\n","Reading package lists... Done\n","Building dependency tree       \n","Reading state information... Done\n","The following additional packages will be installed:\n","  python-pip-whl python3-setuptools python3-wheel\n","Suggested packages:\n","  python-setuptools-doc\n","The following NEW packages will be installed:\n","  python-pip-whl python3-pip python3-setuptools python3-wheel\n","0 upgraded, 4 newly installed, 0 to remove and 24 not upgraded.\n","Need to get 2,389 kB of archives.\n","After this operation, 4,933 kB of additional disk space will be used.\n","Get:1 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 python-pip-whl all 20.0.2-5ubuntu1.8 [1,805 kB]\n","Get:2 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 python3-setuptools all 45.2.0-1ubuntu0.1 [330 kB]\n","Get:3 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 python3-wheel all 0.34.2-1ubuntu0.1 [23.9 kB]\n","Get:4 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 python3-pip all 20.0.2-5ubuntu1.8 [231 kB]\n","Fetched 2,389 kB in 1s (2,616 kB/s)\n","debconf: unable to initialize frontend: Dialog\n","debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 4.)\n","debconf: falling back to frontend: Readline\n","debconf: unable to initialize frontend: Readline\n","debconf: (This frontend requires a controlling tty.)\n","debconf: falling back to frontend: Teletype\n","dpkg-preconfigure: unable to re-open stdin: \n","Selecting previously unselected package python-pip-whl.\n","(Reading database ... 123281 files and directories currently installed.)\n","Preparing to unpack .../python-pip-whl_20.0.2-5ubuntu1.8_all.deb ...\n","Unpacking python-pip-whl (20.0.2-5ubuntu1.8) ...\n","Selecting previously unselected package python3-setuptools.\n","Preparing to unpack .../python3-setuptools_45.2.0-1ubuntu0.1_all.deb ...\n","Unpacking python3-setuptools (45.2.0-1ubuntu0.1) ...\n","Selecting previously unselected package python3-wheel.\n","Preparing to unpack .../python3-wheel_0.34.2-1ubuntu0.1_all.deb ...\n","Unpacking python3-wheel (0.34.2-1ubuntu0.1) ...\n","Selecting previously unselected package python3-pip.\n","Preparing to unpack .../python3-pip_20.0.2-5ubuntu1.8_all.deb ...\n","Unpacking python3-pip (20.0.2-5ubuntu1.8) ...\n","Setting up python3-setuptools (45.2.0-1ubuntu0.1) ...\n","Setting up python3-wheel (0.34.2-1ubuntu0.1) ...\n","Setting up python-pip-whl (20.0.2-5ubuntu1.8) ...\n","Setting up python3-pip (20.0.2-5ubuntu1.8) ...\n","Processing triggers for man-db (2.9.1-1) ...\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting pip\n","  Downloading pip-21.3.1-py3-none-any.whl (1.7 MB)\n","\u001b[K     |████████████████████████████████| 1.7 MB 11.3 MB/s \n","\u001b[?25hInstalling collected packages: pip\n","  Attempting uninstall: pip\n","    Found existing installation: pip 20.0.2\n","    Not uninstalling pip at /usr/lib/python3/dist-packages, outside environment /usr\n","    Can't uninstall 'pip'. No files were found to uninstall.\n","Successfully installed pip-21.3.1\n","Python 3.6.15\n","\u001b[33mWARNING: Skipping six as it is not installed.\u001b[0m\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting pytorch-transformers==1.2.0\n","  Downloading pytorch_transformers-1.2.0-py3-none-any.whl (176 kB)\n","     |████████████████████████████████| 176 kB 13.7 MB/s            \n","\u001b[?25hCollecting prettytable==2.5.0\n","  Downloading prettytable-2.5.0-py3-none-any.whl (24 kB)\n","Collecting boto3\n","  Downloading boto3-1.23.10-py3-none-any.whl (132 kB)\n","     |████████████████████████████████| 132 kB 79.1 MB/s            \n","\u001b[?25hCollecting numpy\n","  Downloading numpy-1.19.5-cp36-cp36m-manylinux2010_x86_64.whl (14.8 MB)\n","     |████████████████████████████████| 14.8 MB 62.3 MB/s            \n","\u001b[?25hCollecting torch>=1.0.0\n","  Downloading torch-1.10.2-cp36-cp36m-manylinux1_x86_64.whl (881.9 MB)\n","     |████████████████████████████████| 881.9 MB 12 kB/s              \n","\u001b[?25hCollecting sacremoses\n","  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n","     |████████████████████████████████| 880 kB 80.3 MB/s            \n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting regex\n","  Downloading regex-2023.5.5-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (756 kB)\n","     |████████████████████████████████| 756 kB 40.4 MB/s            \n","\u001b[?25hCollecting tqdm\n","  Downloading tqdm-4.64.1-py2.py3-none-any.whl (78 kB)\n","     |████████████████████████████████| 78 kB 7.8 MB/s             \n","\u001b[?25hCollecting requests\n","  Downloading requests-2.27.1-py2.py3-none-any.whl (63 kB)\n","     |████████████████████████████████| 63 kB 1.4 MB/s             \n","\u001b[?25hCollecting sentencepiece\n","  Downloading sentencepiece-0.1.99-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","     |████████████████████████████████| 1.3 MB 69.8 MB/s            \n","\u001b[?25hCollecting wcwidth\n","  Downloading wcwidth-0.2.6-py2.py3-none-any.whl (29 kB)\n","Collecting importlib-metadata\n","  Downloading importlib_metadata-4.8.3-py3-none-any.whl (17 kB)\n","Collecting dataclasses\n","  Downloading dataclasses-0.8-py3-none-any.whl (19 kB)\n","Collecting typing-extensions\n","  Downloading typing_extensions-4.1.1-py3-none-any.whl (26 kB)\n","Collecting botocore<1.27.0,>=1.26.10\n","  Downloading botocore-1.26.10-py3-none-any.whl (8.8 MB)\n","     |████████████████████████████████| 8.8 MB 72.3 MB/s            \n","\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1\n","  Downloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n","Collecting s3transfer<0.6.0,>=0.5.0\n","  Downloading s3transfer-0.5.2-py3-none-any.whl (79 kB)\n","     |████████████████████████████████| 79 kB 8.2 MB/s             \n","\u001b[?25hCollecting zipp>=0.5\n","  Downloading zipp-3.6.0-py3-none-any.whl (5.3 kB)\n","Collecting idna<4,>=2.5\n","  Downloading idna-3.4-py3-none-any.whl (61 kB)\n","     |████████████████████████████████| 61 kB 98 kB/s              \n","\u001b[?25hCollecting certifi>=2017.4.17\n","  Downloading certifi-2023.5.7-py3-none-any.whl (156 kB)\n","     |████████████████████████████████| 156 kB 55.6 MB/s            \n","\u001b[?25hCollecting charset-normalizer~=2.0.0\n","  Downloading charset_normalizer-2.0.12-py3-none-any.whl (39 kB)\n","Collecting urllib3<1.27,>=1.21.1\n","  Downloading urllib3-1.26.15-py2.py3-none-any.whl (140 kB)\n","     |████████████████████████████████| 140 kB 73.7 MB/s            \n","\u001b[?25hCollecting click\n","  Downloading click-8.0.4-py3-none-any.whl (97 kB)\n","     |████████████████████████████████| 97 kB 8.0 MB/s             \n","\u001b[?25hCollecting joblib\n","  Downloading joblib-1.1.1-py2.py3-none-any.whl (309 kB)\n","     |████████████████████████████████| 309 kB 73.3 MB/s            \n","\u001b[?25hCollecting six\n","  Downloading six-1.16.0-py2.py3-none-any.whl (11 kB)\n","Collecting importlib-resources\n","  Downloading importlib_resources-5.4.0-py3-none-any.whl (28 kB)\n","Collecting python-dateutil<3.0.0,>=2.1\n","  Downloading python_dateutil-2.8.2-py2.py3-none-any.whl (247 kB)\n","     |████████████████████████████████| 247 kB 68.8 MB/s            \n","\u001b[?25hBuilding wheels for collected packages: sacremoses\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895255 sha256=5e9b490b9f49f364fdeed4c09762d1466d0156c62f65c37b319f4e69de3e4126\n","  Stored in directory: /root/.cache/pip/wheels/4c/64/31/e9900a234b23fb3e9dc565d6114a9d6ff84a72dbdd356502b4\n","Successfully built sacremoses\n","Installing collected packages: six, zipp, urllib3, typing-extensions, python-dateutil, jmespath, importlib-resources, importlib-metadata, botocore, tqdm, s3transfer, regex, joblib, idna, dataclasses, click, charset-normalizer, certifi, wcwidth, torch, sentencepiece, sacremoses, requests, numpy, boto3, pytorch-transformers, prettytable\n","Successfully installed boto3-1.23.10 botocore-1.26.10 certifi-2023.5.7 charset-normalizer-2.0.12 click-8.0.4 dataclasses-0.8 idna-3.4 importlib-metadata-4.8.3 importlib-resources-5.4.0 jmespath-0.10.0 joblib-1.1.1 numpy-1.19.5 prettytable-2.5.0 python-dateutil-2.8.2 pytorch-transformers-1.2.0 regex-2023.5.5 requests-2.27.1 s3transfer-0.5.2 sacremoses-0.0.53 sentencepiece-0.1.99 six-1.16.0 torch-1.10.2 tqdm-4.64.1 typing-extensions-4.1.1 urllib3-1.26.15 wcwidth-0.2.6 zipp-3.6.0\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["dateutil","six","wcwidth"]}}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Python 3.6.15\n"]}],"source":["!python -V\n","!sudo apt-get install python3.6\n","!sudo update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.6 3\n","#!sudo update-alternatives --config python3\n","!sudo apt-get install python3.6-distutils\n","!sudo apt install python3-pip\n","!python -m pip install --upgrade pip\n","!python -V\n","!pip uninstall six -y\n","#!pip install tensorflow==1.11.0 pytorch-transformers==1.2.0\n","!pip install pytorch-transformers==1.2.0 prettytable==2.5.0\n","!python -V"]},{"cell_type":"markdown","source":["1.Download a BERT TF model. 2.Convert by pytorch_transformers library. 3.Tar outputs in a zip file and name it with a '_pytorch' surfix."],"metadata":{"id":"Zv4Li1r4zYsp"}},{"cell_type":"markdown","source":["Install Huawei OBSUtil to update converted pytorch model."],"metadata":{"id":"UizyzI3hzizw"}},{"cell_type":"code","source":["%cd /content/drive/MyDrive/Code_analysis\n","!wget https://obs-community-intl.obs.ap-southeast-1.myhuaweicloud.com/obsutil/current/obsutil_linux_amd64.tar.gz -P /content/drive/MyDrive/Code_analysis\n","!tar xvf obsutil_linux_amd64.tar.gz\n","!chmod 777 obsutil_linux_amd64_5.4.11/obsutil\n","!mv obsutil_linux_amd64_5.4.11/obsutil /bin/\n","!rm -rf /content/drive/MyDrive/Code_analysis/obsutil_linux_amd64_5.4.11"],"metadata":{"id":"cYlELJPazhBf","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1684720425942,"user_tz":-480,"elapsed":4047,"user":{"displayName":"Brian Shen","userId":"08246478872294528508"}},"outputId":"1c508f25-f0a3-4628-b1c0-7d53dec62a61"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Code_analysis\n","--2023-05-22 01:53:41--  https://obs-community-intl.obs.ap-southeast-1.myhuaweicloud.com/obsutil/current/obsutil_linux_amd64.tar.gz\n","Resolving obs-community-intl.obs.ap-southeast-1.myhuaweicloud.com (obs-community-intl.obs.ap-southeast-1.myhuaweicloud.com)... 27.126.206.60\n","Connecting to obs-community-intl.obs.ap-southeast-1.myhuaweicloud.com (obs-community-intl.obs.ap-southeast-1.myhuaweicloud.com)|27.126.206.60|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 3646148 (3.5M) [application/gzip]\n","Saving to: ‘/content/drive/MyDrive/Code_analysis/obsutil_linux_amd64.tar.gz’\n","\n","obsutil_linux_amd64 100%[===================>]   3.48M  2.03MB/s    in 1.7s    \n","\n","2023-05-22 01:53:44 (2.03 MB/s) - ‘/content/drive/MyDrive/Code_analysis/obsutil_linux_amd64.tar.gz’ saved [3646148/3646148]\n","\n","obsutil_linux_amd64_5.4.11/\n","obsutil_linux_amd64_5.4.11/setup.sh\n","obsutil_linux_amd64_5.4.11/obsutil\n"]}]},{"cell_type":"markdown","source":["#BERTs"],"metadata":{"id":"mrpPxopPSPJi"}},{"cell_type":"code","source":["%cd /content/drive/MyDrive/Code_analysis\n","!wget https://transformers-models.obs.cn-north-4.myhuaweicloud.com/bert/cn/pretrain/pt/roberta_36L.zip\n","!unzip roberta_36L.zip"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JZU118Vgv9ab","executionInfo":{"status":"ok","timestamp":1684718768352,"user_tz":-480,"elapsed":175531,"user":{"displayName":"Brian Shen","userId":"08246478872294528508"}},"outputId":"3ceb6bbf-bc08-4617-aa60-863165f3c665"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Code_analysis\n","--2023-05-22 01:23:12--  https://transformers-models.obs.cn-north-4.myhuaweicloud.com/bert/cn/pretrain/pt/roberta_36L.zip\n","Resolving transformers-models.obs.cn-north-4.myhuaweicloud.com (transformers-models.obs.cn-north-4.myhuaweicloud.com)... 121.36.121.226, 121.36.121.227\n","Connecting to transformers-models.obs.cn-north-4.myhuaweicloud.com (transformers-models.obs.cn-north-4.myhuaweicloud.com)|121.36.121.226|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 1771095718 (1.6G) [application/zip]\n","Saving to: ‘roberta_36L.zip’\n","\n","roberta_36L.zip     100%[===================>]   1.65G  12.8MB/s    in 2m 7s   \n","\n","2023-05-22 01:25:19 (13.3 MB/s) - ‘roberta_36L.zip’ saved [1771095718/1771095718]\n","\n","Archive:  roberta_36L.zip\n","   creating: roberta_36L/\n","  inflating: roberta_36L/config.json  \n","  inflating: roberta_36L/training_args.bin  \n","  inflating: roberta_36L/vocab.txt   \n","  inflating: roberta_36L/pytorch_model.bin  \n"]}]},{"cell_type":"code","source":["#!zip -r roberta_night-king_L-36_H-1024_A-16_cn.zip roberta_night-king_L-36_H-1024_A-16_cn/\n","!obsutil cp roberta_night-king_L-36_H-1024_A-16_cn.zip obs://transformers-models/bert/cn/pretrain/pt/"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aaQrJCAUzs7B","executionInfo":{"status":"ok","timestamp":1684720509659,"user_tz":-480,"elapsed":35031,"user":{"displayName":"Brian Shen","userId":"08246478872294528508"}},"outputId":"51f34ba7-a60b-49bc-abba-febd4d0deadc"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Start at 2023-05-22 01:54:34.581733871 +0000 UTC\n","\n","\n","Parallel:      5                   Jobs:          5                   \n","Threshold:     50.00MB             PartSize:      auto                \n","VerifyLength:  false               VerifyMd5:     false               \n","CheckpointDir: /root/.obsutil_checkpoint     \n","\n","\u001b[37m\u001b[0m\u001b[37m\u001b[0m\n","Waiting for the uploaded key to be completed on server side.\n","\n","\n","Upload successfully, 1.65GB, n/a, /content/drive/MyDrive/Code_analysis/roberta_night-king_L-36_H-1024_A-16_cn.zip --> obs://transformers-models/bert/cn/pretrain/pt/roberta_night-king_L-36_H-1024_A-16_cn.zip, cost [32777], status [200], request id [00000188412ADE17EBA46B1471EDCEE2]\n"]}]},{"cell_type":"markdown","source":["#Model Comparison\n"],"metadata":{"id":"l8DHcHs4B3Di"}},{"cell_type":"code","source":["%cd /content/drive/MyDrive/Code_analysis\n","%env BERT_BASE_DIR=roberta_L-12_H-768_A-12_cn\n","%env TO_BERT_BASE_DIR=chinese_L-12_H-768_A-12\n","!python compare.py $BERT_BASE_DIR $TO_BERT_BASE_DIR"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CD9u2OoeB6CB","executionInfo":{"status":"ok","timestamp":1684674808890,"user_tz":-480,"elapsed":8360,"user":{"displayName":"Brian Shen","userId":"08246478872294528508"}},"outputId":"3e95b664-2b27-4d3e-8c5f-01547b740124"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Code_analysis\n","env: BERT_BASE_DIR=roberta_L-12_H-768_A-12_cn\n","env: TO_BERT_BASE_DIR=chinese_L-12_H-768_A-12\n","Models are different.\n"]}]},{"cell_type":"markdown","source":["#Parameter Count\n","Count the size of models."],"metadata":{"id":"vrZxJoh8IjJd"}},{"cell_type":"code","source":["%env BERT_BASE_DIR=roberta_36L\n","#!cp $BERT_BASE_DIR/bert_config.json $BERT_BASE_DIR/config.json\n","!python count.py $BERT_BASE_DIR"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EMqGirCcI0QB","executionInfo":{"status":"ok","timestamp":1684718828184,"user_tz":-480,"elapsed":39173,"user":{"displayName":"Brian Shen","userId":"08246478872294528508"}},"outputId":"edc77f61-eca1-4d33-c3dd-08f474892001"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["env: BERT_BASE_DIR=roberta_36L\n","TOTAL SIZE:476.67712M\n","+----------------------------------------------------+------------+\n","|                      Modules                       | Parameters |\n","+----------------------------------------------------+------------+\n","|         embeddings.word_embeddings.weight          |  21635072  |\n","|       embeddings.position_embeddings.weight        |   524288   |\n","|      embeddings.token_type_embeddings.weight       |    2048    |\n","|            embeddings.LayerNorm.weight             |    1024    |\n","|             embeddings.LayerNorm.bias              |    1024    |\n","|    encoder.layer.0.attention.self.query.weight     |  1048576   |\n","|     encoder.layer.0.attention.self.query.bias      |    1024    |\n","|     encoder.layer.0.attention.self.key.weight      |  1048576   |\n","|      encoder.layer.0.attention.self.key.bias       |    1024    |\n","|    encoder.layer.0.attention.self.value.weight     |  1048576   |\n","|     encoder.layer.0.attention.self.value.bias      |    1024    |\n","|   encoder.layer.0.attention.output.dense.weight    |  1048576   |\n","|    encoder.layer.0.attention.output.dense.bias     |    1024    |\n","| encoder.layer.0.attention.output.LayerNorm.weight  |    1024    |\n","|  encoder.layer.0.attention.output.LayerNorm.bias   |    1024    |\n","|     encoder.layer.0.intermediate.dense.weight      |  4194304   |\n","|      encoder.layer.0.intermediate.dense.bias       |    4096    |\n","|        encoder.layer.0.output.dense.weight         |  4194304   |\n","|         encoder.layer.0.output.dense.bias          |    1024    |\n","|      encoder.layer.0.output.LayerNorm.weight       |    1024    |\n","|       encoder.layer.0.output.LayerNorm.bias        |    1024    |\n","|    encoder.layer.1.attention.self.query.weight     |  1048576   |\n","|     encoder.layer.1.attention.self.query.bias      |    1024    |\n","|     encoder.layer.1.attention.self.key.weight      |  1048576   |\n","|      encoder.layer.1.attention.self.key.bias       |    1024    |\n","|    encoder.layer.1.attention.self.value.weight     |  1048576   |\n","|     encoder.layer.1.attention.self.value.bias      |    1024    |\n","|   encoder.layer.1.attention.output.dense.weight    |  1048576   |\n","|    encoder.layer.1.attention.output.dense.bias     |    1024    |\n","| encoder.layer.1.attention.output.LayerNorm.weight  |    1024    |\n","|  encoder.layer.1.attention.output.LayerNorm.bias   |    1024    |\n","|     encoder.layer.1.intermediate.dense.weight      |  4194304   |\n","|      encoder.layer.1.intermediate.dense.bias       |    4096    |\n","|        encoder.layer.1.output.dense.weight         |  4194304   |\n","|         encoder.layer.1.output.dense.bias          |    1024    |\n","|      encoder.layer.1.output.LayerNorm.weight       |    1024    |\n","|       encoder.layer.1.output.LayerNorm.bias        |    1024    |\n","|    encoder.layer.2.attention.self.query.weight     |  1048576   |\n","|     encoder.layer.2.attention.self.query.bias      |    1024    |\n","|     encoder.layer.2.attention.self.key.weight      |  1048576   |\n","|      encoder.layer.2.attention.self.key.bias       |    1024    |\n","|    encoder.layer.2.attention.self.value.weight     |  1048576   |\n","|     encoder.layer.2.attention.self.value.bias      |    1024    |\n","|   encoder.layer.2.attention.output.dense.weight    |  1048576   |\n","|    encoder.layer.2.attention.output.dense.bias     |    1024    |\n","| encoder.layer.2.attention.output.LayerNorm.weight  |    1024    |\n","|  encoder.layer.2.attention.output.LayerNorm.bias   |    1024    |\n","|     encoder.layer.2.intermediate.dense.weight      |  4194304   |\n","|      encoder.layer.2.intermediate.dense.bias       |    4096    |\n","|        encoder.layer.2.output.dense.weight         |  4194304   |\n","|         encoder.layer.2.output.dense.bias          |    1024    |\n","|      encoder.layer.2.output.LayerNorm.weight       |    1024    |\n","|       encoder.layer.2.output.LayerNorm.bias        |    1024    |\n","|    encoder.layer.3.attention.self.query.weight     |  1048576   |\n","|     encoder.layer.3.attention.self.query.bias      |    1024    |\n","|     encoder.layer.3.attention.self.key.weight      |  1048576   |\n","|      encoder.layer.3.attention.self.key.bias       |    1024    |\n","|    encoder.layer.3.attention.self.value.weight     |  1048576   |\n","|     encoder.layer.3.attention.self.value.bias      |    1024    |\n","|   encoder.layer.3.attention.output.dense.weight    |  1048576   |\n","|    encoder.layer.3.attention.output.dense.bias     |    1024    |\n","| encoder.layer.3.attention.output.LayerNorm.weight  |    1024    |\n","|  encoder.layer.3.attention.output.LayerNorm.bias   |    1024    |\n","|     encoder.layer.3.intermediate.dense.weight      |  4194304   |\n","|      encoder.layer.3.intermediate.dense.bias       |    4096    |\n","|        encoder.layer.3.output.dense.weight         |  4194304   |\n","|         encoder.layer.3.output.dense.bias          |    1024    |\n","|      encoder.layer.3.output.LayerNorm.weight       |    1024    |\n","|       encoder.layer.3.output.LayerNorm.bias        |    1024    |\n","|    encoder.layer.4.attention.self.query.weight     |  1048576   |\n","|     encoder.layer.4.attention.self.query.bias      |    1024    |\n","|     encoder.layer.4.attention.self.key.weight      |  1048576   |\n","|      encoder.layer.4.attention.self.key.bias       |    1024    |\n","|    encoder.layer.4.attention.self.value.weight     |  1048576   |\n","|     encoder.layer.4.attention.self.value.bias      |    1024    |\n","|   encoder.layer.4.attention.output.dense.weight    |  1048576   |\n","|    encoder.layer.4.attention.output.dense.bias     |    1024    |\n","| encoder.layer.4.attention.output.LayerNorm.weight  |    1024    |\n","|  encoder.layer.4.attention.output.LayerNorm.bias   |    1024    |\n","|     encoder.layer.4.intermediate.dense.weight      |  4194304   |\n","|      encoder.layer.4.intermediate.dense.bias       |    4096    |\n","|        encoder.layer.4.output.dense.weight         |  4194304   |\n","|         encoder.layer.4.output.dense.bias          |    1024    |\n","|      encoder.layer.4.output.LayerNorm.weight       |    1024    |\n","|       encoder.layer.4.output.LayerNorm.bias        |    1024    |\n","|    encoder.layer.5.attention.self.query.weight     |  1048576   |\n","|     encoder.layer.5.attention.self.query.bias      |    1024    |\n","|     encoder.layer.5.attention.self.key.weight      |  1048576   |\n","|      encoder.layer.5.attention.self.key.bias       |    1024    |\n","|    encoder.layer.5.attention.self.value.weight     |  1048576   |\n","|     encoder.layer.5.attention.self.value.bias      |    1024    |\n","|   encoder.layer.5.attention.output.dense.weight    |  1048576   |\n","|    encoder.layer.5.attention.output.dense.bias     |    1024    |\n","| encoder.layer.5.attention.output.LayerNorm.weight  |    1024    |\n","|  encoder.layer.5.attention.output.LayerNorm.bias   |    1024    |\n","|     encoder.layer.5.intermediate.dense.weight      |  4194304   |\n","|      encoder.layer.5.intermediate.dense.bias       |    4096    |\n","|        encoder.layer.5.output.dense.weight         |  4194304   |\n","|         encoder.layer.5.output.dense.bias          |    1024    |\n","|      encoder.layer.5.output.LayerNorm.weight       |    1024    |\n","|       encoder.layer.5.output.LayerNorm.bias        |    1024    |\n","|    encoder.layer.6.attention.self.query.weight     |  1048576   |\n","|     encoder.layer.6.attention.self.query.bias      |    1024    |\n","|     encoder.layer.6.attention.self.key.weight      |  1048576   |\n","|      encoder.layer.6.attention.self.key.bias       |    1024    |\n","|    encoder.layer.6.attention.self.value.weight     |  1048576   |\n","|     encoder.layer.6.attention.self.value.bias      |    1024    |\n","|   encoder.layer.6.attention.output.dense.weight    |  1048576   |\n","|    encoder.layer.6.attention.output.dense.bias     |    1024    |\n","| encoder.layer.6.attention.output.LayerNorm.weight  |    1024    |\n","|  encoder.layer.6.attention.output.LayerNorm.bias   |    1024    |\n","|     encoder.layer.6.intermediate.dense.weight      |  4194304   |\n","|      encoder.layer.6.intermediate.dense.bias       |    4096    |\n","|        encoder.layer.6.output.dense.weight         |  4194304   |\n","|         encoder.layer.6.output.dense.bias          |    1024    |\n","|      encoder.layer.6.output.LayerNorm.weight       |    1024    |\n","|       encoder.layer.6.output.LayerNorm.bias        |    1024    |\n","|    encoder.layer.7.attention.self.query.weight     |  1048576   |\n","|     encoder.layer.7.attention.self.query.bias      |    1024    |\n","|     encoder.layer.7.attention.self.key.weight      |  1048576   |\n","|      encoder.layer.7.attention.self.key.bias       |    1024    |\n","|    encoder.layer.7.attention.self.value.weight     |  1048576   |\n","|     encoder.layer.7.attention.self.value.bias      |    1024    |\n","|   encoder.layer.7.attention.output.dense.weight    |  1048576   |\n","|    encoder.layer.7.attention.output.dense.bias     |    1024    |\n","| encoder.layer.7.attention.output.LayerNorm.weight  |    1024    |\n","|  encoder.layer.7.attention.output.LayerNorm.bias   |    1024    |\n","|     encoder.layer.7.intermediate.dense.weight      |  4194304   |\n","|      encoder.layer.7.intermediate.dense.bias       |    4096    |\n","|        encoder.layer.7.output.dense.weight         |  4194304   |\n","|         encoder.layer.7.output.dense.bias          |    1024    |\n","|      encoder.layer.7.output.LayerNorm.weight       |    1024    |\n","|       encoder.layer.7.output.LayerNorm.bias        |    1024    |\n","|    encoder.layer.8.attention.self.query.weight     |  1048576   |\n","|     encoder.layer.8.attention.self.query.bias      |    1024    |\n","|     encoder.layer.8.attention.self.key.weight      |  1048576   |\n","|      encoder.layer.8.attention.self.key.bias       |    1024    |\n","|    encoder.layer.8.attention.self.value.weight     |  1048576   |\n","|     encoder.layer.8.attention.self.value.bias      |    1024    |\n","|   encoder.layer.8.attention.output.dense.weight    |  1048576   |\n","|    encoder.layer.8.attention.output.dense.bias     |    1024    |\n","| encoder.layer.8.attention.output.LayerNorm.weight  |    1024    |\n","|  encoder.layer.8.attention.output.LayerNorm.bias   |    1024    |\n","|     encoder.layer.8.intermediate.dense.weight      |  4194304   |\n","|      encoder.layer.8.intermediate.dense.bias       |    4096    |\n","|        encoder.layer.8.output.dense.weight         |  4194304   |\n","|         encoder.layer.8.output.dense.bias          |    1024    |\n","|      encoder.layer.8.output.LayerNorm.weight       |    1024    |\n","|       encoder.layer.8.output.LayerNorm.bias        |    1024    |\n","|    encoder.layer.9.attention.self.query.weight     |  1048576   |\n","|     encoder.layer.9.attention.self.query.bias      |    1024    |\n","|     encoder.layer.9.attention.self.key.weight      |  1048576   |\n","|      encoder.layer.9.attention.self.key.bias       |    1024    |\n","|    encoder.layer.9.attention.self.value.weight     |  1048576   |\n","|     encoder.layer.9.attention.self.value.bias      |    1024    |\n","|   encoder.layer.9.attention.output.dense.weight    |  1048576   |\n","|    encoder.layer.9.attention.output.dense.bias     |    1024    |\n","| encoder.layer.9.attention.output.LayerNorm.weight  |    1024    |\n","|  encoder.layer.9.attention.output.LayerNorm.bias   |    1024    |\n","|     encoder.layer.9.intermediate.dense.weight      |  4194304   |\n","|      encoder.layer.9.intermediate.dense.bias       |    4096    |\n","|        encoder.layer.9.output.dense.weight         |  4194304   |\n","|         encoder.layer.9.output.dense.bias          |    1024    |\n","|      encoder.layer.9.output.LayerNorm.weight       |    1024    |\n","|       encoder.layer.9.output.LayerNorm.bias        |    1024    |\n","|    encoder.layer.10.attention.self.query.weight    |  1048576   |\n","|     encoder.layer.10.attention.self.query.bias     |    1024    |\n","|     encoder.layer.10.attention.self.key.weight     |  1048576   |\n","|      encoder.layer.10.attention.self.key.bias      |    1024    |\n","|    encoder.layer.10.attention.self.value.weight    |  1048576   |\n","|     encoder.layer.10.attention.self.value.bias     |    1024    |\n","|   encoder.layer.10.attention.output.dense.weight   |  1048576   |\n","|    encoder.layer.10.attention.output.dense.bias    |    1024    |\n","| encoder.layer.10.attention.output.LayerNorm.weight |    1024    |\n","|  encoder.layer.10.attention.output.LayerNorm.bias  |    1024    |\n","|     encoder.layer.10.intermediate.dense.weight     |  4194304   |\n","|      encoder.layer.10.intermediate.dense.bias      |    4096    |\n","|        encoder.layer.10.output.dense.weight        |  4194304   |\n","|         encoder.layer.10.output.dense.bias         |    1024    |\n","|      encoder.layer.10.output.LayerNorm.weight      |    1024    |\n","|       encoder.layer.10.output.LayerNorm.bias       |    1024    |\n","|    encoder.layer.11.attention.self.query.weight    |  1048576   |\n","|     encoder.layer.11.attention.self.query.bias     |    1024    |\n","|     encoder.layer.11.attention.self.key.weight     |  1048576   |\n","|      encoder.layer.11.attention.self.key.bias      |    1024    |\n","|    encoder.layer.11.attention.self.value.weight    |  1048576   |\n","|     encoder.layer.11.attention.self.value.bias     |    1024    |\n","|   encoder.layer.11.attention.output.dense.weight   |  1048576   |\n","|    encoder.layer.11.attention.output.dense.bias    |    1024    |\n","| encoder.layer.11.attention.output.LayerNorm.weight |    1024    |\n","|  encoder.layer.11.attention.output.LayerNorm.bias  |    1024    |\n","|     encoder.layer.11.intermediate.dense.weight     |  4194304   |\n","|      encoder.layer.11.intermediate.dense.bias      |    4096    |\n","|        encoder.layer.11.output.dense.weight        |  4194304   |\n","|         encoder.layer.11.output.dense.bias         |    1024    |\n","|      encoder.layer.11.output.LayerNorm.weight      |    1024    |\n","|       encoder.layer.11.output.LayerNorm.bias       |    1024    |\n","|    encoder.layer.12.attention.self.query.weight    |  1048576   |\n","|     encoder.layer.12.attention.self.query.bias     |    1024    |\n","|     encoder.layer.12.attention.self.key.weight     |  1048576   |\n","|      encoder.layer.12.attention.self.key.bias      |    1024    |\n","|    encoder.layer.12.attention.self.value.weight    |  1048576   |\n","|     encoder.layer.12.attention.self.value.bias     |    1024    |\n","|   encoder.layer.12.attention.output.dense.weight   |  1048576   |\n","|    encoder.layer.12.attention.output.dense.bias    |    1024    |\n","| encoder.layer.12.attention.output.LayerNorm.weight |    1024    |\n","|  encoder.layer.12.attention.output.LayerNorm.bias  |    1024    |\n","|     encoder.layer.12.intermediate.dense.weight     |  4194304   |\n","|      encoder.layer.12.intermediate.dense.bias      |    4096    |\n","|        encoder.layer.12.output.dense.weight        |  4194304   |\n","|         encoder.layer.12.output.dense.bias         |    1024    |\n","|      encoder.layer.12.output.LayerNorm.weight      |    1024    |\n","|       encoder.layer.12.output.LayerNorm.bias       |    1024    |\n","|    encoder.layer.13.attention.self.query.weight    |  1048576   |\n","|     encoder.layer.13.attention.self.query.bias     |    1024    |\n","|     encoder.layer.13.attention.self.key.weight     |  1048576   |\n","|      encoder.layer.13.attention.self.key.bias      |    1024    |\n","|    encoder.layer.13.attention.self.value.weight    |  1048576   |\n","|     encoder.layer.13.attention.self.value.bias     |    1024    |\n","|   encoder.layer.13.attention.output.dense.weight   |  1048576   |\n","|    encoder.layer.13.attention.output.dense.bias    |    1024    |\n","| encoder.layer.13.attention.output.LayerNorm.weight |    1024    |\n","|  encoder.layer.13.attention.output.LayerNorm.bias  |    1024    |\n","|     encoder.layer.13.intermediate.dense.weight     |  4194304   |\n","|      encoder.layer.13.intermediate.dense.bias      |    4096    |\n","|        encoder.layer.13.output.dense.weight        |  4194304   |\n","|         encoder.layer.13.output.dense.bias         |    1024    |\n","|      encoder.layer.13.output.LayerNorm.weight      |    1024    |\n","|       encoder.layer.13.output.LayerNorm.bias       |    1024    |\n","|    encoder.layer.14.attention.self.query.weight    |  1048576   |\n","|     encoder.layer.14.attention.self.query.bias     |    1024    |\n","|     encoder.layer.14.attention.self.key.weight     |  1048576   |\n","|      encoder.layer.14.attention.self.key.bias      |    1024    |\n","|    encoder.layer.14.attention.self.value.weight    |  1048576   |\n","|     encoder.layer.14.attention.self.value.bias     |    1024    |\n","|   encoder.layer.14.attention.output.dense.weight   |  1048576   |\n","|    encoder.layer.14.attention.output.dense.bias    |    1024    |\n","| encoder.layer.14.attention.output.LayerNorm.weight |    1024    |\n","|  encoder.layer.14.attention.output.LayerNorm.bias  |    1024    |\n","|     encoder.layer.14.intermediate.dense.weight     |  4194304   |\n","|      encoder.layer.14.intermediate.dense.bias      |    4096    |\n","|        encoder.layer.14.output.dense.weight        |  4194304   |\n","|         encoder.layer.14.output.dense.bias         |    1024    |\n","|      encoder.layer.14.output.LayerNorm.weight      |    1024    |\n","|       encoder.layer.14.output.LayerNorm.bias       |    1024    |\n","|    encoder.layer.15.attention.self.query.weight    |  1048576   |\n","|     encoder.layer.15.attention.self.query.bias     |    1024    |\n","|     encoder.layer.15.attention.self.key.weight     |  1048576   |\n","|      encoder.layer.15.attention.self.key.bias      |    1024    |\n","|    encoder.layer.15.attention.self.value.weight    |  1048576   |\n","|     encoder.layer.15.attention.self.value.bias     |    1024    |\n","|   encoder.layer.15.attention.output.dense.weight   |  1048576   |\n","|    encoder.layer.15.attention.output.dense.bias    |    1024    |\n","| encoder.layer.15.attention.output.LayerNorm.weight |    1024    |\n","|  encoder.layer.15.attention.output.LayerNorm.bias  |    1024    |\n","|     encoder.layer.15.intermediate.dense.weight     |  4194304   |\n","|      encoder.layer.15.intermediate.dense.bias      |    4096    |\n","|        encoder.layer.15.output.dense.weight        |  4194304   |\n","|         encoder.layer.15.output.dense.bias         |    1024    |\n","|      encoder.layer.15.output.LayerNorm.weight      |    1024    |\n","|       encoder.layer.15.output.LayerNorm.bias       |    1024    |\n","|    encoder.layer.16.attention.self.query.weight    |  1048576   |\n","|     encoder.layer.16.attention.self.query.bias     |    1024    |\n","|     encoder.layer.16.attention.self.key.weight     |  1048576   |\n","|      encoder.layer.16.attention.self.key.bias      |    1024    |\n","|    encoder.layer.16.attention.self.value.weight    |  1048576   |\n","|     encoder.layer.16.attention.self.value.bias     |    1024    |\n","|   encoder.layer.16.attention.output.dense.weight   |  1048576   |\n","|    encoder.layer.16.attention.output.dense.bias    |    1024    |\n","| encoder.layer.16.attention.output.LayerNorm.weight |    1024    |\n","|  encoder.layer.16.attention.output.LayerNorm.bias  |    1024    |\n","|     encoder.layer.16.intermediate.dense.weight     |  4194304   |\n","|      encoder.layer.16.intermediate.dense.bias      |    4096    |\n","|        encoder.layer.16.output.dense.weight        |  4194304   |\n","|         encoder.layer.16.output.dense.bias         |    1024    |\n","|      encoder.layer.16.output.LayerNorm.weight      |    1024    |\n","|       encoder.layer.16.output.LayerNorm.bias       |    1024    |\n","|    encoder.layer.17.attention.self.query.weight    |  1048576   |\n","|     encoder.layer.17.attention.self.query.bias     |    1024    |\n","|     encoder.layer.17.attention.self.key.weight     |  1048576   |\n","|      encoder.layer.17.attention.self.key.bias      |    1024    |\n","|    encoder.layer.17.attention.self.value.weight    |  1048576   |\n","|     encoder.layer.17.attention.self.value.bias     |    1024    |\n","|   encoder.layer.17.attention.output.dense.weight   |  1048576   |\n","|    encoder.layer.17.attention.output.dense.bias    |    1024    |\n","| encoder.layer.17.attention.output.LayerNorm.weight |    1024    |\n","|  encoder.layer.17.attention.output.LayerNorm.bias  |    1024    |\n","|     encoder.layer.17.intermediate.dense.weight     |  4194304   |\n","|      encoder.layer.17.intermediate.dense.bias      |    4096    |\n","|        encoder.layer.17.output.dense.weight        |  4194304   |\n","|         encoder.layer.17.output.dense.bias         |    1024    |\n","|      encoder.layer.17.output.LayerNorm.weight      |    1024    |\n","|       encoder.layer.17.output.LayerNorm.bias       |    1024    |\n","|    encoder.layer.18.attention.self.query.weight    |  1048576   |\n","|     encoder.layer.18.attention.self.query.bias     |    1024    |\n","|     encoder.layer.18.attention.self.key.weight     |  1048576   |\n","|      encoder.layer.18.attention.self.key.bias      |    1024    |\n","|    encoder.layer.18.attention.self.value.weight    |  1048576   |\n","|     encoder.layer.18.attention.self.value.bias     |    1024    |\n","|   encoder.layer.18.attention.output.dense.weight   |  1048576   |\n","|    encoder.layer.18.attention.output.dense.bias    |    1024    |\n","| encoder.layer.18.attention.output.LayerNorm.weight |    1024    |\n","|  encoder.layer.18.attention.output.LayerNorm.bias  |    1024    |\n","|     encoder.layer.18.intermediate.dense.weight     |  4194304   |\n","|      encoder.layer.18.intermediate.dense.bias      |    4096    |\n","|        encoder.layer.18.output.dense.weight        |  4194304   |\n","|         encoder.layer.18.output.dense.bias         |    1024    |\n","|      encoder.layer.18.output.LayerNorm.weight      |    1024    |\n","|       encoder.layer.18.output.LayerNorm.bias       |    1024    |\n","|    encoder.layer.19.attention.self.query.weight    |  1048576   |\n","|     encoder.layer.19.attention.self.query.bias     |    1024    |\n","|     encoder.layer.19.attention.self.key.weight     |  1048576   |\n","|      encoder.layer.19.attention.self.key.bias      |    1024    |\n","|    encoder.layer.19.attention.self.value.weight    |  1048576   |\n","|     encoder.layer.19.attention.self.value.bias     |    1024    |\n","|   encoder.layer.19.attention.output.dense.weight   |  1048576   |\n","|    encoder.layer.19.attention.output.dense.bias    |    1024    |\n","| encoder.layer.19.attention.output.LayerNorm.weight |    1024    |\n","|  encoder.layer.19.attention.output.LayerNorm.bias  |    1024    |\n","|     encoder.layer.19.intermediate.dense.weight     |  4194304   |\n","|      encoder.layer.19.intermediate.dense.bias      |    4096    |\n","|        encoder.layer.19.output.dense.weight        |  4194304   |\n","|         encoder.layer.19.output.dense.bias         |    1024    |\n","|      encoder.layer.19.output.LayerNorm.weight      |    1024    |\n","|       encoder.layer.19.output.LayerNorm.bias       |    1024    |\n","|    encoder.layer.20.attention.self.query.weight    |  1048576   |\n","|     encoder.layer.20.attention.self.query.bias     |    1024    |\n","|     encoder.layer.20.attention.self.key.weight     |  1048576   |\n","|      encoder.layer.20.attention.self.key.bias      |    1024    |\n","|    encoder.layer.20.attention.self.value.weight    |  1048576   |\n","|     encoder.layer.20.attention.self.value.bias     |    1024    |\n","|   encoder.layer.20.attention.output.dense.weight   |  1048576   |\n","|    encoder.layer.20.attention.output.dense.bias    |    1024    |\n","| encoder.layer.20.attention.output.LayerNorm.weight |    1024    |\n","|  encoder.layer.20.attention.output.LayerNorm.bias  |    1024    |\n","|     encoder.layer.20.intermediate.dense.weight     |  4194304   |\n","|      encoder.layer.20.intermediate.dense.bias      |    4096    |\n","|        encoder.layer.20.output.dense.weight        |  4194304   |\n","|         encoder.layer.20.output.dense.bias         |    1024    |\n","|      encoder.layer.20.output.LayerNorm.weight      |    1024    |\n","|       encoder.layer.20.output.LayerNorm.bias       |    1024    |\n","|    encoder.layer.21.attention.self.query.weight    |  1048576   |\n","|     encoder.layer.21.attention.self.query.bias     |    1024    |\n","|     encoder.layer.21.attention.self.key.weight     |  1048576   |\n","|      encoder.layer.21.attention.self.key.bias      |    1024    |\n","|    encoder.layer.21.attention.self.value.weight    |  1048576   |\n","|     encoder.layer.21.attention.self.value.bias     |    1024    |\n","|   encoder.layer.21.attention.output.dense.weight   |  1048576   |\n","|    encoder.layer.21.attention.output.dense.bias    |    1024    |\n","| encoder.layer.21.attention.output.LayerNorm.weight |    1024    |\n","|  encoder.layer.21.attention.output.LayerNorm.bias  |    1024    |\n","|     encoder.layer.21.intermediate.dense.weight     |  4194304   |\n","|      encoder.layer.21.intermediate.dense.bias      |    4096    |\n","|        encoder.layer.21.output.dense.weight        |  4194304   |\n","|         encoder.layer.21.output.dense.bias         |    1024    |\n","|      encoder.layer.21.output.LayerNorm.weight      |    1024    |\n","|       encoder.layer.21.output.LayerNorm.bias       |    1024    |\n","|    encoder.layer.22.attention.self.query.weight    |  1048576   |\n","|     encoder.layer.22.attention.self.query.bias     |    1024    |\n","|     encoder.layer.22.attention.self.key.weight     |  1048576   |\n","|      encoder.layer.22.attention.self.key.bias      |    1024    |\n","|    encoder.layer.22.attention.self.value.weight    |  1048576   |\n","|     encoder.layer.22.attention.self.value.bias     |    1024    |\n","|   encoder.layer.22.attention.output.dense.weight   |  1048576   |\n","|    encoder.layer.22.attention.output.dense.bias    |    1024    |\n","| encoder.layer.22.attention.output.LayerNorm.weight |    1024    |\n","|  encoder.layer.22.attention.output.LayerNorm.bias  |    1024    |\n","|     encoder.layer.22.intermediate.dense.weight     |  4194304   |\n","|      encoder.layer.22.intermediate.dense.bias      |    4096    |\n","|        encoder.layer.22.output.dense.weight        |  4194304   |\n","|         encoder.layer.22.output.dense.bias         |    1024    |\n","|      encoder.layer.22.output.LayerNorm.weight      |    1024    |\n","|       encoder.layer.22.output.LayerNorm.bias       |    1024    |\n","|    encoder.layer.23.attention.self.query.weight    |  1048576   |\n","|     encoder.layer.23.attention.self.query.bias     |    1024    |\n","|     encoder.layer.23.attention.self.key.weight     |  1048576   |\n","|      encoder.layer.23.attention.self.key.bias      |    1024    |\n","|    encoder.layer.23.attention.self.value.weight    |  1048576   |\n","|     encoder.layer.23.attention.self.value.bias     |    1024    |\n","|   encoder.layer.23.attention.output.dense.weight   |  1048576   |\n","|    encoder.layer.23.attention.output.dense.bias    |    1024    |\n","| encoder.layer.23.attention.output.LayerNorm.weight |    1024    |\n","|  encoder.layer.23.attention.output.LayerNorm.bias  |    1024    |\n","|     encoder.layer.23.intermediate.dense.weight     |  4194304   |\n","|      encoder.layer.23.intermediate.dense.bias      |    4096    |\n","|        encoder.layer.23.output.dense.weight        |  4194304   |\n","|         encoder.layer.23.output.dense.bias         |    1024    |\n","|      encoder.layer.23.output.LayerNorm.weight      |    1024    |\n","|       encoder.layer.23.output.LayerNorm.bias       |    1024    |\n","|    encoder.layer.24.attention.self.query.weight    |  1048576   |\n","|     encoder.layer.24.attention.self.query.bias     |    1024    |\n","|     encoder.layer.24.attention.self.key.weight     |  1048576   |\n","|      encoder.layer.24.attention.self.key.bias      |    1024    |\n","|    encoder.layer.24.attention.self.value.weight    |  1048576   |\n","|     encoder.layer.24.attention.self.value.bias     |    1024    |\n","|   encoder.layer.24.attention.output.dense.weight   |  1048576   |\n","|    encoder.layer.24.attention.output.dense.bias    |    1024    |\n","| encoder.layer.24.attention.output.LayerNorm.weight |    1024    |\n","|  encoder.layer.24.attention.output.LayerNorm.bias  |    1024    |\n","|     encoder.layer.24.intermediate.dense.weight     |  4194304   |\n","|      encoder.layer.24.intermediate.dense.bias      |    4096    |\n","|        encoder.layer.24.output.dense.weight        |  4194304   |\n","|         encoder.layer.24.output.dense.bias         |    1024    |\n","|      encoder.layer.24.output.LayerNorm.weight      |    1024    |\n","|       encoder.layer.24.output.LayerNorm.bias       |    1024    |\n","|    encoder.layer.25.attention.self.query.weight    |  1048576   |\n","|     encoder.layer.25.attention.self.query.bias     |    1024    |\n","|     encoder.layer.25.attention.self.key.weight     |  1048576   |\n","|      encoder.layer.25.attention.self.key.bias      |    1024    |\n","|    encoder.layer.25.attention.self.value.weight    |  1048576   |\n","|     encoder.layer.25.attention.self.value.bias     |    1024    |\n","|   encoder.layer.25.attention.output.dense.weight   |  1048576   |\n","|    encoder.layer.25.attention.output.dense.bias    |    1024    |\n","| encoder.layer.25.attention.output.LayerNorm.weight |    1024    |\n","|  encoder.layer.25.attention.output.LayerNorm.bias  |    1024    |\n","|     encoder.layer.25.intermediate.dense.weight     |  4194304   |\n","|      encoder.layer.25.intermediate.dense.bias      |    4096    |\n","|        encoder.layer.25.output.dense.weight        |  4194304   |\n","|         encoder.layer.25.output.dense.bias         |    1024    |\n","|      encoder.layer.25.output.LayerNorm.weight      |    1024    |\n","|       encoder.layer.25.output.LayerNorm.bias       |    1024    |\n","|    encoder.layer.26.attention.self.query.weight    |  1048576   |\n","|     encoder.layer.26.attention.self.query.bias     |    1024    |\n","|     encoder.layer.26.attention.self.key.weight     |  1048576   |\n","|      encoder.layer.26.attention.self.key.bias      |    1024    |\n","|    encoder.layer.26.attention.self.value.weight    |  1048576   |\n","|     encoder.layer.26.attention.self.value.bias     |    1024    |\n","|   encoder.layer.26.attention.output.dense.weight   |  1048576   |\n","|    encoder.layer.26.attention.output.dense.bias    |    1024    |\n","| encoder.layer.26.attention.output.LayerNorm.weight |    1024    |\n","|  encoder.layer.26.attention.output.LayerNorm.bias  |    1024    |\n","|     encoder.layer.26.intermediate.dense.weight     |  4194304   |\n","|      encoder.layer.26.intermediate.dense.bias      |    4096    |\n","|        encoder.layer.26.output.dense.weight        |  4194304   |\n","|         encoder.layer.26.output.dense.bias         |    1024    |\n","|      encoder.layer.26.output.LayerNorm.weight      |    1024    |\n","|       encoder.layer.26.output.LayerNorm.bias       |    1024    |\n","|    encoder.layer.27.attention.self.query.weight    |  1048576   |\n","|     encoder.layer.27.attention.self.query.bias     |    1024    |\n","|     encoder.layer.27.attention.self.key.weight     |  1048576   |\n","|      encoder.layer.27.attention.self.key.bias      |    1024    |\n","|    encoder.layer.27.attention.self.value.weight    |  1048576   |\n","|     encoder.layer.27.attention.self.value.bias     |    1024    |\n","|   encoder.layer.27.attention.output.dense.weight   |  1048576   |\n","|    encoder.layer.27.attention.output.dense.bias    |    1024    |\n","| encoder.layer.27.attention.output.LayerNorm.weight |    1024    |\n","|  encoder.layer.27.attention.output.LayerNorm.bias  |    1024    |\n","|     encoder.layer.27.intermediate.dense.weight     |  4194304   |\n","|      encoder.layer.27.intermediate.dense.bias      |    4096    |\n","|        encoder.layer.27.output.dense.weight        |  4194304   |\n","|         encoder.layer.27.output.dense.bias         |    1024    |\n","|      encoder.layer.27.output.LayerNorm.weight      |    1024    |\n","|       encoder.layer.27.output.LayerNorm.bias       |    1024    |\n","|    encoder.layer.28.attention.self.query.weight    |  1048576   |\n","|     encoder.layer.28.attention.self.query.bias     |    1024    |\n","|     encoder.layer.28.attention.self.key.weight     |  1048576   |\n","|      encoder.layer.28.attention.self.key.bias      |    1024    |\n","|    encoder.layer.28.attention.self.value.weight    |  1048576   |\n","|     encoder.layer.28.attention.self.value.bias     |    1024    |\n","|   encoder.layer.28.attention.output.dense.weight   |  1048576   |\n","|    encoder.layer.28.attention.output.dense.bias    |    1024    |\n","| encoder.layer.28.attention.output.LayerNorm.weight |    1024    |\n","|  encoder.layer.28.attention.output.LayerNorm.bias  |    1024    |\n","|     encoder.layer.28.intermediate.dense.weight     |  4194304   |\n","|      encoder.layer.28.intermediate.dense.bias      |    4096    |\n","|        encoder.layer.28.output.dense.weight        |  4194304   |\n","|         encoder.layer.28.output.dense.bias         |    1024    |\n","|      encoder.layer.28.output.LayerNorm.weight      |    1024    |\n","|       encoder.layer.28.output.LayerNorm.bias       |    1024    |\n","|    encoder.layer.29.attention.self.query.weight    |  1048576   |\n","|     encoder.layer.29.attention.self.query.bias     |    1024    |\n","|     encoder.layer.29.attention.self.key.weight     |  1048576   |\n","|      encoder.layer.29.attention.self.key.bias      |    1024    |\n","|    encoder.layer.29.attention.self.value.weight    |  1048576   |\n","|     encoder.layer.29.attention.self.value.bias     |    1024    |\n","|   encoder.layer.29.attention.output.dense.weight   |  1048576   |\n","|    encoder.layer.29.attention.output.dense.bias    |    1024    |\n","| encoder.layer.29.attention.output.LayerNorm.weight |    1024    |\n","|  encoder.layer.29.attention.output.LayerNorm.bias  |    1024    |\n","|     encoder.layer.29.intermediate.dense.weight     |  4194304   |\n","|      encoder.layer.29.intermediate.dense.bias      |    4096    |\n","|        encoder.layer.29.output.dense.weight        |  4194304   |\n","|         encoder.layer.29.output.dense.bias         |    1024    |\n","|      encoder.layer.29.output.LayerNorm.weight      |    1024    |\n","|       encoder.layer.29.output.LayerNorm.bias       |    1024    |\n","|    encoder.layer.30.attention.self.query.weight    |  1048576   |\n","|     encoder.layer.30.attention.self.query.bias     |    1024    |\n","|     encoder.layer.30.attention.self.key.weight     |  1048576   |\n","|      encoder.layer.30.attention.self.key.bias      |    1024    |\n","|    encoder.layer.30.attention.self.value.weight    |  1048576   |\n","|     encoder.layer.30.attention.self.value.bias     |    1024    |\n","|   encoder.layer.30.attention.output.dense.weight   |  1048576   |\n","|    encoder.layer.30.attention.output.dense.bias    |    1024    |\n","| encoder.layer.30.attention.output.LayerNorm.weight |    1024    |\n","|  encoder.layer.30.attention.output.LayerNorm.bias  |    1024    |\n","|     encoder.layer.30.intermediate.dense.weight     |  4194304   |\n","|      encoder.layer.30.intermediate.dense.bias      |    4096    |\n","|        encoder.layer.30.output.dense.weight        |  4194304   |\n","|         encoder.layer.30.output.dense.bias         |    1024    |\n","|      encoder.layer.30.output.LayerNorm.weight      |    1024    |\n","|       encoder.layer.30.output.LayerNorm.bias       |    1024    |\n","|    encoder.layer.31.attention.self.query.weight    |  1048576   |\n","|     encoder.layer.31.attention.self.query.bias     |    1024    |\n","|     encoder.layer.31.attention.self.key.weight     |  1048576   |\n","|      encoder.layer.31.attention.self.key.bias      |    1024    |\n","|    encoder.layer.31.attention.self.value.weight    |  1048576   |\n","|     encoder.layer.31.attention.self.value.bias     |    1024    |\n","|   encoder.layer.31.attention.output.dense.weight   |  1048576   |\n","|    encoder.layer.31.attention.output.dense.bias    |    1024    |\n","| encoder.layer.31.attention.output.LayerNorm.weight |    1024    |\n","|  encoder.layer.31.attention.output.LayerNorm.bias  |    1024    |\n","|     encoder.layer.31.intermediate.dense.weight     |  4194304   |\n","|      encoder.layer.31.intermediate.dense.bias      |    4096    |\n","|        encoder.layer.31.output.dense.weight        |  4194304   |\n","|         encoder.layer.31.output.dense.bias         |    1024    |\n","|      encoder.layer.31.output.LayerNorm.weight      |    1024    |\n","|       encoder.layer.31.output.LayerNorm.bias       |    1024    |\n","|    encoder.layer.32.attention.self.query.weight    |  1048576   |\n","|     encoder.layer.32.attention.self.query.bias     |    1024    |\n","|     encoder.layer.32.attention.self.key.weight     |  1048576   |\n","|      encoder.layer.32.attention.self.key.bias      |    1024    |\n","|    encoder.layer.32.attention.self.value.weight    |  1048576   |\n","|     encoder.layer.32.attention.self.value.bias     |    1024    |\n","|   encoder.layer.32.attention.output.dense.weight   |  1048576   |\n","|    encoder.layer.32.attention.output.dense.bias    |    1024    |\n","| encoder.layer.32.attention.output.LayerNorm.weight |    1024    |\n","|  encoder.layer.32.attention.output.LayerNorm.bias  |    1024    |\n","|     encoder.layer.32.intermediate.dense.weight     |  4194304   |\n","|      encoder.layer.32.intermediate.dense.bias      |    4096    |\n","|        encoder.layer.32.output.dense.weight        |  4194304   |\n","|         encoder.layer.32.output.dense.bias         |    1024    |\n","|      encoder.layer.32.output.LayerNorm.weight      |    1024    |\n","|       encoder.layer.32.output.LayerNorm.bias       |    1024    |\n","|    encoder.layer.33.attention.self.query.weight    |  1048576   |\n","|     encoder.layer.33.attention.self.query.bias     |    1024    |\n","|     encoder.layer.33.attention.self.key.weight     |  1048576   |\n","|      encoder.layer.33.attention.self.key.bias      |    1024    |\n","|    encoder.layer.33.attention.self.value.weight    |  1048576   |\n","|     encoder.layer.33.attention.self.value.bias     |    1024    |\n","|   encoder.layer.33.attention.output.dense.weight   |  1048576   |\n","|    encoder.layer.33.attention.output.dense.bias    |    1024    |\n","| encoder.layer.33.attention.output.LayerNorm.weight |    1024    |\n","|  encoder.layer.33.attention.output.LayerNorm.bias  |    1024    |\n","|     encoder.layer.33.intermediate.dense.weight     |  4194304   |\n","|      encoder.layer.33.intermediate.dense.bias      |    4096    |\n","|        encoder.layer.33.output.dense.weight        |  4194304   |\n","|         encoder.layer.33.output.dense.bias         |    1024    |\n","|      encoder.layer.33.output.LayerNorm.weight      |    1024    |\n","|       encoder.layer.33.output.LayerNorm.bias       |    1024    |\n","|    encoder.layer.34.attention.self.query.weight    |  1048576   |\n","|     encoder.layer.34.attention.self.query.bias     |    1024    |\n","|     encoder.layer.34.attention.self.key.weight     |  1048576   |\n","|      encoder.layer.34.attention.self.key.bias      |    1024    |\n","|    encoder.layer.34.attention.self.value.weight    |  1048576   |\n","|     encoder.layer.34.attention.self.value.bias     |    1024    |\n","|   encoder.layer.34.attention.output.dense.weight   |  1048576   |\n","|    encoder.layer.34.attention.output.dense.bias    |    1024    |\n","| encoder.layer.34.attention.output.LayerNorm.weight |    1024    |\n","|  encoder.layer.34.attention.output.LayerNorm.bias  |    1024    |\n","|     encoder.layer.34.intermediate.dense.weight     |  4194304   |\n","|      encoder.layer.34.intermediate.dense.bias      |    4096    |\n","|        encoder.layer.34.output.dense.weight        |  4194304   |\n","|         encoder.layer.34.output.dense.bias         |    1024    |\n","|      encoder.layer.34.output.LayerNorm.weight      |    1024    |\n","|       encoder.layer.34.output.LayerNorm.bias       |    1024    |\n","|    encoder.layer.35.attention.self.query.weight    |  1048576   |\n","|     encoder.layer.35.attention.self.query.bias     |    1024    |\n","|     encoder.layer.35.attention.self.key.weight     |  1048576   |\n","|      encoder.layer.35.attention.self.key.bias      |    1024    |\n","|    encoder.layer.35.attention.self.value.weight    |  1048576   |\n","|     encoder.layer.35.attention.self.value.bias     |    1024    |\n","|   encoder.layer.35.attention.output.dense.weight   |  1048576   |\n","|    encoder.layer.35.attention.output.dense.bias    |    1024    |\n","| encoder.layer.35.attention.output.LayerNorm.weight |    1024    |\n","|  encoder.layer.35.attention.output.LayerNorm.bias  |    1024    |\n","|     encoder.layer.35.intermediate.dense.weight     |  4194304   |\n","|      encoder.layer.35.intermediate.dense.bias      |    4096    |\n","|        encoder.layer.35.output.dense.weight        |  4194304   |\n","|         encoder.layer.35.output.dense.bias         |    1024    |\n","|      encoder.layer.35.output.LayerNorm.weight      |    1024    |\n","|       encoder.layer.35.output.LayerNorm.bias       |    1024    |\n","|                pooler.dense.weight                 |  1048576   |\n","|                 pooler.dense.bias                  |    1024    |\n","+----------------------------------------------------+------------+\n","Total Trainable Params: 476677120\n"]}]},{"cell_type":"code","source":["%env BERT_BASE_DIR=chinese_L-12_H-768_A-12\n","!cp $BERT_BASE_DIR/bert_config.json $BERT_BASE_DIR/config.json\n","!python count.py $BERT_BASE_DIR"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IdtqHl03SYFu","executionInfo":{"status":"ok","timestamp":1684554828780,"user_tz":-480,"elapsed":6522,"user":{"displayName":"Brian Shen","userId":"08246478872294528508"}},"outputId":"efccb125-7995-4358-80dd-254f9b6f19ea"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["env: BERT_BASE_DIR=chinese_L-12_H-768_A-12\n","TOTAL SIZE:102.267648M\n","+----------------------------------------------------+------------+\n","|                      Modules                       | Parameters |\n","+----------------------------------------------------+------------+\n","|         embeddings.word_embeddings.weight          |  16226304  |\n","|       embeddings.position_embeddings.weight        |   393216   |\n","|      embeddings.token_type_embeddings.weight       |    1536    |\n","|            embeddings.LayerNorm.weight             |    768     |\n","|             embeddings.LayerNorm.bias              |    768     |\n","|    encoder.layer.0.attention.self.query.weight     |   589824   |\n","|     encoder.layer.0.attention.self.query.bias      |    768     |\n","|     encoder.layer.0.attention.self.key.weight      |   589824   |\n","|      encoder.layer.0.attention.self.key.bias       |    768     |\n","|    encoder.layer.0.attention.self.value.weight     |   589824   |\n","|     encoder.layer.0.attention.self.value.bias      |    768     |\n","|   encoder.layer.0.attention.output.dense.weight    |   589824   |\n","|    encoder.layer.0.attention.output.dense.bias     |    768     |\n","| encoder.layer.0.attention.output.LayerNorm.weight  |    768     |\n","|  encoder.layer.0.attention.output.LayerNorm.bias   |    768     |\n","|     encoder.layer.0.intermediate.dense.weight      |  2359296   |\n","|      encoder.layer.0.intermediate.dense.bias       |    3072    |\n","|        encoder.layer.0.output.dense.weight         |  2359296   |\n","|         encoder.layer.0.output.dense.bias          |    768     |\n","|      encoder.layer.0.output.LayerNorm.weight       |    768     |\n","|       encoder.layer.0.output.LayerNorm.bias        |    768     |\n","|    encoder.layer.1.attention.self.query.weight     |   589824   |\n","|     encoder.layer.1.attention.self.query.bias      |    768     |\n","|     encoder.layer.1.attention.self.key.weight      |   589824   |\n","|      encoder.layer.1.attention.self.key.bias       |    768     |\n","|    encoder.layer.1.attention.self.value.weight     |   589824   |\n","|     encoder.layer.1.attention.self.value.bias      |    768     |\n","|   encoder.layer.1.attention.output.dense.weight    |   589824   |\n","|    encoder.layer.1.attention.output.dense.bias     |    768     |\n","| encoder.layer.1.attention.output.LayerNorm.weight  |    768     |\n","|  encoder.layer.1.attention.output.LayerNorm.bias   |    768     |\n","|     encoder.layer.1.intermediate.dense.weight      |  2359296   |\n","|      encoder.layer.1.intermediate.dense.bias       |    3072    |\n","|        encoder.layer.1.output.dense.weight         |  2359296   |\n","|         encoder.layer.1.output.dense.bias          |    768     |\n","|      encoder.layer.1.output.LayerNorm.weight       |    768     |\n","|       encoder.layer.1.output.LayerNorm.bias        |    768     |\n","|    encoder.layer.2.attention.self.query.weight     |   589824   |\n","|     encoder.layer.2.attention.self.query.bias      |    768     |\n","|     encoder.layer.2.attention.self.key.weight      |   589824   |\n","|      encoder.layer.2.attention.self.key.bias       |    768     |\n","|    encoder.layer.2.attention.self.value.weight     |   589824   |\n","|     encoder.layer.2.attention.self.value.bias      |    768     |\n","|   encoder.layer.2.attention.output.dense.weight    |   589824   |\n","|    encoder.layer.2.attention.output.dense.bias     |    768     |\n","| encoder.layer.2.attention.output.LayerNorm.weight  |    768     |\n","|  encoder.layer.2.attention.output.LayerNorm.bias   |    768     |\n","|     encoder.layer.2.intermediate.dense.weight      |  2359296   |\n","|      encoder.layer.2.intermediate.dense.bias       |    3072    |\n","|        encoder.layer.2.output.dense.weight         |  2359296   |\n","|         encoder.layer.2.output.dense.bias          |    768     |\n","|      encoder.layer.2.output.LayerNorm.weight       |    768     |\n","|       encoder.layer.2.output.LayerNorm.bias        |    768     |\n","|    encoder.layer.3.attention.self.query.weight     |   589824   |\n","|     encoder.layer.3.attention.self.query.bias      |    768     |\n","|     encoder.layer.3.attention.self.key.weight      |   589824   |\n","|      encoder.layer.3.attention.self.key.bias       |    768     |\n","|    encoder.layer.3.attention.self.value.weight     |   589824   |\n","|     encoder.layer.3.attention.self.value.bias      |    768     |\n","|   encoder.layer.3.attention.output.dense.weight    |   589824   |\n","|    encoder.layer.3.attention.output.dense.bias     |    768     |\n","| encoder.layer.3.attention.output.LayerNorm.weight  |    768     |\n","|  encoder.layer.3.attention.output.LayerNorm.bias   |    768     |\n","|     encoder.layer.3.intermediate.dense.weight      |  2359296   |\n","|      encoder.layer.3.intermediate.dense.bias       |    3072    |\n","|        encoder.layer.3.output.dense.weight         |  2359296   |\n","|         encoder.layer.3.output.dense.bias          |    768     |\n","|      encoder.layer.3.output.LayerNorm.weight       |    768     |\n","|       encoder.layer.3.output.LayerNorm.bias        |    768     |\n","|    encoder.layer.4.attention.self.query.weight     |   589824   |\n","|     encoder.layer.4.attention.self.query.bias      |    768     |\n","|     encoder.layer.4.attention.self.key.weight      |   589824   |\n","|      encoder.layer.4.attention.self.key.bias       |    768     |\n","|    encoder.layer.4.attention.self.value.weight     |   589824   |\n","|     encoder.layer.4.attention.self.value.bias      |    768     |\n","|   encoder.layer.4.attention.output.dense.weight    |   589824   |\n","|    encoder.layer.4.attention.output.dense.bias     |    768     |\n","| encoder.layer.4.attention.output.LayerNorm.weight  |    768     |\n","|  encoder.layer.4.attention.output.LayerNorm.bias   |    768     |\n","|     encoder.layer.4.intermediate.dense.weight      |  2359296   |\n","|      encoder.layer.4.intermediate.dense.bias       |    3072    |\n","|        encoder.layer.4.output.dense.weight         |  2359296   |\n","|         encoder.layer.4.output.dense.bias          |    768     |\n","|      encoder.layer.4.output.LayerNorm.weight       |    768     |\n","|       encoder.layer.4.output.LayerNorm.bias        |    768     |\n","|    encoder.layer.5.attention.self.query.weight     |   589824   |\n","|     encoder.layer.5.attention.self.query.bias      |    768     |\n","|     encoder.layer.5.attention.self.key.weight      |   589824   |\n","|      encoder.layer.5.attention.self.key.bias       |    768     |\n","|    encoder.layer.5.attention.self.value.weight     |   589824   |\n","|     encoder.layer.5.attention.self.value.bias      |    768     |\n","|   encoder.layer.5.attention.output.dense.weight    |   589824   |\n","|    encoder.layer.5.attention.output.dense.bias     |    768     |\n","| encoder.layer.5.attention.output.LayerNorm.weight  |    768     |\n","|  encoder.layer.5.attention.output.LayerNorm.bias   |    768     |\n","|     encoder.layer.5.intermediate.dense.weight      |  2359296   |\n","|      encoder.layer.5.intermediate.dense.bias       |    3072    |\n","|        encoder.layer.5.output.dense.weight         |  2359296   |\n","|         encoder.layer.5.output.dense.bias          |    768     |\n","|      encoder.layer.5.output.LayerNorm.weight       |    768     |\n","|       encoder.layer.5.output.LayerNorm.bias        |    768     |\n","|    encoder.layer.6.attention.self.query.weight     |   589824   |\n","|     encoder.layer.6.attention.self.query.bias      |    768     |\n","|     encoder.layer.6.attention.self.key.weight      |   589824   |\n","|      encoder.layer.6.attention.self.key.bias       |    768     |\n","|    encoder.layer.6.attention.self.value.weight     |   589824   |\n","|     encoder.layer.6.attention.self.value.bias      |    768     |\n","|   encoder.layer.6.attention.output.dense.weight    |   589824   |\n","|    encoder.layer.6.attention.output.dense.bias     |    768     |\n","| encoder.layer.6.attention.output.LayerNorm.weight  |    768     |\n","|  encoder.layer.6.attention.output.LayerNorm.bias   |    768     |\n","|     encoder.layer.6.intermediate.dense.weight      |  2359296   |\n","|      encoder.layer.6.intermediate.dense.bias       |    3072    |\n","|        encoder.layer.6.output.dense.weight         |  2359296   |\n","|         encoder.layer.6.output.dense.bias          |    768     |\n","|      encoder.layer.6.output.LayerNorm.weight       |    768     |\n","|       encoder.layer.6.output.LayerNorm.bias        |    768     |\n","|    encoder.layer.7.attention.self.query.weight     |   589824   |\n","|     encoder.layer.7.attention.self.query.bias      |    768     |\n","|     encoder.layer.7.attention.self.key.weight      |   589824   |\n","|      encoder.layer.7.attention.self.key.bias       |    768     |\n","|    encoder.layer.7.attention.self.value.weight     |   589824   |\n","|     encoder.layer.7.attention.self.value.bias      |    768     |\n","|   encoder.layer.7.attention.output.dense.weight    |   589824   |\n","|    encoder.layer.7.attention.output.dense.bias     |    768     |\n","| encoder.layer.7.attention.output.LayerNorm.weight  |    768     |\n","|  encoder.layer.7.attention.output.LayerNorm.bias   |    768     |\n","|     encoder.layer.7.intermediate.dense.weight      |  2359296   |\n","|      encoder.layer.7.intermediate.dense.bias       |    3072    |\n","|        encoder.layer.7.output.dense.weight         |  2359296   |\n","|         encoder.layer.7.output.dense.bias          |    768     |\n","|      encoder.layer.7.output.LayerNorm.weight       |    768     |\n","|       encoder.layer.7.output.LayerNorm.bias        |    768     |\n","|    encoder.layer.8.attention.self.query.weight     |   589824   |\n","|     encoder.layer.8.attention.self.query.bias      |    768     |\n","|     encoder.layer.8.attention.self.key.weight      |   589824   |\n","|      encoder.layer.8.attention.self.key.bias       |    768     |\n","|    encoder.layer.8.attention.self.value.weight     |   589824   |\n","|     encoder.layer.8.attention.self.value.bias      |    768     |\n","|   encoder.layer.8.attention.output.dense.weight    |   589824   |\n","|    encoder.layer.8.attention.output.dense.bias     |    768     |\n","| encoder.layer.8.attention.output.LayerNorm.weight  |    768     |\n","|  encoder.layer.8.attention.output.LayerNorm.bias   |    768     |\n","|     encoder.layer.8.intermediate.dense.weight      |  2359296   |\n","|      encoder.layer.8.intermediate.dense.bias       |    3072    |\n","|        encoder.layer.8.output.dense.weight         |  2359296   |\n","|         encoder.layer.8.output.dense.bias          |    768     |\n","|      encoder.layer.8.output.LayerNorm.weight       |    768     |\n","|       encoder.layer.8.output.LayerNorm.bias        |    768     |\n","|    encoder.layer.9.attention.self.query.weight     |   589824   |\n","|     encoder.layer.9.attention.self.query.bias      |    768     |\n","|     encoder.layer.9.attention.self.key.weight      |   589824   |\n","|      encoder.layer.9.attention.self.key.bias       |    768     |\n","|    encoder.layer.9.attention.self.value.weight     |   589824   |\n","|     encoder.layer.9.attention.self.value.bias      |    768     |\n","|   encoder.layer.9.attention.output.dense.weight    |   589824   |\n","|    encoder.layer.9.attention.output.dense.bias     |    768     |\n","| encoder.layer.9.attention.output.LayerNorm.weight  |    768     |\n","|  encoder.layer.9.attention.output.LayerNorm.bias   |    768     |\n","|     encoder.layer.9.intermediate.dense.weight      |  2359296   |\n","|      encoder.layer.9.intermediate.dense.bias       |    3072    |\n","|        encoder.layer.9.output.dense.weight         |  2359296   |\n","|         encoder.layer.9.output.dense.bias          |    768     |\n","|      encoder.layer.9.output.LayerNorm.weight       |    768     |\n","|       encoder.layer.9.output.LayerNorm.bias        |    768     |\n","|    encoder.layer.10.attention.self.query.weight    |   589824   |\n","|     encoder.layer.10.attention.self.query.bias     |    768     |\n","|     encoder.layer.10.attention.self.key.weight     |   589824   |\n","|      encoder.layer.10.attention.self.key.bias      |    768     |\n","|    encoder.layer.10.attention.self.value.weight    |   589824   |\n","|     encoder.layer.10.attention.self.value.bias     |    768     |\n","|   encoder.layer.10.attention.output.dense.weight   |   589824   |\n","|    encoder.layer.10.attention.output.dense.bias    |    768     |\n","| encoder.layer.10.attention.output.LayerNorm.weight |    768     |\n","|  encoder.layer.10.attention.output.LayerNorm.bias  |    768     |\n","|     encoder.layer.10.intermediate.dense.weight     |  2359296   |\n","|      encoder.layer.10.intermediate.dense.bias      |    3072    |\n","|        encoder.layer.10.output.dense.weight        |  2359296   |\n","|         encoder.layer.10.output.dense.bias         |    768     |\n","|      encoder.layer.10.output.LayerNorm.weight      |    768     |\n","|       encoder.layer.10.output.LayerNorm.bias       |    768     |\n","|    encoder.layer.11.attention.self.query.weight    |   589824   |\n","|     encoder.layer.11.attention.self.query.bias     |    768     |\n","|     encoder.layer.11.attention.self.key.weight     |   589824   |\n","|      encoder.layer.11.attention.self.key.bias      |    768     |\n","|    encoder.layer.11.attention.self.value.weight    |   589824   |\n","|     encoder.layer.11.attention.self.value.bias     |    768     |\n","|   encoder.layer.11.attention.output.dense.weight   |   589824   |\n","|    encoder.layer.11.attention.output.dense.bias    |    768     |\n","| encoder.layer.11.attention.output.LayerNorm.weight |    768     |\n","|  encoder.layer.11.attention.output.LayerNorm.bias  |    768     |\n","|     encoder.layer.11.intermediate.dense.weight     |  2359296   |\n","|      encoder.layer.11.intermediate.dense.bias      |    3072    |\n","|        encoder.layer.11.output.dense.weight        |  2359296   |\n","|         encoder.layer.11.output.dense.bias         |    768     |\n","|      encoder.layer.11.output.LayerNorm.weight      |    768     |\n","|       encoder.layer.11.output.LayerNorm.bias       |    768     |\n","|                pooler.dense.weight                 |   589824   |\n","|                 pooler.dense.bias                  |    768     |\n","+----------------------------------------------------+------------+\n","Total Trainable Params: 102267648\n"]}]}]}